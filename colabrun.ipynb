{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5KB0_RDrJTzT"
   },
   "source": [
    "# setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JaXYxzifbhst"
   },
   "outputs": [],
   "source": [
    "run_test=True\n",
    "run_test=False\n",
    "epochs=(1,1,1)\n",
    "epochs=(15,500,3)\n",
    "cutdate='2024-04-30'\n",
    "testData=''\n",
    "testData='new/'\n",
    "itr=5\n",
    "metrics_cnt=6\n",
    "import torch,sys\n",
    "\n",
    "if 'google.colab' in str(get_ipython()):\n",
    "  from google.colab import drive\n",
    "  drive.mount('/content/drive')\n",
    "  mydrive='/content/drive/MyDrive/volrt/'\n",
    "  source_path=mydrive+\"git/Crossformer\"\n",
    "  tables = ['volvNVDA.csv', 'volvTSLA.csv', 'volvAAPL.csv', 'volvGOOG.csv', ]\n",
    "  batch_size=int(torch.cuda.get_device_properties(0).total_memory/1e9+.5)*32\n",
    "  import os,sys\n",
    "  if not os.path.exists(source_path):\n",
    "    %cd $mydrive/git\n",
    "    !git clone https://github.com/jerronl/Crossformer.git\n",
    "    %cd $source_path\n",
    "  else:\n",
    "    %cd $source_path\n",
    "    !git reset --hard HEAD\n",
    "    !git pull origin master\n",
    "  %pip install einops #scikit-learn\n",
    "  sys.path.append( source_path)\n",
    "else:\n",
    "  tables = [ 'volvA.csv', 'volvG.csv', ]\n",
    "  mydrive= 'E:/mydoc/git/trade/analyics/'\n",
    "  batch_size=32\n",
    "%cd $mydrive\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import argparse\n",
    "import torch\n",
    "\n",
    "from cross_exp.exp_crossformer import Exp_crossformer\n",
    "from utils.tools import string_split\n",
    "\n",
    "\n",
    "parser = argparse.ArgumentParser(description=\"CrossFormer\")\n",
    "\n",
    "parser.add_argument(\"--data\", type=str, default=\"vols\", help=\"data\")\n",
    "parser.add_argument(\n",
    "    \"--root_path\", type=str, default=mydrive, help=\"root path of the data file\"\n",
    ")\n",
    "parser.add_argument(\"--data_path\", type=list, default=tables, help=\"data file\")\n",
    "parser.add_argument(\n",
    "    \"--data_split\",\n",
    "    type=str,\n",
    "    default=\"0.7,0.1,0.2\",\n",
    "    help=\"train/val/test split, can be ratio or number\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--checkpoints\",\n",
    "    type=str,\n",
    "    default=\"./checkpoints/\",\n",
    "    help=\"location to store model checkpoints\",\n",
    ")\n",
    "\n",
    "parser.add_argument(\"--in_len\", type=int, default=20, help=\"input MTS length (T)\")\n",
    "parser.add_argument(\"--out_len\", type=int, default=1, help=\"output MTS length (\\tau)\")\n",
    "parser.add_argument(\"--seg_len\", type=int, default=5, help=\"segment length (L_seg)\")\n",
    "parser.add_argument(\n",
    "    \"--win_size\", type=int, default=2, help=\"window size for segment merge\"\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--factor\",\n",
    "    type=int,\n",
    "    default=10,\n",
    "    help=\"num of routers in Cross-Dimension Stage of TSA (c)\",\n",
    ")\n",
    "\n",
    "parser.add_argument(\n",
    "    \"--d_model\", type=int, default=256, help=\"dimension of hidden states (d_model)\"\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--d_ff\", type=int, default=512, help=\"dimension of MLP in transformer\"\n",
    ")\n",
    "parser.add_argument(\"--n_heads\", type=int, default=4, help=\"num of heads\")\n",
    "parser.add_argument(\"--e_layers\", type=int, default=3, help=\"num of encoder layers (N)\")\n",
    "parser.add_argument(\"--dropout\", type=float, default=0.2, help=\"dropout\")\n",
    "\n",
    "parser.add_argument(\n",
    "    \"--baseline\",\n",
    "    action=\"store_true\",\n",
    "    help=\"whether to use mean of past series as baseline for prediction\",\n",
    "    default=False,\n",
    ")\n",
    "\n",
    "parser.add_argument(\n",
    "    \"--num_workers\", type=int, default=0, help=\"data loader num workers\"\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--batch_size\", type=int, default=32, help=\"batch size of train input data\"\n",
    ")\n",
    "parser.add_argument(\"--train_epochs\", type=int, default=20, help=\"train epochs\")\n",
    "parser.add_argument(\"--patience\", type=int, default=3, help=\"early stopping patience\")\n",
    "parser.add_argument(\n",
    "    \"--learning_rate\", type=float, default=1e-4, help=\"optimizer initial learning rate\"\n",
    ")\n",
    "parser.add_argument(\"--lradj\", type=str, default=\"type1\", help=\"adjust learning rate\")\n",
    "parser.add_argument(\"--itr\", type=int, default=itr, help=\"experiments times\")\n",
    "\n",
    "parser.add_argument(\n",
    "    \"--save_pred\",\n",
    "    action=\"store_true\",\n",
    "    help=\"whether to save the predicted future MTS\",\n",
    "    default=False,\n",
    ")\n",
    "\n",
    "parser.add_argument(\"--use_gpu\", type=bool, default=True, help=\"use gpu\")\n",
    "parser.add_argument(\"--resume\", type=bool, default=True, help=\"resume\")\n",
    "parser.add_argument(\"--query\", type=str, default=None, help=\"resume\")\n",
    "# parser.add_argument(\"--use_gpu\", type=bool, default=False, help=\"use gpu\")\n",
    "parser.add_argument(\"--gpu\", type=int, default=0, help=\"gpu\")\n",
    "parser.add_argument(\n",
    "    \"--use_multi_gpu\", action=\"store_true\", help=\"use multiple gpus\", default=False\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--devices\", type=str, default=\"0,1,2,3\", help=\"device ids of multile gpus\"\n",
    ")\n",
    "\n",
    "args = parser.parse_args(args=[])\n",
    "\n",
    "args.use_gpu = True if torch.cuda.is_available() and args.use_gpu else False\n",
    "\n",
    "if args.use_gpu and args.use_multi_gpu:\n",
    "    args.devices = args.devices.replace(\" \", \"\")\n",
    "    device_ids = args.devices.split(\",\")\n",
    "    args.device_ids = [int(id_) for id_ in device_ids]\n",
    "    args.gpu = args.device_ids[0]\n",
    "    print(args.gpu)\n",
    "\n",
    "\n",
    "def update_args(itr):\n",
    "    if args.data in data_parser.keys():\n",
    "        data_info = data_parser[args.data]\n",
    "        for k,v in data_info.items():\n",
    "            args.__setattr__(k,v)\n",
    "    if isinstance(args.data_split, str) :\n",
    "        args.data_split = string_split(args.data_split)\n",
    "\n",
    "    print(\"Args in experiment:\")\n",
    "    print(args)\n",
    "    setting = \"Crossformer_il{}_ol{}_sl{}_win{}_fa{}_dm{}_nh{}_el{}_itr{}\".format(\n",
    "        args.in_len,\n",
    "        args.out_len,\n",
    "        args.seg_len,\n",
    "        args.win_size,\n",
    "        args.factor,\n",
    "        args.d_model,\n",
    "        args.n_heads,\n",
    "        args.e_layers,\n",
    "        itr,\n",
    "    )\n",
    "    return setting\n",
    "import seaborn as sns, numpy as np,math\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "def regplot(cols, itr=None, figsize=(16, 16)):\n",
    "    global metrics\n",
    "    cnt = len(dep_var) - dep_var.count(\"_\")\n",
    "    figs = min(cnt, cols)\n",
    "    _, axes = plt.subplots(math.ceil(cnt / figs), figs, figsize=figsize)\n",
    "    j = 0\n",
    "\n",
    "    for i, name in enumerate(dep_var):\n",
    "        if name != \"_\":\n",
    "            if itr:\n",
    "                name=f'{itr}_{name}'\n",
    "            axs = axes.flat[j] if figs > 1 else axes\n",
    "            j = j + 1\n",
    "            left, right = 999, -999\n",
    "            for ii in range(len(results)):\n",
    "                preds, trues, _ = results[ii]\n",
    "                sns.regplot(\n",
    "                    ax=axs,\n",
    "                    x=trues[:, i],\n",
    "                    y=preds[:, i],\n",
    "                    scatter_kws={\"color\": f\"C{ii}\", \"alpha\": 0.3},\n",
    "                    line_kws={\"color\": f\"C{ii}\", \"alpha\": 0.3},\n",
    "                    label=labels[1][ii],\n",
    "                )\n",
    "                mask = ~np.isnan(trues[:, i])\n",
    "                if not dep_var[i][:3] in [\"dtm\", \"pmc\"]:\n",
    "                    left = min(left, max(np.min(trues[:, i][mask]), -5))\n",
    "                    right = max(right, min(np.max(trues[:, i][mask]), 5))\n",
    "                else:\n",
    "                    left = min(left, np.min(trues[:, i][mask]))\n",
    "                    right = max(right, np.max(trues[:, i][mask]))\n",
    "            axs.set_title(name)\n",
    "            axs.set_xlim(left=left, right=right)\n",
    "            axs.legend()\n",
    "    metric = []\n",
    "    for ii in range(len(results)):\n",
    "        _, _, m = results[ii]\n",
    "        metric.append(m)\n",
    "\n",
    "    metrics = np.append(\n",
    "        metrics, np.array(metric).reshape([1, len(metric), len(m)]), axis=0\n",
    "    )\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_metric(*args, **kwargs):\n",
    "    a, b, c = metrics.shape\n",
    "    _, axs = plt.subplots(\n",
    "        nrows=math.ceil(c / 2),\n",
    "        ncols=2, figsize=(16, 16), \n",
    "    )\n",
    "    for i in range(c):\n",
    "        ax = (\n",
    "            axs[i // 2, i % 2] if c > 1 else axs\n",
    "        )  # Handle the case when c=1 to avoid indexing errors\n",
    "        for j in range(a):\n",
    "            ax.plot(\n",
    "                metrics[j, :, i], label=labels[0][j], *args, **kwargs\n",
    "            )  # Plot each series in the i-th plot\n",
    "        ax.set_title(labels[2][i])\n",
    "        ax.legend()  # Show legend in each subplot\n",
    "\n",
    "        # Set custom x-axis labels\n",
    "        ax.set_xticks(range(b))  # Set x-tick positions for all 'b' points\n",
    "        ax.set_xticklabels(labels[1])  # Set x-tick labels\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qCfd-gU7JTzW"
   },
   "source": [
    "# train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YeTQzMtGy8Ih",
    "outputId": "80409e53-2e4e-494f-da99-81a52c5c8f49"
   },
   "outputs": [],
   "source": [
    "if not run_test:\n",
    "    from cross_exp.exp_crossformer import Exp_crossformer\n",
    "    from data.data_loader import DatasetMTS    \n",
    "    data_parser = {\n",
    "        \"vols\": {\n",
    "            \"patience\":epochs[0],\n",
    "            \"train_epochs\":epochs[1],\n",
    "            'learning_rate':0.01,\n",
    "            'data_split':[0.7,0.15,0.15],\n",
    "            'batch_size':batch_size*2//5,\n",
    "            'e_layers':5,\n",
    "            'd_model':512,\n",
    "            'lradj':'type2',\n",
    "            \"checkpoints\":\"./checkpoints/\",\n",
    "        },\n",
    "        }\n",
    "    for _ in range(epochs[2]):\n",
    "        data_parser[\"vols\"][\"learning_rate\"]=.01\n",
    "        for i in range(epochs[2]):\n",
    "            for ii in range(itr):\n",
    "                # setting record of experiments\n",
    "                setting = update_args(ii)\n",
    "                DatasetMTS.clear()\n",
    "\n",
    "                exp = Exp_crossformer(args)  # set experiments\n",
    "                print(f\">>>>>>>start training : {setting}>>>>>>>>>>>>>>>>>>>>>>>>>>\")\n",
    "                exp.train(setting, \"vols\")\n",
    "\n",
    "                print(f\">>>>>>>testing : {setting}<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\")\n",
    "                preds, trues,_ = exp.test(setting, 'vols', True, data_path=[tables[-1]], inverse=True)\n",
    "                print(preds.shape, trues.shape)\n",
    "\n",
    "                exp.train(setting, \"prcs\")\n",
    "                preds, trues,_ = exp.test(setting, 'prcs', True, data_path=[tables[-1]], inverse=True)\n",
    "                print(preds.shape, trues.shape)\n",
    "            data_parser[\"vols\"][\"learning_rate\"]/=3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4kj_rRG1J66H"
   },
   "outputs": [],
   "source": [
    "if not run_test:\n",
    "    from google.colab import runtime\n",
    "    runtime.unassign()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "066vGmCNJTzY"
   },
   "source": [
    "# test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "w03KqC8jJTzY"
   },
   "outputs": [],
   "source": [
    "from data.data_loader import DatasetMTS\n",
    "data_parser = {\n",
    "    \"vols\": {\n",
    "        'e_layers':5,\n",
    "        'd_model':512,\n",
    "        'lradj':'type2',\n",
    "    },\n",
    "    }\n",
    "dep_var=['level0', 'slope0', 'curve0', 'level1', 'slope1', 'curve1', 'level2', 'slope2', 'curve2', 'level3', 'slope3', 'curve3']\n",
    "labels=[[f'm{i}' for i in range(itr)],tables,[\"mae\", \"mse\", \"rmse\", \"mape\", \"mspe\", \"accr\"]]\n",
    "metrics=np.empty((0,len(tables),metrics_cnt))\n",
    "for i in range(itr):\n",
    "  setting=update_args(i)\n",
    "  DatasetMTS.clear()\n",
    "  exp = Exp_crossformer(args)\n",
    "  print(f\">>>>>>>testing : {setting}<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\")\n",
    "  results = []\n",
    "  for table in tables:\n",
    "      results.append(exp.test(setting, 'vols', True, data_path=[table], inverse=True))\n",
    "  regplot(3,i)\n",
    "\n",
    "print(metrics)\n",
    "plot_metric()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## _"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "P-BDe1GjJTzZ"
   },
   "outputs": [],
   "source": [
    "dep_var=['level0', '_', '_', 'level1', '_', '_', 'level2', '_', '_', 'level3', '_', '_']\n",
    "for i in range(itr):\n",
    "  setting=update_args(i)\n",
    "  DatasetMTS.clear()\n",
    "  exp = Exp_crossformer(args)\n",
    "  print(f\">>>>>>>testing : {setting}<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\")\n",
    "  results = []\n",
    "  for table in tables:\n",
    "      results.append(exp.test(setting, 'vols', True, data_path=[table], inverse=True))\n",
    "  regplot(4,i,(20,5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## hlc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JKW9afa-cENf"
   },
   "outputs": [],
   "source": [
    "dep_var=['pmcat','close', 'hi', 'lo',]\n",
    "metrics=np.empty((0,len(tables),metrics_cnt))\n",
    "for i in range(itr):\n",
    "  setting=update_args(i)\n",
    "  DatasetMTS.clear()\n",
    "  exp = Exp_crossformer(args)\n",
    "  print(f\">>>>>>>testing : {setting}<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\")\n",
    "  results = []\n",
    "  for table in tables:\n",
    "      results.append(exp.test(setting, 'prcs', True, data_path=[table], inverse=True))\n",
    "  regplot(2,i)\n",
    "  for j,result in enumerate(results):\n",
    "    preds, trues, _ = result\n",
    "    preds=preds[:,-22:].argmax(1)\n",
    "    sns.jointplot(x=trues[:,0] , y=preds,kind=\"kde\",fill=True,rug=True, color=f'C{j+1}')\n",
    "    plt.suptitle(f'{tables[j]}_{i}')\n",
    "  plt.show()\n",
    "\n",
    "print(metrics)\n",
    "plot_metric()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## horizon\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data.data_loader import DatasetMTS\n",
    "from cross_exp.exp_crossformer import Exp_crossformer\n",
    "\n",
    "labels=[[f'm{i}' for i in range(itr)] ,[f'h{h+1}' for h in range(5)],[\"mae\", \"mse\", \"rmse\", \"mape\", \"mspe\", \"accr\"]]\n",
    "dep_var=['level0', 'slope0', 'curve0', 'level1', 'slope1', 'curve1', 'level2', 'slope2', 'curve2', 'level3', 'slope3', 'curve3']\n",
    "metrics=np.empty((0,len(labels[1]),len(labels[2])))\n",
    "for i in range(itr):\n",
    "  results = []\n",
    "  for h in range(5):\n",
    "    data_parser = {\n",
    "    \"vols\": {\n",
    "        'e_layers':5,\n",
    "        'd_model':512,\n",
    "        'lradj':'type2',\n",
    "        \"query\": f\"date>'#{cutdate}' and floor(horizon)=={h+1}\",\n",
    "    },\n",
    "    }\n",
    "    setting=update_args(i)\n",
    "    DatasetMTS.clear()\n",
    "    exp = Exp_crossformer(args)\n",
    "    print(f\">>>>>>>testing : {data_parser['vols']['query']} m{i}h{h+1}<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\")\n",
    "    results.append(exp.test(setting, 'vols', True, inverse=True))\n",
    "  regplot(3)\n",
    "\n",
    "print(metrics)\n",
    "plot_metric()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## cutline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "F6WWmBSmcENg"
   },
   "outputs": [],
   "source": [
    "from data.data_loader import DatasetMTS\n",
    "from cross_exp.exp_crossformer import Exp_crossformer\n",
    "data_parser = {\n",
    "    \"vols\": {\n",
    "        'e_layers':5,\n",
    "        'd_model':512,\n",
    "        \"query\": f\"date>'#{cutdate}'\",        \n",
    "        'root_path':mydrive+testData,\n",
    "    },\n",
    "    }\n",
    "\n",
    "dep_var=['level0', 'slope0', 'curve0', 'level1', 'slope1', 'curve1', 'level2', 'slope2', 'curve2', 'level3', 'slope3', 'curve3']\n",
    "labels=[[f'm{i}' for i in range(itr)],tables,[\"mae\", \"mse\", \"rmse\", \"mape\", \"mspe\", \"accr\"]]\n",
    "metrics=np.empty((0,len(tables),metrics_cnt))\n",
    "for i in range(itr):\n",
    "  setting=update_args(i)\n",
    "  DatasetMTS.clear()\n",
    "  exp = Exp_crossformer(args)\n",
    "  print(f\">>>>>>>testing : {setting}<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\")\n",
    "  results = []\n",
    "  for table in tables:\n",
    "      results.append(exp.test(setting, 'vols', True, data_path=[table], inverse=True))\n",
    "  regplot(3,i)\n",
    "\n",
    "print(metrics)\n",
    "plot_metric()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## _\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-lpaApqDcENh"
   },
   "outputs": [],
   "source": [
    "dep_var=['level0', '_', '_', 'level1', '_', '_', 'level2', '_', '_', 'level3', '_', '_']\n",
    "for i in range(itr):\n",
    "  setting=update_args(i)\n",
    "  DatasetMTS.clear()\n",
    "  exp = Exp_crossformer(args)\n",
    "  print(f\">>>>>>>testing : {setting}<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\")\n",
    "  results = []\n",
    "  for table in tables:\n",
    "      results.append(exp.test(setting, 'vols', True, data_path=[table], inverse=True))\n",
    "  regplot(4,i,(20,5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## hlc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FFlVJgjocENh"
   },
   "outputs": [],
   "source": [
    "dep_var=['pmcat','close', 'hi', 'lo',]\n",
    "metrics=np.empty((0,len(tables),metrics_cnt))\n",
    "for i in range(itr):\n",
    "  setting=update_args(i)\n",
    "  DatasetMTS.clear()\n",
    "  exp = Exp_crossformer(args)\n",
    "  print(f\">>>>>>>testing : {setting}<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\")\n",
    "  results = []\n",
    "  for table in tables:\n",
    "      results.append(exp.test(setting, 'prcs', True, data_path=[table], inverse=True))\n",
    "  regplot(2,i)\n",
    "  for j,result in enumerate(results):\n",
    "    preds, trues, _ = result\n",
    "    preds=preds[:,-22:].argmax(1)\n",
    "    sns.jointplot(x=trues[:,0] , y=preds,kind=\"kde\",fill=True,rug=True, color=f'C{j+1}')\n",
    "    plt.suptitle(f'{tables[j]}_{i}')\n",
    "  plt.show()\n",
    "  \n",
    "print(metrics)\n",
    "plot_metric()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## horizon\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data.data_loader import DatasetMTS\n",
    "from cross_exp.exp_crossformer import Exp_crossformer\n",
    "\n",
    "labels=[[f'm{i}' for i in range(itr)] ,[f'h{h+1}' for h in range(5)],[\"mae\", \"mse\", \"rmse\", \"mape\", \"mspe\", \"accr\"]]\n",
    "dep_var=['level0', 'slope0', 'curve0', 'level1', 'slope1', 'curve1', 'level2', 'slope2', 'curve2', 'level3', 'slope3', 'curve3']\n",
    "metrics=np.empty((0,len(labels[1]),len(labels[2])))\n",
    "for i in range(itr):\n",
    "  results = []\n",
    "  for h in range(5):\n",
    "    data_parser = {\n",
    "    \"vols\": {\n",
    "        'e_layers':5,\n",
    "        'd_model':512,\n",
    "        'lradj':'type2',\n",
    "        \"query\": f\"date>'#{cutdate}' and floor(horizon)=={h+1}\",\n",
    "    },\n",
    "    }\n",
    "    setting=update_args(i)\n",
    "    DatasetMTS.clear()\n",
    "    exp = Exp_crossformer(args)\n",
    "    print(f\">>>>>>>testing : {data_parser['vols']['query']} m{i}h{h+1}<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\")\n",
    "    results.append(exp.test(setting, 'vols', True, inverse=True))\n",
    "  regplot(3)\n",
    "\n",
    "print(metrics)\n",
    "plot_metric()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "45zLIW5xJTza"
   },
   "outputs": [],
   "source": [
    "plt.show()\n",
    "from google.colab import runtime\n",
    "runtime.unassign()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "V100",
   "machine_shape": "hm",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "e1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
