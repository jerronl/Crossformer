{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5KB0_RDrJTzT"
   },
   "source": [
    "# setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JaXYxzifbhst"
   },
   "outputs": [],
   "source": [
    "run_test=True\n",
    "# run_test=False\n",
    "epochs=(1,1,1,0)\n",
    "epochs=(15,500,3,0)\n",
    "cutdate='2025-11-18'\n",
    "valData=''\n",
    "use_amp=True\n",
    "use_amp=False\n",
    "# valData='2512'\n",
    "testData=''\n",
    "testData='new/'\n",
    "checkpoints=\"./checkpoints/\"\n",
    "\n",
    "weight=(0.81,1.01,0.03,0)\n",
    "itr=5\n",
    "metrics_cnt=6\n",
    "import torch,sys\n",
    "\n",
    "if 'google.colab' in str(get_ipython()):\n",
    "  from google.colab import drive\n",
    "  drive.mount('/content/drive')\n",
    "  mydrive='/content/drive/MyDrive/volrt/'\n",
    "  source_path=mydrive+\"git/Crossformer\"\n",
    "  tables = [ 'volvTSLA.csv', 'volvAAPL.csv', 'volvGOOG.csv','volvNVDA.csv', 'volvMETA.csv', 'volvMSFT.csv', 'volvAMZN.csv', ]\n",
    "  batch_size=int(torch.cuda.get_device_properties(0).total_memory/1e9+.5)*32\n",
    "  import os,sys\n",
    "  if not os.path.exists(source_path):\n",
    "    %cd $mydrive/git\n",
    "    !git clone https://github.com/jerronl/Crossformer.git\n",
    "    %cd $source_path\n",
    "  else:\n",
    "    %cd $source_path\n",
    "    # !git reset --hard HEAD\n",
    "    # !git pull origin master\n",
    "  %pip install einops #scikit-learn\n",
    "  sys.path.append( source_path)\n",
    "else:\n",
    "  tables = [ 'volvAAPL.csv']\n",
    "  testData=''\n",
    "  mydrive= 'E:/mydoc/git/trade/analyics/'\n",
    "  batch_size=32\n",
    "  sys.path.append(\"G:/git/Crossformer1/\")\n",
    "  itr=1\n",
    "  %load_ext autoreload\n",
    "  %autoreload 2\n",
    "%cd $mydrive\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dQsiHS9i8ua4"
   },
   "outputs": [],
   "source": [
    "from cross_exp.exp_crossformer import Exp_crossformer\n",
    "\n",
    "\n",
    "from utils.tools import init_args,update_args\n",
    "import seaborn as sns, numpy as np,math\n",
    "import matplotlib.pyplot as plt\n",
    "from data.data_def import set_cat\n",
    "set_cat(20)\n",
    "args=init_args()\n",
    "data_parser={}\n",
    "\n",
    "\n",
    "def regplot(dep_var, metrics, cols, itr=None, figsize=4):\n",
    "    cnt = len(dep_var) - dep_var.count(\"_\")\n",
    "    figs = min(cnt, cols)\n",
    "    _, axes = plt.subplots(math.ceil(cnt / figs), figs, figsize=(figsize*figs,figsize*max(1,(cnt-1)//figs+1)))\n",
    "    j = 0\n",
    "\n",
    "    for i, name in enumerate(dep_var):\n",
    "        if name != \"_\":\n",
    "            # if itr:\n",
    "            name=f'{itr}_{name}'\n",
    "            axs = axes.flat[j] if figs > 1 else axes\n",
    "            j = j + 1\n",
    "            left, right = 999, -999\n",
    "            ax2=axs.twinx()\n",
    "            max_hist=0\n",
    "            for ii in range(len(results)):\n",
    "                preds, trues, _ = results[ii]\n",
    "                h,_,_=ax2.hist(trues[:, i], density=True,alpha=0.2,color=f\"C{ii}\")\n",
    "                max_hist=max(max_hist,np.max(h))\n",
    "                sns.regplot(\n",
    "                    ax=axs,\n",
    "                    x=trues[:, i],\n",
    "                    y=preds[:, i],\n",
    "                    scatter_kws={\"color\": f\"C{ii}\", \"alpha\": 0.2},\n",
    "                    line_kws={\"color\": f\"C{ii}\", \"alpha\": 0.4},\n",
    "                    label=labels[1][ii],\n",
    "                )\n",
    "                mask = ~np.isnan(trues[:, i])\n",
    "                if not dep_var[i][:3] in [\"dtm\", \"pmc\"]:\n",
    "                    left = min(left, max(np.min(trues[:, i][mask]), -5))\n",
    "                    right = max(right, min(np.max(trues[:, i][mask]), 5))\n",
    "                else:\n",
    "                    left = min(left, np.min(trues[:, i][mask]))\n",
    "                    right = max(right, np.max(trues[:, i][mask]))\n",
    "            ax2.tick_params(axis='y', labelleft=False, labelright=False, left=False, right=False)\n",
    "            ax2.set_ylim(0, max_hist*3)\n",
    "            ax2.set_ylabel('')\n",
    "            axs.set_title(name)\n",
    "            xmin, xmax = axs.get_ylim()\n",
    "            left, right=min(-0.01,min(left,xmin)),max(0.01,max(xmax, right))\n",
    "            axs.set_xlim(left=left, right=right)\n",
    "            axs.set_ylim(left, right)\n",
    "            axs.legend()\n",
    "    metric = []\n",
    "    for ii in range(len(results)):\n",
    "        _, _, m = results[ii]\n",
    "        metric.append(m)\n",
    "\n",
    "    metrics = np.append(\n",
    "        metrics, np.array(metric).reshape([1, len(metric), len(m)]), axis=0\n",
    "    )\n",
    "\n",
    "    plt.show()\n",
    "    return metrics\n",
    "\n",
    "\n",
    "\n",
    "def plot_metric(metrics, labels, *args, **kwargs):\n",
    "    a, b, c = metrics.shape\n",
    "    _, axs = plt.subplots(\n",
    "        nrows=math.ceil(c / 2),\n",
    "        ncols=2, figsize=(16, 16),\n",
    "    )\n",
    "    for i in range(c):\n",
    "        ax = (\n",
    "            axs[i // 2, i % 2] if c > 1 else axs\n",
    "        )  # Handle the case when c=1 to avoid indexing errors\n",
    "        for j in range(a):\n",
    "            ax.plot(\n",
    "                metrics[j, :, i], label=labels[0][j], *args, **kwargs\n",
    "            )  # Plot each series in the i-th plot\n",
    "        ax.set_title(labels[2][i])\n",
    "        ax.legend()  # Show legend in each subplot\n",
    "\n",
    "        # Set custom x-axis labels\n",
    "        ax.set_xticks(range(b))  # Set x-tick positions for all 'b' points\n",
    "        ax.set_xticklabels(labels[1])  # Set x-tick labels\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def plot_hlc():\n",
    "    global results, labels\n",
    "    dep_var = data_names(data_columns(test_set), 20)[0]\n",
    "    labels = [\n",
    "        [f'm{i}' for i in range(itr)],  # Model identifiers\n",
    "        tables,                         # Table names\n",
    "        [\"mae\", \"mse\", \"rmse\", \"mape\", \"wmse\", \"accr\"]  # Metric labels\n",
    "    ]\n",
    "    metrics = np.empty((0, len(tables), metrics_cnt))\n",
    "    n_categories = data_columns(test_set)[\"ycat\"]\n",
    "    x = np.arange(1, n_categories + 1)\n",
    "    for i in range(itr):\n",
    "        setting = update_args(args, data_parser, i)\n",
    "        DatasetMTS.clear()\n",
    "        exp = Exp_crossformer(args)\n",
    "        print(f\">>>>>>> Testing: {setting} <<<<<<<<<<<<<<<<<<<<<<<<<<<\")\n",
    "        results = []\n",
    "\n",
    "        for table in tables:\n",
    "            results.append(exp.test(setting, 'prcs', True, data_path=[table], inverse=1))\n",
    "\n",
    "        metrics = regplot(dep_var, metrics, 4, i)\n",
    "\n",
    "        cols=4\n",
    "        rows = (len(results) - 1) // cols + 1\n",
    "\n",
    "        _, axes = plt.subplots(rows*2, cols, figsize=(16, cols * rows*2))\n",
    "        axes = axes.flatten()\n",
    "\n",
    "        for j, result in enumerate(results):\n",
    "            preds, trues, _ = result\n",
    "            preds = preds[:, -n_categories:]\n",
    "            trues = np.round(trues[:, 0]).astype(int)\n",
    "            df = pd.DataFrame(preds, columns=[str(i) for i in range(1, n_categories + 1)])\n",
    "            df['True_Label'] = trues\n",
    "\n",
    "            summed_probs = df.groupby('True_Label').mean().T\n",
    "            xi=[float(x) + 0.5 for x in summed_probs.index]\n",
    "            half=max(summed_probs.columns)/2\n",
    "            third=max(summed_probs.columns)//3+1\n",
    "            ls=['--','-',':']\n",
    "            for k in (0,1):\n",
    "              ci=0\n",
    "              ax = axes[int(j//cols)*cols*2+j%cols+k*cols]\n",
    "              ax.hist(trues, bins=np.arange(0.5, n_categories + 0.5),alpha=0.2, density=True)\n",
    "              for m in range(k,len(summed_probs.columns),2):\n",
    "                  col=summed_probs.columns[m]\n",
    "                  ax.plot(xi, summed_probs[col],\n",
    "                          label=f'Col {col}',\n",
    "                          linestyle=ls[col // third ],\n",
    "                          color=f'C{ci % 10}',alpha=0.5)\n",
    "                  ci+=1\n",
    "\n",
    "                  ax.text(col-.5, summed_probs[col][col-1], f'{col}',\n",
    "                          fontsize=8, verticalalignment='center', horizontalalignment='left')\n",
    "                  ax.legend(loc='center left', bbox_to_anchor=(1.05, 0.5))\n",
    "\n",
    "              ax.set_title(f'{tables[j]}_{i}')\n",
    "              ax.set_ylim(0.0, 0.2)\n",
    "              ax.set_xlim(0.5, n_categories + 0.5)\n",
    "              ax.set_xticks(x)\n",
    "              ax.set_xticklabels([str(i) for i in x], rotation=-45)\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    print(metrics)\n",
    "    plot_metric(metrics, labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qCfd-gU7JTzW"
   },
   "source": [
    "# train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================\n",
    "#   FINAL TRAINING SCRIPT\n",
    "# ===========================\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from copy import deepcopy\n",
    "\n",
    "from cross_exp.exp_crossformer import Exp_crossformer\n",
    "from data.data_loader import DatasetMTS\n",
    "\n",
    "# -----------------------------------------\n",
    "# Heatmap for residual (auto-truncate logits)\n",
    "# -----------------------------------------\n",
    "def plot_residual_heatmap(preds, trues, title, save_path, bins=50, show_inline=True):\n",
    "    \"\"\"\n",
    "    画预测 vs 真实的 2D residual heatmap\n",
    "    - vols: preds/trues 维度一致\n",
    "    - prcs: preds 多出 ycat logits，自动截掉\n",
    "    \"\"\"\n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt\n",
    "    import os\n",
    "\n",
    "    preds = np.asarray(preds)\n",
    "    trues = np.asarray(trues)\n",
    "\n",
    "    # prcs: preds 多出分类 logits，自动截掉\n",
    "    if preds.ndim == 2 and trues.ndim == 2 and preds.shape[1] > trues.shape[1]:\n",
    "        preds = preds[:, :trues.shape[1]]\n",
    "\n",
    "    preds_flat = preds.reshape(-1)\n",
    "    trues_flat = trues.reshape(-1)\n",
    "\n",
    "    # 对齐长度（极端情况下）\n",
    "    if preds_flat.size != trues_flat.size:\n",
    "        L = min(preds_flat.size, trues_flat.size)\n",
    "        preds_flat = preds_flat[:L]\n",
    "        trues_flat = trues_flat[:L]\n",
    "\n",
    "    # 去 NaN\n",
    "    mask = ~np.isnan(preds_flat) & ~np.isnan(trues_flat)\n",
    "    preds_flat = preds_flat[mask]\n",
    "    trues_flat = trues_flat[mask]\n",
    "\n",
    "    plt.figure(figsize=(5, 4))\n",
    "    plt.hist2d(trues_flat, preds_flat, bins=bins)\n",
    "    plt.colorbar(label=\"count\")\n",
    "    plt.xlabel(\"True\")\n",
    "    plt.ylabel(\"Predicted\")\n",
    "    plt.title(title)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    os.makedirs(os.path.dirname(save_path), exist_ok=True)\n",
    "    plt.savefig(save_path, dpi=150)\n",
    "\n",
    "    if show_inline:\n",
    "        plt.show()\n",
    "    else:\n",
    "        plt.close()\n",
    "\n",
    "\n",
    "# ------------------------\n",
    "#  Prepare directories\n",
    "# ------------------------\n",
    "SUMMARY_DIR = os.path.join(checkpoints, \"summaries\")\n",
    "FIG_DIR = os.path.join(checkpoints, \"figures\")\n",
    "os.makedirs(SUMMARY_DIR, exist_ok=True)\n",
    "os.makedirs(FIG_DIR, exist_ok=True)\n",
    "SUMMARY_PATH = os.path.join(SUMMARY_DIR, \"summary.csv\")\n",
    "\n",
    "# ===========================\n",
    "#       PARAMETER GRID\n",
    "# ===========================\n",
    "\n",
    "BASE_LR = 0.01\n",
    "RUN_PRCS = True  # 单独跑 prcs\n",
    "\n",
    "# 只 sweep vols 的参数\n",
    "VOL_GRID = []\n",
    "lambda_vars = [0.0005, 0.001, 0.002]\n",
    "weight_overs = [1.5, 2.0, 3.0]\n",
    "\n",
    "for lv in lambda_vars:\n",
    "    for wo in weight_overs:\n",
    "        name = f\"LV{lv}_WO{wo}\"\n",
    "        VOL_GRID.append((name, lv, 2.0, 0.0, wo))  \n",
    "        # (name, lambda_var, lambda_ce, lambda_shape, weight_over)\n",
    "\n",
    "# ------------------------\n",
    "# Base data parser\n",
    "# ------------------------\n",
    "base_data_parser = {\n",
    "    \"vols\": {\n",
    "        \"data\": \"vols\",\n",
    "        \"patience\": epochs[0],\n",
    "        \"train_epochs\": epochs[1],\n",
    "        \"learning_rate\": BASE_LR,\n",
    "        \"data_split\": [0.7, 0.15, 0.15],\n",
    "        \"batch_size\": batch_size * 2 // 5,\n",
    "        \"e_layers\": 5,\n",
    "        \"d_model\": 512,\n",
    "        \"lradj\": \"type2\",\n",
    "        \"checkpoints\": checkpoints,\n",
    "        \"root_path\": mydrive + valData,\n",
    "        \"data_path\": tables,\n",
    "        \"profile_mode\": False,\n",
    "        \"use_amp\": use_amp,\n",
    "    },\n",
    "    \"prcs\": {\n",
    "        \"data\": \"prcs\",\n",
    "        \"weight\": 0.0,        # prcs 固定 λ_var=0\n",
    "        \"over_weight\": weight[3],\n",
    "    },\n",
    "}\n",
    "\n",
    "# ------------------------\n",
    "#  Helper: apply parser\n",
    "# ------------------------\n",
    "def update_args_from_parser(args, data_parser, run_name, ds):\n",
    "    cfg = data_parser[ds]\n",
    "    for k, v in cfg.items():\n",
    "        setattr(args, k, v)\n",
    "    return f\"{run_name}_{ds}\"\n",
    "\n",
    "# Clear dataset ONCE (保证所有组合使用同一划分）\n",
    "DatasetMTS.clear()\n",
    "\n",
    "summary_rows = []\n",
    "\n",
    "# ===========================\n",
    "#       TRAINING LOOP\n",
    "# ===========================\n",
    "for name, lambda_var, lambda_ce, lambda_shape, weight_over in VOL_GRID:\n",
    "\n",
    "    print(f\"\\n===========  VOLS: {name}  ===========\")\n",
    "\n",
    "    # ---- build data parser ----\n",
    "    data_parser = deepcopy(base_data_parser)\n",
    "    data_parser[\"vols\"][\"learning_rate\"] = BASE_LR\n",
    "    data_parser[\"vols\"][\"weight\"] = lambda_var\n",
    "    data_parser[\"vols\"][\"lambda_ce\"] = lambda_ce\n",
    "    data_parser[\"vols\"][\"lambda_shape\"] = lambda_shape\n",
    "    data_parser[\"vols\"][\"weight_over\"] = weight_over\n",
    "\n",
    "    # ---------------------\n",
    "    #    train vols\n",
    "    # ---------------------\n",
    "    setting = update_args_from_parser(args, data_parser, name, \"vols\")\n",
    "    exp = Exp_crossformer(args)\n",
    "\n",
    "    print(f\"Training vols: {setting}\")\n",
    "    exp.train(setting, \"vols\")\n",
    "\n",
    "    preds, trues, metrics = exp.test(\n",
    "        setting, \"vols\", save_pred=True, data_path=[tables[-1]], inverse=True\n",
    "    )\n",
    "    fig_path = os.path.join(FIG_DIR, f\"{setting}_residual_vols.png\")\n",
    "    plot_residual_heatmap(preds, trues, f\"{setting} vols\", fig_path)\n",
    "\n",
    "    if metrics is not None:\n",
    "        mae, mse, rmse, mape, mdst, accr = metrics\n",
    "        summary_rows.append({\n",
    "            \"exp\": name, \"dataset\": \"vols\",\n",
    "            \"lambda_var\": lambda_var,\n",
    "            \"weight_over\": weight_over,\n",
    "            \"lambda_ce\": lambda_ce,\n",
    "            \"lambda_shape\": lambda_shape,\n",
    "            \"mae\": mae, \"mse\": mse, \"rmse\": rmse,\n",
    "            \"mape\": mape, \"mdst\": mdst, \"accr\": accr\n",
    "        })\n",
    "\n",
    "\n",
    "    # ---------------------\n",
    "    #    train prcs (optional)\n",
    "    # ---------------------\n",
    "    if RUN_PRCS:\n",
    "        print(f\"\\n---- PRCS for {name} ----\")\n",
    "\n",
    "        # prcs 固定 λ_var=0，只同步 ce/shape\n",
    "        data_parser[\"prcs\"][\"lambda_ce\"] = lambda_ce\n",
    "        data_parser[\"prcs\"][\"lambda_shape\"] = lambda_shape\n",
    "        data_parser[\"prcs\"][\"weight_over\"] = 1.0  # prcs 不用 asymmetry\n",
    "\n",
    "        setting_p = update_args_from_parser(args, data_parser, name, \"prcs\")\n",
    "        exp_p = Exp_crossformer(args)\n",
    "        exp_p.train(setting_p, \"prcs\")\n",
    "\n",
    "        preds_p, trues_p, metrics_p = exp_p.test(\n",
    "            setting_p, \"prcs\", save_pred=False, data_path=[tables[-1]], inverse=True\n",
    "        )\n",
    "\n",
    "        fig_path_p = os.path.join(FIG_DIR, f\"{setting_p}_residual_prcs.png\")\n",
    "        plot_residual_heatmap(preds_p, trues_p, f\"{setting_p} prcs\", fig_path_p)\n",
    "\n",
    "        if metrics_p is not None:\n",
    "            mae, mse, rmse, mape, mdst, accr = metrics_p\n",
    "            summary_rows.append({\n",
    "                \"exp\": name, \"dataset\": \"prcs\",\n",
    "                \"lambda_var\": 0.0,\n",
    "                \"weight_over\": 1.0,\n",
    "                \"lambda_ce\": lambda_ce,\n",
    "                \"lambda_shape\": lambda_shape,\n",
    "                \"mae\": mae, \"mse\": mse, \"rmse\": rmse,\n",
    "                \"mape\": mape, \"mdst\": mdst, \"accr\": accr\n",
    "            })\n",
    "\n",
    "# ===========================\n",
    "#     SAVE SUMMARY\n",
    "# ===========================\n",
    "df = pd.DataFrame(summary_rows)\n",
    "df.to_csv(SUMMARY_PATH, index=False)\n",
    "\n",
    "print(\"\\nSummary saved:\", SUMMARY_PATH)\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4kj_rRG1J66H"
   },
   "outputs": [],
   "source": [
    "if not run_test:\n",
    "    from google.colab import runtime\n",
    "    runtime.unassign()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not run_test:\n",
    "    from cross_exp.exp_crossformer import Exp_crossformer\n",
    "    from data.data_loader import DatasetMTS\n",
    "    data_parser = {\n",
    "        \"vols\": {\n",
    "            'data':'vols',\n",
    "            \"patience\":epochs[0],\n",
    "            \"train_epochs\":epochs[1],\n",
    "            'learning_rate':0.01,\n",
    "            'data_split':[0.7,0.15,0.15],\n",
    "            'batch_size':batch_size*2//5,\n",
    "            'e_layers':5,\n",
    "            'd_model':512,\n",
    "            'lradj':'type2',\n",
    "            \"checkpoints\":checkpoints,\n",
    "            'root_path':mydrive+valData,\n",
    "            'data_path':tables,\n",
    "            'weight':weight[0],\n",
    "            'over_weight':weight[2],\n",
    "            'profile_mode':False,\n",
    "            'use_amp':use_amp\n",
    "        },\n",
    "        \"prcs\":{\n",
    "            'data':'prcs',\n",
    "            'weight':weight[1],\n",
    "            'over_weight':weight[3],\n",
    "        }\n",
    "        }\n",
    "    s=epochs[3]\n",
    "    for _ in range(epochs[2]):\n",
    "        data_parser[\"vols\"][\"learning_rate\"]=.01\n",
    "        for i in range(epochs[2]):\n",
    "            for ii in range(s,itr):\n",
    "                # setting record of experiments\n",
    "                # data_parser[\"vols\"]['weight']=weight[0]\n",
    "                setting=update_args(args,data_parser,ii)\n",
    "                DatasetMTS.clear()\n",
    "                # drive.mount('/content/drive/',force_remount=True)\n",
    "                !google-drive-ocamlfuse -cc\n",
    "\n",
    "                exp = Exp_crossformer(args)  # set experiments\n",
    "                print(f\"start training :lr={data_parser[\"vols\"][\"learning_rate\"]} {setting}\")\n",
    "                exp.train(setting, \"vols\")\n",
    "\n",
    "                print(f\">>>>>>>testing : {setting}<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\")\n",
    "                preds, trues,_ = exp.test(setting, 'vols', True, data_path=[tables[-1]], inverse=True)\n",
    "                print(preds.shape, trues.shape)\n",
    "\n",
    "                # data_parser[\"vols\"]['weight']=weight[1]\n",
    "                setting=update_args(args,data_parser,ii,'prcs')\n",
    "                DatasetMTS.clear()\n",
    "                exp = Exp_crossformer(args)  # set experiments\n",
    "                print(f\"start training :lr={data_parser[\"vols\"][\"learning_rate\"]} {setting}\")\n",
    "                exp.train(setting, \"prcs\")\n",
    "                preds, trues,_ = exp.test(setting, 'prcs', True, data_path=[tables[-1]], inverse=True)\n",
    "                print(preds.shape, trues.shape)\n",
    "            data_parser[\"vols\"][\"learning_rate\"]/=3.\n",
    "            s=0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "066vGmCNJTzY"
   },
   "source": [
    "# test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "w03KqC8jJTzY"
   },
   "outputs": [],
   "source": [
    "from data.data_loader import DatasetMTS\n",
    "from data.data_def import data_columns, data_names\n",
    "data_parser = {\n",
    "    \"vols\": {\n",
    "        'e_layers':5,\n",
    "        'd_model':512,\n",
    "        'lradj':'type2',\n",
    "        'weight':weight[0],\n",
    "        'root_path':mydrive+valData,\n",
    "    },\n",
    "    }\n",
    "test_set='vols'\n",
    "dep_var=data_names(data_columns(test_set),20)[0]\n",
    "labels=[[f'm{i}' for i in range(itr)],tables,[\"mae\", \"mse\", \"rmse\", \"mape\", \"wmse\", \"accr\"]]\n",
    "metrics=np.empty((0,len(tables),metrics_cnt))\n",
    "for i in range(itr):\n",
    "  setting=update_args(args,data_parser,i)\n",
    "  DatasetMTS.clear()\n",
    "  exp = Exp_crossformer(args)\n",
    "  print(f\">>>>>>>testing : {setting}<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\")\n",
    "  results = []\n",
    "  for table in tables:\n",
    "      results.append(exp.test(setting, 'vols', True, data_path=[table], inverse=True))\n",
    "  metrics=regplot(dep_var,metrics,4,i)\n",
    "\n",
    "print(metrics)\n",
    "plot_metric(metrics,labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wkGkKgp98ua9"
   },
   "source": [
    "## hlc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JKW9afa-cENf"
   },
   "outputs": [],
   "source": [
    "from data.data_loader import DatasetMTS\n",
    "from data.data_def import data_columns, data_names\n",
    "import pandas as pd\n",
    "\n",
    "test_set='prcs'\n",
    "data_parser = {\n",
    "    \"vols\": {\n",
    "        'e_layers':5,\n",
    "        'd_model':512,\n",
    "        'lradj':'type2',\n",
    "        'root_path':mydrive+valData,\n",
    "        'weight':weight[1]#0.8#\n",
    "    },\n",
    "    }\n",
    "plot_hlc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L9IXNP9K8ua-"
   },
   "source": [
    "## horizon\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rpzR-1aN8ua-"
   },
   "outputs": [],
   "source": [
    "from data.data_loader import DatasetMTS\n",
    "from cross_exp.exp_crossformer import Exp_crossformer\n",
    "test_set='vols'\n",
    "\n",
    "labels=[[f'm{i}' for i in range(itr)] ,[f'h{5-h}' for h in range(5)],[\"mae\", \"mse\", \"rmse\", \"mape\", \"wmse\", \"accr\"]]\n",
    "dep_var=data_names(data_columns(test_set),20)[0]\n",
    "metrics=np.empty((0,len(labels[1]),len(labels[2])))\n",
    "for i in range(itr):\n",
    "  results = []\n",
    "  for h in range(5):\n",
    "    data_parser = {\n",
    "    \"vols\": {\n",
    "        'e_layers':5,\n",
    "        'd_model':512,\n",
    "        'lradj':'type2',\n",
    "        \"query\": f\"floor(horizon)=={5-h}\",\n",
    "        'weight':weight[0],\n",
    "        'root_path':mydrive+valData,\n",
    "        'data_path':tables,    \n",
    "    },\n",
    "    }\n",
    "    setting=update_args(args,data_parser,i)\n",
    "    DatasetMTS.clear()\n",
    "    exp = Exp_crossformer(args)\n",
    "    print(f\">>>>>>>testing : {data_parser['vols']['query']} m{i}h{5-h}<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\")\n",
    "    results.append(exp.test(setting, 'vols', True, inverse=True))\n",
    "  metrics=regplot(dep_var,metrics,4,i)\n",
    "\n",
    "print(metrics)\n",
    "plot_metric(metrics,labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KBfRZp9y8ua-"
   },
   "source": [
    "## cutline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "F6WWmBSmcENg"
   },
   "outputs": [],
   "source": [
    "from cross_exp.exp_crossformer import Exp_crossformer\n",
    "from data.data_loader import DatasetMTS\n",
    "from data.data_def import data_columns, data_names\n",
    "test_set='vols'\n",
    "\n",
    "data_parser = {\n",
    "    \"vols\": {\n",
    "        'e_layers':5,\n",
    "        'd_model':512,\n",
    "        \"query\": f\"date>'#{cutdate}'\",\n",
    "        'root_path':mydrive+testData,\n",
    "        'weight':weight[0],    \n",
    "    },\n",
    "    }\n",
    "\n",
    "dep_var=data_names(data_columns(test_set),20)[0]\n",
    "labels=[[f'm{i}' for i in range(itr)],tables,[\"mae\", \"mse\", \"rmse\", \"mape\", \"wmse\", \"accr\"]]\n",
    "metrics=np.empty((0,len(tables),metrics_cnt))\n",
    "for i in range(itr):\n",
    "  setting=update_args(args,data_parser,i)\n",
    "  DatasetMTS.clear()\n",
    "  exp = Exp_crossformer(args)\n",
    "  print(f\">>>>>>>testing : {setting}<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\")\n",
    "  results = []\n",
    "  for table in tables:\n",
    "      results.append(exp.test(setting, 'vols', True, data_path=[table], inverse=True))\n",
    "  metrics=regplot(dep_var,metrics,4,i)\n",
    "\n",
    "print(metrics)\n",
    "plot_metric(metrics,labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rWJgEQeu8ua_"
   },
   "source": [
    "## hlc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FFlVJgjocENh"
   },
   "outputs": [],
   "source": [
    "from data.data_loader import DatasetMTS\n",
    "from data.data_def import data_columns, data_names\n",
    "import pandas as pd\n",
    "\n",
    "test_set='prcs'\n",
    "data_parser = {\n",
    "    \"vols\": {\n",
    "        'e_layers':5,\n",
    "        'd_model':512,\n",
    "        'lradj':'type2',\n",
    "        \"query\": f\"date>'#{cutdate}'\",\n",
    "        'root_path':mydrive+testData,\n",
    "        'weight':weight[1],\n",
    "        },\n",
    "    }\n",
    "plot_hlc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ff1dksSt8ubA"
   },
   "source": [
    "## horizon\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VPL62tkj8ubA"
   },
   "outputs": [],
   "source": [
    "from data.data_loader import DatasetMTS\n",
    "from cross_exp.exp_crossformer import Exp_crossformer\n",
    "from data.data_def import data_columns, data_names\n",
    "test_set='vols'\n",
    "labels=[[f'm{i}' for i in range(itr)] ,[f'h{5-h}' for h in range(5)],[\"mae\", \"mse\", \"rmse\", \"mape\", \"wmse\", \"accr\"]]\n",
    "dep_var=data_names(data_columns(test_set),20)[0]\n",
    "metrics=np.empty((0,len(labels[1]),len(labels[2])))\n",
    "for i in range(itr):\n",
    "  results = []\n",
    "  for h in range(5):\n",
    "    data_parser = {\n",
    "    \"vols\": {\n",
    "        'e_layers':5,\n",
    "        'd_model':512,\n",
    "        'lradj':'type2',\n",
    "        'root_path':mydrive+testData,\n",
    "        \"query\": f\"date>'#{cutdate}' and floor(horizon)=={5-h}\",\n",
    "        'weight':weight[0],\n",
    "        'data_path':tables,    \n",
    "    },\n",
    "    }\n",
    "    setting=update_args(args,data_parser,i)\n",
    "    DatasetMTS.clear()\n",
    "    exp = Exp_crossformer(args)\n",
    "    print(f\">>>>>>>testing : {data_parser['vols']['query']} m{i}h{5-h}<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\")\n",
    "    results.append(exp.test(setting, 'vols', True, inverse=True))\n",
    "  metrics=regplot(dep_var,metrics,4,i)\n",
    "\n",
    "print(metrics)\n",
    "plot_metric(metrics,labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jI4GPCiA8ubA"
   },
   "source": [
    "# end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "45zLIW5xJTza"
   },
   "outputs": [],
   "source": [
    "plt.show()\n",
    "from google.colab import runtime\n",
    "runtime.unassign()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "V100",
   "machine_shape": "hm",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "e1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
