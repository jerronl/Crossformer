{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5KB0_RDrJTzT"
   },
   "source": [
    "# setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JaXYxzifbhst"
   },
   "outputs": [],
   "source": [
    "run_test=True\n",
    "DO_TRAIN_VOLS = True\n",
    "DO_TRAIN_PRCS = True\n",
    "Provisional=True\n",
    "MODE = 'tuning'\n",
    "\n",
    "# run_test=False\n",
    "# DO_TRAIN_VOLS = False   # 是否运行 VOLS 的 VOL_GRID 训练\n",
    "# DO_TRAIN_PRCS = False  # 是否运行 PRCS 的 LMSE x VOL_GRID 交叉训练\n",
    "# Provisional=False\n",
    "MODE = 'prod'\n",
    "\n",
    "'''\n",
    "Provisional\trun_test\tMODE\tVOLS/PRCS 配置\tTables\tTrain itrs\n",
    "TRUE\tTRUE\ttuning\t完整网格→切片前2\t前2个表\tna\n",
    "TRUE\tTRUE\tprod\tBEST配置\t前2个表\trange(itr)\n",
    "TRUE\tFALSE\ttuning\t完整网格→切片前2\t全部\t0\n",
    "TRUE\tFALSE\tprod\tBEST配置\t全部\t0\n",
    "FALSE\tTRUE\ttuning\t完整网格\t全部\tNA\n",
    "FALSE\tTRUE\tprod\tBEST配置\t全部\tNA\n",
    "FALSE\tFALSE\ttuning\t完整网格\t全部\trange(itr)\n",
    "FALSE\tFALSE\tprod\tBEST配置\t全部\trange(itr)\n",
    "'''\n",
    "\n",
    "epochs=(1,1,1,0,12) if Provisional else (15,500,3,0,12)\n",
    "\n",
    "cutdate='2025-11-18'\n",
    "valData=''\n",
    "use_amp=True\n",
    "use_amp=False\n",
    "# valData='2512'\n",
    "testData=''\n",
    "testData='new/'\n",
    "initial_lr = .01\n",
    "\n",
    "weight=(0.81,1.01,0.03,0)\n",
    "itr=3\n",
    "metrics_cnt=6\n",
    "import torch,sys\n",
    "Provisional=Provisional and run_test\n",
    "\n",
    "if 'google.colab' in str(get_ipython()):\n",
    "  from google.colab import drive\n",
    "  drive.mount('/content/drive')\n",
    "  mydrive='/content/drive/MyDrive/volrt/'\n",
    "  checkpoints=mydrive+\"checkpoints/\"\n",
    "  source_path=mydrive+\"git/Crossformer\"\n",
    "  tables = [ 'volvTSLA.csv', 'volvAAPL.csv'] if Provisional else [ 'volvTSLA.csv', 'volvAAPL.csv', 'volvGOOG.csv','volvNVDA.csv', 'volvMETA.csv', 'volvMSFT.csv', 'volvAMZN.csv', ]\n",
    "  batch_size=int(torch.cuda.get_device_properties(0).total_memory/1e9+.5)*25\n",
    "  import os,sys\n",
    "  if not os.path.exists(source_path):\n",
    "    %cd $mydrive/git\n",
    "    !git clone https://github.com/jerronl/Crossformer.git\n",
    "    %cd $source_path\n",
    "  else:\n",
    "    %cd $source_path\n",
    "    # !git reset --hard HEAD\n",
    "    # !git pull origin master\n",
    "  %pip install einops #scikit-learn\n",
    "  sys.path.append( source_path)\n",
    "else:\n",
    "  tables = [ 'volvAAPLt.csv']\n",
    "  use_amp=True\n",
    "  testData=''\n",
    "  mydrive= 'E:/mydoc/git/trade/analyics/'\n",
    "  checkpoints=\"G:/git/Crossformer1/checkpoints/\"\n",
    "  batch_size=32\n",
    "  sys.path.append(\"G:/git/Crossformer1/\")\n",
    "  # itr=1\n",
    "  %load_ext autoreload\n",
    "  %autoreload 2\n",
    "%cd $mydrive\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Funcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import traceback\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "from matplotlib.colors import LogNorm\n",
    "import torch\n",
    "\n",
    "from cross_exp.exp_crossformer import Exp_crossformer\n",
    "from data.data_loader import DatasetMTS, data_columns, data_names\n",
    "from data.data_def import set_cat\n",
    "from utils.tools import init_args, update_args\n",
    "from utils.metrics import metric_names\n",
    "\n",
    "set_cat(20)\n",
    "args = init_args()\n",
    "data_parser = {}\n",
    "\n",
    "COMMON_SETTINGS = {\n",
    "    \"e_layers\": 5,\n",
    "    \"d_model\": 512,\n",
    "    \"lradj\": \"type2\",\n",
    "    \"checkpoints\": checkpoints,\n",
    "}\n",
    "\n",
    "def generate_configs(grid, mode_idx):\n",
    "    active_keys = []\n",
    "    values_lists = []\n",
    "    for key, (vals, in_vols, in_prcs) in grid.items():\n",
    "        is_active = in_vols if mode_idx == 1 else in_prcs\n",
    "        if is_active:\n",
    "            active_keys.append(key)\n",
    "            values_lists.append(vals)\n",
    "    return [dict(zip(active_keys, c)) for c in itertools.product(*values_lists)]\n",
    "\n",
    "def apply_config_override(parser_config: dict, ds: str, config_dict: dict) -> dict:\n",
    "    temp_config = (\n",
    "        parser_config.copy() if ds not in parser_config else parser_config[ds].copy()\n",
    "    )\n",
    "    temp_config.update(config_dict)\n",
    "    \n",
    "    if \"weight_over\" in config_dict and \"over_weight\" not in temp_config:\n",
    "        temp_config[\"over_weight\"] = config_dict[\"weight_over\"]\n",
    "        \n",
    "    if ds not in parser_config:\n",
    "        return temp_config\n",
    "    parser_config[ds] = temp_config\n",
    "    return parser_config\n",
    "\n",
    "def build_parser(mode, ds, extra_query=\"\", root_override=None, config_defaults=None):\n",
    "    root = root_override or mydrive + (valData if mode == \"insample\" else testData)\n",
    "    q = \"\"\n",
    "    if mode == \"oos\":\n",
    "        q = f\"date>'#{cutdate}'\"\n",
    "        if extra_query:\n",
    "            q += \" and \" + extra_query\n",
    "    elif mode == \"insample\":\n",
    "        q = extra_query\n",
    "\n",
    "    idx_w = 0 if ds == 'vols' else 1\n",
    "    idx_ow = 2 if ds == 'vols' else 3\n",
    "    \n",
    "    defaults = config_defaults or {}\n",
    "    \n",
    "    ds_config = {\n",
    "        **COMMON_SETTINGS,\n",
    "        \"root_path\": root,\n",
    "        \"data_path\": tables,\n",
    "        \"data\": ds,\n",
    "        \"weight\": defaults.get(\"weight\", weight[idx_w]),\n",
    "        \"over_weight\": defaults.get(\"weight_over\", weight[idx_ow]), \n",
    "        **defaults\n",
    "    }\n",
    "\n",
    "    if q:\n",
    "        ds_config[\"query\"] = re.sub(r\"^\\s*and\\s+\", \"\", q)\n",
    "\n",
    "    parser = {} if ds == \"vols\" else {\"vols\": {\"checkpoints\": checkpoints}}\n",
    "    parser[ds] = ds_config\n",
    "    return parser\n",
    "\n",
    "def build_train_parser(root_path=None):\n",
    "    base = {\n",
    "        \"patience\": epochs[0],\n",
    "        \"train_epochs\": TRAIN_EPOCHS,\n",
    "        \"learning_rate\": initial_lr,\n",
    "        \"data_split\": [0.7, 0.15, 0.15],\n",
    "        \"batch_size\": batch_size * 2 // 5,\n",
    "        \"e_layers\": 5,\n",
    "        \"d_model\": 512,\n",
    "        \"lradj\": \"type2\",\n",
    "        \"checkpoints\": checkpoints,\n",
    "        \"root_path\": root_path or mydrive + valData,\n",
    "        \"data_path\": tables,\n",
    "        \"profile_mode\": False,\n",
    "        \"use_amp\": use_amp,\n",
    "    }\n",
    "    return {\n",
    "        \"vols\": {**base, \"data\": \"vols\", \"weight\": weight[0], \"over_weight\": weight[2]},\n",
    "        \"prcs\": {**base, \"data\": \"prcs\", \"weight\": weight[1], \"over_weight\": weight[3]},\n",
    "    }\n",
    "\n",
    "def get_feature_names(ds_name, in_len):\n",
    "    cols = data_columns(ds_name)\n",
    "    return data_names(cols, 1)[0]\n",
    "\n",
    "def get_trained_epochs(exp,setting_str, ds,idx):\n",
    "    trained_ep = exp.get_epochs() \n",
    "    if trained_ep != -1:\n",
    "        return trained_ep\n",
    "    \n",
    "    folder_path = os.path.join(checkpoints, setting_str) + ds +cstr(idx)\n",
    "    file_path = os.path.join(folder_path, \"checkpoint.pth\")\n",
    "    if os.path.exists(file_path):\n",
    "        try:\n",
    "            state = torch.load(file_path, weights_only=False)\n",
    "            if isinstance(state, dict) and \"epoch\" in state:\n",
    "                return state[\"epoch\"]\n",
    "        except Exception:\n",
    "            return \"Err\"\n",
    "    return \"Not Fnd\"\n",
    "\n",
    "def prepare_preds_trues_for_plot(preds, trues, ycat=0):\n",
    "    preds, trues = np.asarray(preds), np.asarray(trues)\n",
    "    if ycat > 0:\n",
    "        reg_dim = preds.shape[1] - ycat\n",
    "        min_dim = min(trues.shape[1], reg_dim)\n",
    "        return preds[:, :min_dim], trues[:, :min_dim]\n",
    "    return preds, trues\n",
    "\n",
    "def _metrics_text(t, p):\n",
    "    diff = p - t\n",
    "    metrics = {\n",
    "        \"mae\": np.mean(np.abs(diff)),\n",
    "        \"rmse\": np.sqrt(np.mean(diff**2)),\n",
    "        \"mape\": np.mean(np.abs(diff) / (np.abs(t) + 1e-12))\n",
    "    }\n",
    "    return f\"mae={metrics['mae']:.4g}\\nrmse={metrics['rmse']:.4g}\\nmape={metrics['mape']:.3g}\"\n",
    "\n",
    "def _metrics_text_prcs_ic_iv(t_iv, p_iv, t_ic, p_ic_label):\n",
    "    diff = p_iv - t_iv\n",
    "    mae = np.mean(np.abs(diff))\n",
    "    rmse = np.sqrt(np.mean(diff**2))\n",
    "    mape = np.mean(np.abs(diff) / (np.abs(t_iv) + 1e-12))\n",
    "    \n",
    "    accr = np.nan\n",
    "    valid_mask = ~np.isnan(p_ic_label) & ~np.isnan(t_ic)\n",
    "    if len(t_ic) > 0 and (np.unique(t_ic).size <= 20) and (~np.isnan(t_ic)).sum() > 0:\n",
    "         if np.unique(p_ic_label).size <= 20:\n",
    "            accr = np.mean(p_ic_label.round()[valid_mask] == t_ic.round()[valid_mask])\n",
    "            \n",
    "    base_text = f\"mae(IV)={mae:.4g}\\nrmse(IV)={rmse:.4g}\"\n",
    "    return f\"accr(IC)={accr:.3f}\\n{base_text}\" if not np.isnan(accr) else f\"{base_text}\\nmape(IV)={mape:.3g}\"\n",
    "\n",
    "def _compute_limits_like_old_regplot(trues_list, preds_list, feat_idx, feat_name):\n",
    "    left, right = np.inf, -np.inf\n",
    "    for trues, preds in zip(trues_list, preds_list):\n",
    "        t, p = trues[:, feat_idx], preds[:, feat_idx]\n",
    "        mask = ~np.isnan(t) & ~np.isnan(p)\n",
    "        if not mask.any(): continue\n",
    "        t, p = t[mask], p[mask]\n",
    "        \n",
    "        l_curr, r_curr = (np.min(t), np.max(t)) if feat_name[:3] in [\"dtm\", \"pmc\"] else (max(np.min(t), -5), min(np.max(t), 5))\n",
    "        p_min, p_max = (np.min(p), np.max(p)) if feat_name[:3] in [\"dtm\", \"pmc\"] else (max(np.min(p), -5), min(np.max(p), 5))\n",
    "        \n",
    "        left = min(left, l_curr, p_min)\n",
    "        right = max(right, r_curr, p_max)\n",
    "        \n",
    "    if not np.isfinite(left) or not np.isfinite(right) or left == right:\n",
    "        return -1, 1\n",
    "    return left, right\n",
    "\n",
    "def plot_residual_heatmap_family(preds_raw, trues_raw, feature_names, title, bins=80, ycat=0, cols=4, figsize_per_cell=4):\n",
    "    preds, trues = prepare_preds_trues_for_plot(preds_raw, trues_raw, ycat=ycat)\n",
    "    effective_dim = min(trues.shape[1], len(feature_names))\n",
    "    rows = int(np.ceil(effective_dim / cols))\n",
    "    \n",
    "    fig, axes = plt.subplots(rows, cols, figsize=(figsize_per_cell * cols, figsize_per_cell * rows), squeeze=False, constrained_layout=True)\n",
    "    \n",
    "    for i in range(effective_dim):\n",
    "        ax = axes.flatten()[i]\n",
    "        t, p = trues[:, i], preds[:, i]\n",
    "        mask = ~np.isnan(t) & ~np.isnan(p)\n",
    "        t, p = t[mask], p[mask]\n",
    "        \n",
    "        if len(t) == 0:\n",
    "            ax.set_title(feature_names[i])\n",
    "            ax.axis(\"off\")\n",
    "            continue\n",
    "            \n",
    "        metrics_text = _metrics_text_prcs_ic_iv(t, p, t, preds[mask, 4]) if (ycat > 0 and i == 0) else _metrics_text(t, p)\n",
    "        left, right = _compute_limits_like_old_regplot([trues_raw], [preds_raw], i, feature_names[i])\n",
    "        \n",
    "        ax.hist2d(t, p, bins=bins, range=[[left, right], [left, right]], norm=\"log\")\n",
    "        ax.plot([left, right], [left, right], \"w--\", alpha=0.45)\n",
    "        ax.set_xlim(left, right); ax.set_ylim(left, right)\n",
    "        ax.set_title(feature_names[i], fontsize=12)\n",
    "        ax.text(0.02, 0.98, metrics_text, transform=ax.transAxes, va=\"top\", ha=\"left\", fontsize=9,\n",
    "                bbox=dict(boxstyle=\"round,pad=0.25\", fc=\"black\", ec=\"none\", alpha=0.35), color=\"white\", zorder=3)\n",
    "                \n",
    "    for i in range(effective_dim, rows * cols): axes.flatten()[i].axis(\"off\")\n",
    "    if title: fig.suptitle(title, fontsize=14)\n",
    "    plt.show(); plt.close(fig)\n",
    "\n",
    "def _get_plot_config(all_preds_raw, feature_names, cols):\n",
    "    if not all_preds_raw or not all_preds_raw[0].shape[1]: return None\n",
    "    effective_dim = min(all_preds_raw[0].shape[1], len(feature_names))\n",
    "    if len(feature_names) < effective_dim:\n",
    "        feature_names += [f\"F{i}\" for i in range(len(feature_names), effective_dim)]\n",
    "    \n",
    "    return {\n",
    "        \"effective_dim\": effective_dim,\n",
    "        \"feature_names\": feature_names[:effective_dim],\n",
    "        \"rows\": (effective_dim + cols - 1) // cols,\n",
    "        \"colors_errors\": plt.rcParams[\"axes.prop_cycle\"].by_key().get(\"color\", [f\"C{i}\" for i in range(10)]),\n",
    "        \"colors_residuals\": [\"#1f77b4\", \"#ff7f0e\", \"#2ca02c\", \"#d62728\", \"#9467bd\", \"#8c564b\", \"#e377c2\", \"#7f7f7f\", \"#bcbd22\", \"#17becf\"] # truncated for brevity\n",
    "    }\n",
    "\n",
    "def plot_multi_stock_errors(all_preds_raw, all_trues_raw, stock_labels, feature_names, title=\"\", cols=4, figsize_per_cell=4, config=None):\n",
    "    config = config or _get_plot_config(all_preds_raw, feature_names, cols)\n",
    "    if not config: return\n",
    "\n",
    "    rows = config[\"rows\"]\n",
    "    fig = plt.figure(figsize=(cols * figsize_per_cell, rows * figsize_per_cell))\n",
    "    outer = gridspec.GridSpec(rows, cols, wspace=0.25, hspace=0.4)\n",
    "\n",
    "    for i in range(config[\"effective_dim\"]):\n",
    "        ax = fig.add_subplot(outer[divmod(i, cols)])\n",
    "        t_all, e_all = [], []\n",
    "        \n",
    "        for j, (p_reg, t_reg) in enumerate(zip(all_preds_raw, all_trues_raw)):\n",
    "            t, p = t_reg[:, i], p_reg[:, i]\n",
    "            mask = ~np.isnan(t) & ~np.isnan(p)\n",
    "            if not mask.any(): continue\n",
    "            t, p = t[mask], p[mask]\n",
    "            e = p - t\n",
    "            t_all.append(t); e_all.append(e)\n",
    "            ax.scatter(t, e, s=4, alpha=0.4, color=config[\"colors_errors\"][j % len(config[\"colors_errors\"])], label=stock_labels[j] if i == 0 else None)\n",
    "\n",
    "        if not t_all:\n",
    "             ax.set_title(config[\"feature_names\"][i]); ax.axis(\"off\"); continue\n",
    "             \n",
    "        t_all, e_all = np.concatenate(t_all), np.concatenate(e_all)\n",
    "        ax.axhline(0.0, color=\"k\", linestyle=\"--\", linewidth=0.8, alpha=0.7)\n",
    "        \n",
    "        if np.unique(t_all).size > 1:\n",
    "             m, c = np.polyfit(t_all, e_all, 1)\n",
    "             ax.plot([t_all.min(), t_all.max()], m * np.array([t_all.min(), t_all.max()]) + c, \"-.\", lw=1.0, color=\"tab:orange\")\n",
    "\n",
    "        rmse, mae = np.sqrt(np.mean(e_all**2)), np.mean(np.abs(e_all))\n",
    "        metrics = f\"RMSE: {rmse:.4g}\\nMAE: {mae:.4g}\"\n",
    "        ax.text(0.03, 0.97, metrics, transform=ax.transAxes, fontsize=8, va=\"top\", bbox=dict(boxstyle=\"round\", facecolor=\"white\", alpha=0.8))\n",
    "        ax.set_title(config[\"feature_names\"][i], fontsize=10)\n",
    "        if i == 0: ax.legend(fontsize=7, loc=\"lower right\")\n",
    "\n",
    "    if title: fig.suptitle(title, fontsize=14, y=0.99)\n",
    "    plt.show()\n",
    "\n",
    "def plot_multi_stock_residuals(all_preds_raw, all_trues_raw, stock_labels, feature_names, ycat=0, title=\"\", bins=80, cols=4, figsize_per_cell=4):\n",
    "    config = _get_plot_config(all_preds_raw, feature_names, cols)\n",
    "    if not config: return\n",
    "\n",
    "    rows = config[\"rows\"]\n",
    "    fig = plt.figure(figsize=(cols * figsize_per_cell, rows * figsize_per_cell))\n",
    "    outer = gridspec.GridSpec(rows, cols, wspace=0.25, hspace=0.4)\n",
    "\n",
    "    for i in range(config[\"effective_dim\"]):\n",
    "        ax = fig.add_subplot(outer[divmod(i, cols)])\n",
    "        ax_hist = ax.twinx()\n",
    "        left, right = 999, -999\n",
    "        \n",
    "        for j, (p_reg, t_reg) in enumerate(zip(all_preds_raw, all_trues_raw)):\n",
    "            t, p = t_reg[:, i], p_reg[:, i]\n",
    "            mask = ~np.isnan(t) & ~np.isnan(p)\n",
    "            if not mask.any(): continue\n",
    "            t, p = t[mask], p[mask]\n",
    "            \n",
    "            color = config[\"colors_residuals\"][j % len(config[\"colors_residuals\"])]\n",
    "            ax_hist.hist(t, bins=bins, density=True, alpha=0.15, color=color)\n",
    "            ax.scatter(t, p, s=0.5, alpha=0.4, color=color)\n",
    "            \n",
    "            l_curr, r_curr = (np.min(t), np.max(t)) if feature_names[i][:3] in [\"dtm\", \"pmc\"] else (max(np.min(t), -5), min(np.max(t), 5))\n",
    "            left, right = min(left, l_curr), max(right, r_curr)\n",
    "            \n",
    "            try:\n",
    "                m, c = np.polyfit(t, p, 1)\n",
    "                ax.plot([t.min(), t.max()], m * np.array([t.min(), t.max()]) + c, \"--\", color=color, lw=1.5, alpha=0.4, label=stock_labels[j])\n",
    "            except: pass\n",
    "\n",
    "        ax.set_xlim(left, right); ax.set_ylim(left, right)\n",
    "        ax_hist.axis(\"off\")\n",
    "        ax.set_title(config[\"feature_names\"][i], y=1.01, fontsize=11)\n",
    "        ax.legend(fontsize=8, loc=\"best\")\n",
    "        \n",
    "        # Global Metrics for this feature\n",
    "        all_t = np.concatenate([t[:, i] for t in all_trues_raw if t.shape[1] > i])\n",
    "        all_p = np.concatenate([p[:, i] for p in all_preds_raw if p.shape[1] > i])\n",
    "        mask = ~np.isnan(all_t) & ~np.isnan(all_p)\n",
    "        if mask.any():\n",
    "             metrics = f\"RMSE: {np.sqrt(np.mean((all_t[mask]-all_p[mask])**2)):.4f}\\nMAE: {np.mean(np.abs(all_t[mask]-all_p[mask])):.4f}\"\n",
    "             ax.text(0.05, 0.95, metrics, transform=ax.transAxes, fontsize=9, va=\"top\", bbox=dict(boxstyle=\"round\", fc=\"white\", alpha=0.85))\n",
    "\n",
    "    if title: fig.suptitle(title, fontsize=14, y=0.99)\n",
    "    plt.show(); \n",
    "    \n",
    "    if all_preds_raw:\n",
    "        plot_multi_stock_errors(all_preds_raw, all_trues_raw, stock_labels, feature_names, title=f\"{title} - Prediction Errors\", cols=cols, figsize_per_cell=figsize_per_cell, config=config)\n",
    "\n",
    "def plot_prcs_distribution_detailed(results_list, model_idx, ycat, dep_var, tables_list, cols=4, title_prefix=\"PRCS Distribution\"):\n",
    "    if not results_list or ycat == 0: return\n",
    "    \n",
    "    outer_rows = (len(results_list) - 1) // cols + 1\n",
    "    fig = plt.figure(figsize=(16, 4 * outer_rows))\n",
    "    outer = gridspec.GridSpec(outer_rows, cols, wspace=0.3, hspace=0.45)\n",
    "    \n",
    "    print(f\"\\n--- Plotting {title_prefix} for Model m{model_idx} ---\")\n",
    "    for j, (preds, trues, _) in enumerate(results_list):\n",
    "        probs, labels = np.asarray(preds)[:, -ycat:], np.round(np.asarray(trues)[:, 0]).astype(int)\n",
    "        mask = (~np.isnan(labels)) & (labels >= 1) & (labels <= ycat)\n",
    "        if not mask.any(): continue\n",
    "        \n",
    "        probs, labels = probs[mask], labels[mask]\n",
    "        if probs.size > 0 and (probs.max() > 1.05 or probs.min() < -0.05): # Softmax if raw logits\n",
    "             probs = np.exp(probs - probs.max(1, keepdims=True)) / np.exp(probs - probs.max(1, keepdims=True)).sum(1, keepdims=True)\n",
    "             \n",
    "        df = pd.DataFrame(probs, columns=[str(i) for i in range(1, ycat + 1)]).assign(True_Label=labels)\n",
    "        summed = df.groupby(\"True_Label\").mean().T\n",
    "        \n",
    "        sub_gs = outer[j // cols, j % cols].subgridspec(2, 1, hspace=0.0)\n",
    "        for k in (0, 1):\n",
    "            ax = fig.add_subplot(sub_gs[k, 0])\n",
    "            ax.hist(labels, bins=np.arange(1, ycat + 2) - 0.5, alpha=0.2, density=True, color=\"gray\", label=\"True\")\n",
    "            \n",
    "            for i, col in enumerate(sorted([c for c in summed.columns if 1 <= c <= ycat])):\n",
    "                if i % 2 != k: continue \n",
    "                ax.plot([int(x) for x in summed.index], summed[col], label=f\"cat {col}\", alpha=0.7)\n",
    "                ax.text(col, summed[col][str(col)], f\"{col}\", fontsize=8, va=\"bottom\", ha=\"center\")\n",
    "                \n",
    "            ax.set_ylim(0, 0.2); ax.set_xlim(0.5, ycat + 1.5)\n",
    "            if k == 0: ax.set_title(tables_list[j], fontsize=10); ax.set_xticks([])\n",
    "            else: ax.set_xlabel(\"Pred Class\"); ax.set_xticks(np.arange(1, ycat+1))\n",
    "            ax.grid(axis=\"y\", linestyle=\"--\", alpha=0.3)\n",
    "            \n",
    "    fig.suptitle(f\"{title_prefix} - Model m{model_idx}\", fontsize=14)\n",
    "    plt.tight_layout(rect=[0, 0.03, 1, 0.97]); plt.show(); plt.close()\n",
    "\n",
    "def generate_final_summary(summary_records):\n",
    "    if not summary_records: return\n",
    "    df = pd.DataFrame(summary_records)\n",
    "    meta = [c for c in [\"dataset\", \"idx\", \"horizon\", \"epochs\"] if c in df]\n",
    "    metrics = sorted([c for c in df.columns if c in set(metric_names[0] + metric_names[1])])\n",
    "    params = sorted([c for c in df.columns if c not in meta + metrics])\n",
    "    print(df[meta + params + metrics].to_string(float_format=lambda x: f\"{x:.4g}\" if isinstance(x, (float, int)) else str(x)))\n",
    "\n",
    "def _init_exp_and_setting(parser_config: dict, ds: str, itr_idx: int = 0):\n",
    "    args = init_args()\n",
    "    return args, update_args(args, parser_config, itr=itr_idx, arg_set=ds), Exp_crossformer(args)\n",
    "\n",
    "def run_test_one_setting(exp, setting_str, ds, dep_var, ycat, title_prefix, by_stock=False, stock_tables=None, plot_individual_heatmaps=True, test_data=None, itr_idx=0):\n",
    "    m_list, all_p, all_t = [], [], []\n",
    "    ds_tag = ds + str(itr_idx)\n",
    "    \n",
    "    def _plot(p, t, title):\n",
    "        if plot_individual_heatmaps:\n",
    "            print(f\"\\n--- Residual Heatmap: {title} ---\")\n",
    "            plot_residual_heatmap_family(p, t, dep_var, title=title, ycat=ycat)\n",
    "\n",
    "    if by_stock:\n",
    "        for tb in stock_tables:\n",
    "            p, t, m = exp.test(setting_str, ds_tag, True, data_path=[tb], inverse=True)\n",
    "            m_list.append(m); all_p.append(p); all_t.append(t)\n",
    "            _plot(p, t, f\"{title_prefix} {tb}\")\n",
    "        return m_list, all_p, all_t\n",
    "\n",
    "    p, t, m = exp.test(setting_str, ds_tag, True, inverse=True, test_data=test_data)\n",
    "    _plot(p, t, title_prefix)\n",
    "    return [m], ([p] if test_data else [p]), ([t] if test_data else [t])\n",
    "\n",
    "def train_unified_all():\n",
    "    global args, UNIFIED_CONFIGS, active_grid_indices, DO_TRAIN_VOLS, DO_TRAIN_PRCS\n",
    "    base_parser = build_train_parser()\n",
    "    \n",
    "    print(f\"\\n=== Unified Training (Mode: {MODE}, Active: {len(active_grid_indices)}) ===\")\n",
    "    for idx in active_grid_indices:\n",
    "        if idx >= len(UNIFIED_CONFIGS): break\n",
    "        cfg = UNIFIED_CONFIGS[idx].copy()\n",
    "        ds, itr_idx = cfg.pop(\"target_ds\"), cfg.pop(\"itr_idx\", 0)\n",
    "\n",
    "        if (ds == \"vols\" and not DO_TRAIN_VOLS) or (ds == \"prcs\" and not DO_TRAIN_PRCS): continue\n",
    "        \n",
    "        DatasetMTS.clear()\n",
    "        curr_parser = {k: v.copy() for k, v in base_parser.items()}\n",
    "        curr_parser[ds] = apply_config_override(curr_parser[ds], ds, cfg)\n",
    "        \n",
    "        # Training Cycles\n",
    "        start_lr = curr_parser[ds][\"learning_rate\"]\n",
    "        for cycle in range(epochs[2]):\n",
    "            curr_parser[ds][\"learning_rate\"] = start_lr / (3.0**cycle)\n",
    "            args, setting, exp = _init_exp_and_setting(curr_parser, ds, itr_idx)\n",
    "            \n",
    "            print(f\"\\n[Idx {idx}|Itr {itr_idx}|{ds.upper()}|Cyc {cycle+1}] LR={curr_parser[ds]['learning_rate']:.6f} | {setting}\")\n",
    "            try:\n",
    "                exp.train(setting, ds + str(itr_idx))\n",
    "                if MODE == \"prod\": exp.test(setting, ds + str(itr_idx), True, data_path=[tables[-1]], inverse=True)\n",
    "            except Exception as e:\n",
    "                print(f\"--- FAILED Idx {idx} --- {e}\"); traceback.print_exc()\n",
    "\n",
    "def test_unified(mode: str, target_ds: str, by_stock=True, plot_residuals=True, plot_stock=False):\n",
    "    global args, UNIFIED_CONFIGS, active_grid_indices, tables\n",
    "    summary = []\n",
    "    \n",
    "    indices = [i for i in active_grid_indices if i < len(UNIFIED_CONFIGS) and UNIFIED_CONFIGS[i][\"target_ds\"] == target_ds]\n",
    "    if not indices: return print(f\"No configs for {target_ds}\")\n",
    "    \n",
    "    print(f\"\\n=== Testing {target_ds.upper()} ({mode}) - {len(indices)} configs ===\")\n",
    "    for idx in indices:\n",
    "        cfg = UNIFIED_CONFIGS[idx].copy()\n",
    "        ds, itr_idx = cfg.pop(\"target_ds\"), cfg.pop(\"itr_idx\", 0)\n",
    "        ycat = data_columns(ds).get(\"ycat\", 0) if ds == \"prcs\" else 0\n",
    "        \n",
    "        base_parser = build_parser(mode, ds)\n",
    "        base_parser[ds] = apply_config_override(base_parser[ds], ds, cfg)\n",
    "        \n",
    "        args, setting, exp = _init_exp_and_setting(base_parser, ds, itr_idx)\n",
    "        trained_ep = get_trained_epochs(exp,setting, ds,itr_idx)\n",
    "        \n",
    "        # if trained_ep == \"Not Fnd\": print(f\"Skipping {setting}, model not found\"); continue\n",
    "        \n",
    "        try:\n",
    "            dep_var = get_feature_names(ds, getattr(args, \"seq_len\", 1))\n",
    "            title = f\"{ds.upper()} {mode} [Idx {idx}|Itr {itr_idx}]\"\n",
    "            \n",
    "            m_list, p_fam, t_fam = run_test_one_setting(exp, setting, ds, dep_var, ycat, title, by_stock, tables, plot_stock, itr_idx=itr_idx)\n",
    "            \n",
    "            if by_stock and p_fam and plot_residuals:\n",
    "                print(f\"\\n--- AGGREGATED: {title} ---\")\n",
    "                plot_multi_stock_residuals(p_fam, t_fam, tables, dep_var, ycat, title=f\"AGG {title}\")\n",
    "                if ds == \"prcs\" and ycat > 0:\n",
    "                     plot_prcs_distribution_detailed(list(zip(p_fam, t_fam, m_list)), idx, ycat, dep_var, tables, title_prefix=f\"AGG {title}\")\n",
    "            \n",
    "            summary.append({\"dataset\": ds, \"idx\": idx, \"itr\": itr_idx, \"epochs\": trained_ep, **cfg, **dict(zip(metric_names[1 if ycat > 0 else 0], np.mean(m_list, axis=0)))})\n",
    "            \n",
    "        except Exception as e: print(f\"--- FAILED Test Idx {idx} --- {e}\"); traceback.print_exc()\n",
    "\n",
    "    generate_final_summary(summary)\n",
    "    if len(summary) > 1: print(\"\\n--- Metrics Summary ---\"); plot_metric_summary(summary)\n",
    "    return summary\n",
    "\n",
    "def test_vols_per_horizon(mode=\"insample\", plot_residuals=True, best_idx=-1):\n",
    "    global args, UNIFIED_CONFIGS, tables\n",
    "    summary, ds, horizons = [], \"vols\", [1, 2, 3, 4, 5]\n",
    "    \n",
    "    indices = [i for i in active_grid_indices if i < len(UNIFIED_CONFIGS) and UNIFIED_CONFIGS[i][\"target_ds\"] == ds]\n",
    "    if best_idx != -1 and best_idx in range(len(UNIFIED_CONFIGS)): indices = [best_idx]\n",
    "    if not indices: return\n",
    "\n",
    "    print(f\"\\n--- VOLS Horizon Test ({len(indices)} configs) ---\")\n",
    "    for idx in indices:\n",
    "        cfg = UNIFIED_CONFIGS[idx].copy()\n",
    "        ds, itr_idx = cfg.pop(\"target_ds\"), cfg.pop(\"itr_idx\", 0)\n",
    "        \n",
    "        base_parser = build_parser(mode, ds)\n",
    "        parser_load = base_parser.copy(); parser_load[ds] = apply_config_override(parser_load[ds], ds, cfg)\n",
    "        \n",
    "        args, setting, exp = _init_exp_and_setting(parser_load, ds, itr_idx)\n",
    "        trained_ep = get_trained_epochs(exp,setting, ds,itr_idx)\n",
    "        # if trained_ep == \"Not Fnd\": continue\n",
    "\n",
    "        dep_var, orig_q = get_feature_names(ds, getattr(args, \"seq_len\", 1)), exp.args.query\n",
    "        h_preds, h_trues, h_names = [], [], []\n",
    "\n",
    "        for h in horizons:\n",
    "            exp.args.query = build_parser(mode, ds, extra_query=f\"floor(horizon)=={h}\")[ds].get(\"query\", \"\")\n",
    "            try:\n",
    "                dataset, loader = exp._get_data(flag=\"test\", data=ds)\n",
    "                m_list, p, t = run_test_one_setting(exp, setting, ds, dep_var, 0, \"\", False, None, False, (dataset, loader), itr_idx)\n",
    "                \n",
    "                if m_list:\n",
    "                     summary.append({\"dataset\": ds, \"idx\": idx, \"itr\": itr_idx, \"horizon\": h, \"epochs\": trained_ep, **cfg, **dict(zip(metric_names[0], m_list[0]))})\n",
    "                     h_preds.append(p[0]); h_trues.append(t[0]); h_names.append(f\"H {h}\")\n",
    "            except: pass\n",
    "            \n",
    "        exp.args.query = orig_q\n",
    "        if plot_residuals and h_preds:\n",
    "             plot_multi_stock_residuals(h_preds, h_trues, h_names, dep_var, 0, title=f\"VOLS Horizons [Idx {idx}]\")\n",
    "\n",
    "    generate_final_summary(summary); plot_metric_summary(summary)\n",
    "    return summary\n",
    "\n",
    "def plot_metric_summary(records):\n",
    "    if not records: return\n",
    "    df = pd.DataFrame(records)\n",
    "    metrics = [m for m in metric_names[0] + metric_names[1] if m in df.columns]\n",
    "    \n",
    "    rows = (len(metrics) + 1) // 2\n",
    "    fig, axes = plt.subplots(rows, 2, figsize=(15, 5 * rows))\n",
    "    for i, m in enumerate(metrics):\n",
    "        ax = axes.flatten()[i]\n",
    "        if \"horizon\" in df:\n",
    "            for idx in df[\"idx\"].unique():\n",
    "                sub = df[df[\"idx\"] == idx].sort_values(\"horizon\")\n",
    "                ax.plot(sub[\"horizon\"], sub[m], \"o-\", label=f\"Cfg {idx}\")\n",
    "            ax.legend()\n",
    "        else:\n",
    "            ax.plot(df[\"idx\"], df[m], \"o-\")\n",
    "        ax.set_title(m.upper()); ax.grid(True, linestyle=\"--\", alpha=0.5)\n",
    "    plt.tight_layout(); plt.show(); plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-bmjLRHTfVt-"
   },
   "source": [
    "# Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mJovfe3GfVt-"
   },
   "outputs": [],
   "source": [
    "PARAM_GRID_VOLS = {\n",
    "    \"lambda_var\":  ([0.00050, 0.00055, 0.00060], True, True),\n",
    "    \"gain_reg\":    ([1.5, 2.0], True, True),\n",
    "    \"weight_over\": ([1.4, 1.5, 1.6], True, True),\n",
    "\n",
    "    # 固定的最优值，不再扫描\n",
    "    \"lambda_tail\": ([0.0], False, True),\n",
    "    \"lambda_anti\": ([0.1], False, True),\n",
    "    \"dist_alpha\":  ([1.0], False, True),\n",
    "    \"lambda_dist\": ([0.0], False, True),\n",
    "}\n",
    "\n",
    "PARAM_GRID_PRCS = {\n",
    "    # 围绕 0.0004 做轻微上下微调\n",
    "    \"lambda_var\":  ([0.00035, 0.00040, 0.00045], False, True),\n",
    "\n",
    "    # gain_reg 只看 0.8 / 1.0 / 1.2，都是“正常有梯度”的范围\n",
    "    \"gain_reg\":    ([0.8, 1.0, 1.2],             False, True),\n",
    "\n",
    "    # weight_over：基准 1.2，再看看 1.0 会不会稍微放松一点\n",
    "    \"weight_over\": ([1.0, 1.2],                  False, True),\n",
    "\n",
    "    # 这一轮先严格完全兼容老版：这些都锁死为 0\n",
    "    \"lambda_tail\": ([0.0],                       False, True),\n",
    "    \"lambda_anti\": ([0.0],                       False, True),\n",
    "    \"lambda_dist\": ([0.0],                       False, True),\n",
    "\n",
    "    # 老 baseline 用的是分类 + 回归等权\n",
    "    \"lambda_mse\":  ([1.0],                       False, True),\n",
    "\n",
    "    # 先固定为 1.0（和之前老跑法一致），下一轮再单独扫 dist_alpha\n",
    "    \"dist_alpha\":  ([1.0],                       False, True),\n",
    "}\n",
    "\n",
    "vols_configs_raw = []\n",
    "prcs_configs_raw = [\n",
    "    {\"dist_alpha\": 1.0, \"gain_reg\": 1.12, \"lambda_var\": 0.0004, \"weight_over\": 1.0},\n",
    "    {\"dist_alpha\": 1.0, \"gain_reg\": 1.18, \"lambda_var\": 0.0004, \"weight_over\": 1.0},\n",
    "    {\"dist_alpha\": 1.0, \"gain_reg\": 1.15, \"lambda_var\": 0.0004, \"weight_over\": 0.95},\n",
    "    {\"dist_alpha\": 1.0, \"gain_reg\": 1.15, \"lambda_var\": 0.0004, \"weight_over\": 1.05},\n",
    "    {\"dist_alpha\": 1.1, \"gain_reg\": 1.15, \"lambda_var\": 0.0004, \"weight_over\": 1.0},\n",
    "    {\"dist_alpha\": 1.1, \"gain_reg\": 1.12, \"lambda_var\": 0.0004, \"weight_over\": 0.95},\n",
    "    {\"dist_alpha\": 1.1, \"gain_reg\": 1.12, \"lambda_var\": 0.0004, \"weight_over\": 1.05},\n",
    "    {\"dist_alpha\": 1.1, \"gain_reg\": 1.18, \"lambda_var\": 0.0004, \"weight_over\": 1.0},\n",
    "    # A Group\n",
    "    {\"dist_alpha\": 1.15, \"gain_reg\": 1.15, \"lambda_var\": 0.0004, \"weight_over\": 1.0},\n",
    "    {\"dist_alpha\": 1.2,  \"gain_reg\": 1.15, \"lambda_var\": 0.0004, \"weight_over\": 1.0},\n",
    "    # B Group\n",
    "    {\"dist_alpha\": 1.0, \"gain_reg\": 1.15, \"lambda_var\": 0.0004, \"weight_over\": 1.02},\n",
    "    {\"dist_alpha\": 1.0, \"gain_reg\": 1.15, \"lambda_var\": 0.0004, \"weight_over\": 1.08},\n",
    "    # C Group\n",
    "    {\"dist_alpha\": 1.1,  \"gain_reg\": 1.15, \"lambda_var\": 0.0004, \"weight_over\": 1.02},\n",
    "    {\"dist_alpha\": 1.15, \"gain_reg\": 1.15, \"lambda_var\": 0.0004, \"weight_over\": 1.08},\n",
    "    # EMD Group\n",
    "    {\"dist_alpha\": 1.0, \"gain_reg\": 1.12, \"lambda_emd\": 0.001, \"weight_over\": 1.0},\n",
    "    {\"dist_alpha\": 1.0, \"gain_reg\": 1.18, \"lambda_emd\": 0.001, \"weight_over\": 1.0},\n",
    "    {\"dist_alpha\": 1.0, \"gain_reg\": 1.15, \"lambda_emd\": 0.001, \"weight_over\": 0.95},\n",
    "    {\"dist_alpha\": 1.0, \"gain_reg\": 1.15, \"lambda_emd\": 0.001, \"weight_over\": 1.05},\n",
    "    {\"dist_alpha\": 1.1, \"gain_reg\": 1.15, \"lambda_emd\": 0.001, \"weight_over\": 1.0},\n",
    "]\n",
    "\n",
    "\n",
    "BEST_VOLS = {\"lambda_var\": 0.0005, \"gain_reg\": 1.5, \"weight_over\": 1.4, \"lambda_anti\": 0.1, \"dist_alpha\": 1.0}\n",
    "BEST_PRCS = {\"dist_alpha\": 1.1, \"gain_reg\": 1.18, \"lambda_mse\": 1.0, \"lambda_var\": 0.0004, \"weight_over\": 1.0}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ESF8ae6wWyUS"
   },
   "outputs": [],
   "source": [
    "\n",
    "if MODE == \"prod\":\n",
    "    vols_configs_raw = [BEST_VOLS] if DO_TRAIN_VOLS else []\n",
    "    prcs_configs_raw = [BEST_PRCS] if DO_TRAIN_PRCS else []\n",
    "else:\n",
    "    if DO_TRAIN_VOLS and not vols_configs_raw: vols_configs_raw = generate_configs(PARAM_GRID_VOLS, 1)\n",
    "    if DO_TRAIN_PRCS and not prcs_configs_raw: prcs_configs_raw = generate_configs(PARAM_GRID_PRCS, 2)\n",
    "\n",
    "\n",
    "train_itr_list = [0] if Provisional else list(range(itr))\n",
    "\n",
    "defaults_map = {\n",
    "    \"vols\": {\"weight\": weight[0], \"weight_over\": weight[2]},\n",
    "    \"prcs\": {\"weight\": weight[1], \"weight_over\": weight[3]}\n",
    "}\n",
    "\n",
    "loop_itrs = train_itr_list\n",
    "\n",
    "UNIFIED_CONFIGS = []\n",
    "for ds, configs in [(\"vols\", vols_configs_raw), (\"prcs\", prcs_configs_raw)]:\n",
    "    defaults = defaults_map[ds]\n",
    "    for cfg in configs:\n",
    "        full_cfg = {**defaults, **cfg} \n",
    "        \n",
    "        \n",
    "        for itr_idx in loop_itrs:\n",
    "            UNIFIED_CONFIGS.append({**full_cfg, \"target_ds\": ds, \"itr_idx\": itr_idx})\n",
    "\n",
    "# Provisional Filter\n",
    "if Provisional and MODE == \"tuning\":\n",
    "    v_cnt = len(vols_configs_raw) * len(loop_itrs)\n",
    "    p_cnt = len(prcs_configs_raw) * len(loop_itrs)\n",
    "    UNIFIED_CONFIGS = (UNIFIED_CONFIGS[:min(2, v_cnt)] if v_cnt else []) + \\\n",
    "                      (UNIFIED_CONFIGS[v_cnt:v_cnt+min(2, p_cnt)] if p_cnt else [])\n",
    "\n",
    "# Active Range Calculation\n",
    "TRAIN_EPOCHS = min(30, epochs[1]) if MODE == \"tuning\" else epochs[1]\n",
    "total = len(UNIFIED_CONFIGS)\n",
    "start, end = epochs[3], min(epochs[3] + epochs[4], total)\n",
    "active_grid_indices = [0] + list(range(start, end)) if (epochs[0] < 2 and start > 0) else list(range(start, end))\n",
    "\n",
    "print(f\"\\n{'='*80}\\nConfig Summary: Total={total}, Active={len(active_grid_indices)}, Epochs={TRAIN_EPOCHS}\")\n",
    "print(f\"  Mode={MODE}, Test={run_test}, Provisional={Provisional}\")\n",
    "print(f\"{'='*80}\")\n",
    "for i in active_grid_indices[:5]:\n",
    "    if i < total:\n",
    "        c = UNIFIED_CONFIGS[i]\n",
    "        p_str = \", \".join([f\"{k}={v:.4g}\" if isinstance(v, float) else f\"{k}={v}\" for k, v in c.items() if k not in [\"target_ds\", \"itr_idx\"]])\n",
    "        print(f\"  [{i}] {c['target_ds'].upper()}|itr{c['itr_idx']}: {p_str}\")\n",
    "print(f\"{'='*80}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qCfd-gU7JTzW"
   },
   "source": [
    "# train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "edfP8114fVuB"
   },
   "outputs": [],
   "source": [
    "if run_test == False:\n",
    "        train_unified_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4kj_rRG1J66H"
   },
   "outputs": [],
   "source": [
    "if not run_test:\n",
    "    from google.colab import runtime\n",
    "    runtime.unassign()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "066vGmCNJTzY"
   },
   "source": [
    "# test\n",
    "##  PART A — In-sample (test split of same source)\n",
    "Subparts:\n",
    "1. vols per-stock heatmap  \n",
    "2. prcs per-stock heatmap + avg prob by true class  \n",
    "3. vols per-horizon heatmap\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "w03KqC8jJTzY"
   },
   "outputs": [],
   "source": [
    "if run_test:\n",
    "            test_unified(\"insample\", \"vols\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wkGkKgp98ua9"
   },
   "source": [
    "## In-sample - Prcs Per-Stock\n",
    "\n",
    "Subparts:\n",
    "1. vols per-stock heatmap  \n",
    "2. prcs per-stock heatmap + avg prob by true class  \n",
    "3. vols per-horizon heatmap\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JKW9afa-cENf"
   },
   "outputs": [],
   "source": [
    "if run_test:\n",
    "\n",
    "           test_unified(\"insample\", \"prcs\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L9IXNP9K8ua-"
   },
   "source": [
    "## In-sample - Horizon\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rpzR-1aN8ua-"
   },
   "outputs": [],
   "source": [
    "if run_test:\n",
    "        test_vols_per_horizon(mode=\"insample\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KBfRZp9y8ua-"
   },
   "source": [
    "# PART B — Out-of-sample (testData, cutdate+)\n",
    "## OOS - Vols Per-Stock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "F6WWmBSmcENg"
   },
   "outputs": [],
   "source": [
    "if run_test:\n",
    "\n",
    "        test_unified(\"oos\", \"vols\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rWJgEQeu8ua_"
   },
   "source": [
    "## hlc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FFlVJgjocENh"
   },
   "outputs": [],
   "source": [
    "if run_test:\n",
    "        test_unified(\"oos\", \"prcs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ff1dksSt8ubA"
   },
   "source": [
    "## horizon\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VPL62tkj8ubA"
   },
   "outputs": [],
   "source": [
    "if run_test:\n",
    "\n",
    "        test_vols_per_horizon(mode=\"oos\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jI4GPCiA8ubA"
   },
   "source": [
    "# end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "45zLIW5xJTza"
   },
   "outputs": [],
   "source": [
    "plt.show()\n",
    "from google.colab import runtime\n",
    "runtime.unassign()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "L4",
   "machine_shape": "hm",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "s1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
