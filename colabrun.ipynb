{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5KB0_RDrJTzT"
   },
   "source": [
    "# setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JaXYxzifbhst"
   },
   "outputs": [],
   "source": [
    "run_test=True\n",
    "DO_TRAIN_VOLS = True\n",
    "DO_TRAIN_PRCS = True\n",
    "Provisional=True\n",
    "MODE = 'tuning'\n",
    "\n",
    "# run_test=False\n",
    "DO_TRAIN_VOLS = False   # 是否运行 VOLS 的 VOL_GRID 训练\n",
    "# DO_TRAIN_PRCS = False  # 是否运行 PRCS 的 LMSE x VOL_GRID 交叉训练\n",
    "# Provisional=False\n",
    "# MODE = 'prod'\n",
    "\n",
    "\n",
    "epochs=(1,1,1,0,9) if Provisional else (15,500,3,0,9)\n",
    "\n",
    "cutdate='2025-11-18'\n",
    "valData=''\n",
    "use_amp=True\n",
    "use_amp=False\n",
    "# valData='2512'\n",
    "testData=''\n",
    "testData='new/'\n",
    "\n",
    "weight=(0.81,1.01,0.03,0)\n",
    "itr=5\n",
    "metrics_cnt=6\n",
    "import torch,sys\n",
    "\n",
    "if 'google.colab' in str(get_ipython()):\n",
    "  from google.colab import drive\n",
    "  drive.mount('/content/drive')\n",
    "  mydrive='/content/drive/MyDrive/volrt/'\n",
    "  checkpoints=mydrive+\"checkpoints/\"\n",
    "  source_path=mydrive+\"git/Crossformer\"\n",
    "  Provisional=Provisional and run_test\n",
    "  tables = [ 'volvTSLA.csv', 'volvAAPL.csv'] if Provisional else [ 'volvTSLA.csv', 'volvAAPL.csv', 'volvGOOG.csv','volvNVDA.csv', 'volvMETA.csv', 'volvMSFT.csv', 'volvAMZN.csv', ]\n",
    "  batch_size=int(torch.cuda.get_device_properties(0).total_memory/1e9+.5)*32\n",
    "  import os,sys\n",
    "  if not os.path.exists(source_path):\n",
    "    %cd $mydrive/git\n",
    "    !git clone https://github.com/jerronl/Crossformer.git\n",
    "    %cd $source_path\n",
    "  else:\n",
    "    %cd $source_path\n",
    "    # !git reset --hard HEAD\n",
    "    # !git pull origin master\n",
    "  %pip install einops #scikit-learn\n",
    "  sys.path.append( source_path)\n",
    "else:\n",
    "  tables = [ 'volvAAPL.csv']\n",
    "  testData=''\n",
    "  mydrive= 'E:/mydoc/git/trade/analyics/'\n",
    "  batch_size=32\n",
    "  sys.path.append(\"G:/git/Crossformer1/\")\n",
    "  itr=1\n",
    "  %load_ext autoreload\n",
    "  %autoreload 2\n",
    "%cd $mydrive\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Funcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import traceback\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "from matplotlib.colors import LogNorm\n",
    "import torch\n",
    "\n",
    "from cross_exp.exp_crossformer import Exp_crossformer\n",
    "from data.data_loader import DatasetMTS, data_columns, data_names\n",
    "from data.data_def import set_cat\n",
    "from utils.tools import init_args, update_args\n",
    "\n",
    "set_cat(20)\n",
    "args = init_args()\n",
    "data_parser = {}\n",
    "\n",
    "COMMON_SETTINGS = {\n",
    "    \"e_layers\": 5,\n",
    "    \"d_model\": 512,\n",
    "    \"lradj\": \"type2\",\n",
    "    \"checkpoints\": checkpoints,\n",
    "}\n",
    "\n",
    "\n",
    "def generate_configs(grid, mode_idx):\n",
    "    active_keys = []\n",
    "    values_lists = []\n",
    "    for key, (vals, in_vols, in_prcs) in grid.items():\n",
    "        is_active = in_vols if mode_idx == 1 else in_prcs\n",
    "        if is_active:\n",
    "            active_keys.append(key)\n",
    "            values_lists.append(vals)\n",
    "    configs = []\n",
    "    for combination in itertools.product(*values_lists):\n",
    "        cfg = dict(zip(active_keys, combination))\n",
    "        configs.append(cfg)\n",
    "    return configs\n",
    "\n",
    "\n",
    "def apply_config_override(parser_config: dict, ds: str, config_dict: dict) -> dict:\n",
    "    if ds not in parser_config:\n",
    "        temp_config = parser_config.copy()\n",
    "    else:\n",
    "        temp_config = parser_config[ds].copy()\n",
    "    temp_config.update(config_dict)\n",
    "    if ds not in parser_config:\n",
    "        return temp_config\n",
    "    else:\n",
    "        parser_config[ds] = temp_config\n",
    "        return parser_config\n",
    "\n",
    "\n",
    "def build_parser(mode, ds, extra_query=\"\", root_override=None):\n",
    "    \"\"\"\n",
    "    根据 mode (insample/oos) 和 extra_query 构造数据加载配置。\n",
    "    - oos: 路径为 testData，且 query 包含 cutdate 过滤。\n",
    "    - insample: 路径为 valData，query 不含 cutdate 过滤。\n",
    "    \"\"\"\n",
    "    root = mydrive + valData if mode == \"insample\" else mydrive + testData\n",
    "    if root_override:\n",
    "        root = root_override\n",
    "\n",
    "    q = \"\"\n",
    "    if mode == \"oos\":\n",
    "        # OOS 模式：必须满足 cutdate 之后，并附加 extra_query\n",
    "        q = f\"date>'#{cutdate}'\"\n",
    "        if extra_query:\n",
    "            q += \" and \" + extra_query\n",
    "    elif mode == \"insample\":\n",
    "        # Insample 模式：只附加 extra_query (例如 horizon 过滤)\n",
    "        q = extra_query\n",
    "\n",
    "    ds_config = COMMON_SETTINGS.copy()\n",
    "    ds_config[\"root_path\"] = root\n",
    "    ds_config[\"data_path\"] = tables\n",
    "    ds_config[\"weight\"] = weight[0] if ds == \"vols\" else weight[1]\n",
    "    ds_config[\"data\"] = ds\n",
    "\n",
    "    if q:\n",
    "        ds_config[\"query\"] = q.lstrip(\" and \")\n",
    "\n",
    "    parser = {}\n",
    "    if ds != \"vols\":\n",
    "        parser[\"vols\"] = {\"checkpoints\": checkpoints}\n",
    "    parser[ds] = ds_config\n",
    "    return parser\n",
    "\n",
    "\n",
    "def build_train_parser(root_path=None):\n",
    "    if root_path == None:\n",
    "        root_path = mydrive + valData\n",
    "    base = {\n",
    "        \"patience\": epochs[0],\n",
    "        \"train_epochs\": TRAIN_EPOCHS,\n",
    "        \"learning_rate\": 0.01,\n",
    "        \"data_split\": [0.7, 0.15, 0.15],\n",
    "        \"batch_size\": batch_size * 2 // 5,\n",
    "        \"e_layers\": 5,\n",
    "        \"d_model\": 512,\n",
    "        \"lradj\": \"type2\",\n",
    "        \"checkpoints\": checkpoints,\n",
    "        \"root_path\": root_path,\n",
    "        \"data_path\": tables,\n",
    "        \"profile_mode\": False,\n",
    "        \"use_amp\": use_amp,\n",
    "    }\n",
    "    return {\n",
    "        \"vols\": {**base, \"data\": \"vols\", \"weight\": weight[0], \"over_weight\": weight[2]},\n",
    "        \"prcs\": {**base, \"data\": \"prcs\", \"weight\": weight[1], \"over_weight\": weight[3]},\n",
    "    }\n",
    "\n",
    "\n",
    "def get_feature_names(ds_name, in_len):\n",
    "    cols = data_columns(ds_name)\n",
    "    return data_names(cols, 1)[0]\n",
    "\n",
    "\n",
    "def get_trained_epochs(setting_str, ds):\n",
    "    folder_path = os.path.join(checkpoints, setting_str) + ds\n",
    "    file_path = os.path.join(folder_path, \"checkpoint.pth\")\n",
    "    if os.path.exists(file_path):\n",
    "        try:\n",
    "            state = torch.load(file_path, weights_only=False)\n",
    "            if isinstance(state, dict) and \"epoch\" in state:\n",
    "                return state[\"epoch\"]\n",
    "            else:\n",
    "                return \"N/A\"\n",
    "        except Exception:\n",
    "            return \"Err\"\n",
    "    else:\n",
    "        return \"Not Fnd\"\n",
    "\n",
    "\n",
    "def prepare_preds_trues_for_plot(preds, trues, ycat=0):\n",
    "    preds = np.asarray(preds)\n",
    "    trues = np.asarray(trues)\n",
    "    if ycat > 0:\n",
    "        reg_dim = preds.shape[1] - ycat\n",
    "        reg_preds = preds[:, :reg_dim]\n",
    "        if trues.shape[1] >= reg_dim:\n",
    "            reg_trues = trues[:, :reg_dim]\n",
    "        else:\n",
    "            min_dim = min(trues.shape[1], reg_dim)\n",
    "            reg_preds = reg_preds[:, :min_dim]\n",
    "            reg_trues = trues[:, :min_dim]\n",
    "        return reg_preds, reg_trues\n",
    "    return preds, trues\n",
    "\n",
    "\n",
    "def _metrics_text(t, p):\n",
    "    diff = p - t\n",
    "    mae = np.mean(np.abs(diff))\n",
    "    mse = np.mean(diff**2)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mape = np.mean(np.abs(diff) / (np.abs(t) + 1e-12))\n",
    "    return f\"mae={mae:.4g}\\nrmse={rmse:.4g}\\nmape={mape:.3g}\"\n",
    "\n",
    "\n",
    "def _metrics_text_prcs_ic_iv(t_iv, p_iv, t_ic, p_ic_label):\n",
    "    diff = p_iv - t_iv\n",
    "    mae = np.mean(np.abs(diff))\n",
    "    mse = np.mean(diff**2)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mape = np.mean(np.abs(diff) / (np.abs(t_iv) + 1e-12))\n",
    "    accr = np.nan\n",
    "    if len(t_ic) > 0 and (np.unique(t_ic).size <= 20) and (~np.isnan(t_ic)).sum() > 0:\n",
    "        if np.unique(p_ic_label).size <= 20:\n",
    "            accr = np.mean(\n",
    "                (p_ic_label.round() == t_ic.round())[\n",
    "                    ~np.isnan(p_ic_label) & ~np.isnan(t_ic)\n",
    "                ]\n",
    "            )\n",
    "    if not np.isnan(accr):\n",
    "        return f\"accr(IC)={accr:.3f}\\nmae(IV)={mae:.4g}\\nrmse(IV)={rmse:.4g}\"\n",
    "    else:\n",
    "        return f\"mae(IV)={mae:.4g}\\nrmse(IV)={rmse:.4g}\\nmape(IV)={mape:.3g}\"\n",
    "\n",
    "\n",
    "def _compute_limits_like_old_regplot(trues_list, preds_list, feat_idx, feat_name):\n",
    "    left, right = np.inf, -np.inf\n",
    "    for trues, preds in zip(trues_list, preds_list):\n",
    "        t = trues[:, feat_idx]\n",
    "        p = preds[:, feat_idx]\n",
    "        mask = ~np.isnan(t) & ~np.isnan(p)\n",
    "        if not mask.any():\n",
    "            continue\n",
    "        t, p = t[mask], p[mask]\n",
    "        if feat_name[:3] not in [\"dtm\", \"pmc\"]:\n",
    "            left = min(left, max(np.min(t), -5), max(np.min(p), -5))\n",
    "            right = max(right, min(np.max(t), 5), min(np.max(p), 5))\n",
    "        else:\n",
    "            left = min(left, np.min(t), np.min(p))\n",
    "            right = max(right, np.max(t), np.max(p))\n",
    "    if not np.isfinite(left) or not np.isfinite(right) or left == right:\n",
    "        left, right = -1, 1\n",
    "    return left, right\n",
    "\n",
    "\n",
    "def plot_residual_heatmap_family(\n",
    "    preds_raw,\n",
    "    trues_raw,\n",
    "    feature_names,\n",
    "    title,\n",
    "    bins=80,\n",
    "    ycat=0,\n",
    "    cols=4,\n",
    "    figsize_per_cell=4,\n",
    "):\n",
    "    preds, trues = prepare_preds_trues_for_plot(preds_raw, trues_raw, ycat=ycat)\n",
    "    out_dim = trues.shape[1]\n",
    "    max_plot_dim = len(feature_names)\n",
    "    effective_dim = min(out_dim, max_plot_dim)\n",
    "    rows = int(np.ceil(effective_dim / cols))\n",
    "    fig, axes = plt.subplots(\n",
    "        rows,\n",
    "        cols,\n",
    "        figsize=(figsize_per_cell * cols, figsize_per_cell * rows),\n",
    "        squeeze=False,\n",
    "        constrained_layout=True,\n",
    "    )\n",
    "    for i in range(effective_dim):\n",
    "        r, c = divmod(i, cols)\n",
    "        ax = axes[r, c]\n",
    "        fname = feature_names[i]\n",
    "        t = trues[:, i]\n",
    "        p = preds[:, i]\n",
    "        mask = ~np.isnan(t) & ~np.isnan(p)\n",
    "        t, p = t[mask], p[mask]\n",
    "        if len(t) == 0:\n",
    "            ax.set_title(fname)\n",
    "            ax.axis(\"off\")\n",
    "            continue\n",
    "        if ycat > 0 and i == 0:\n",
    "            p_cls = preds[mask, 4]\n",
    "            metrics_text = _metrics_text_prcs_ic_iv(t, p, t, p_cls)\n",
    "        else:\n",
    "            metrics_text = _metrics_text(t, p)\n",
    "        left, right = _compute_limits_like_old_regplot(\n",
    "            [trues_raw], [preds_raw], i, fname\n",
    "        )\n",
    "        ax.hist2d(t, p, bins=bins, range=[[left, right], [left, right]], norm=\"log\")\n",
    "        ax.plot([left, right], [left, right], \"w--\", alpha=0.45)\n",
    "        ax.set_xlim(left, right)\n",
    "        ax.set_ylim(left, right)\n",
    "        ax.set_xlabel(\"True\")\n",
    "        ax.set_ylabel(\"Pred\")\n",
    "        ax.set_title(fname, fontsize=12)\n",
    "        ax.text(\n",
    "            0.02,\n",
    "            0.98,\n",
    "            metrics_text,\n",
    "            transform=ax.transAxes,\n",
    "            va=\"top\",\n",
    "            ha=\"left\",\n",
    "            fontsize=9,\n",
    "            bbox=dict(boxstyle=\"round,pad=0.25\", fc=\"black\", ec=\"none\", alpha=0.35),\n",
    "            color=\"white\",\n",
    "            zorder=3,\n",
    "        )\n",
    "    for i in range(effective_dim, rows * cols):\n",
    "        axes.flatten()[i].axis(\"off\")\n",
    "    if title:\n",
    "        fig.suptitle(title, fontsize=14)\n",
    "    plt.show()\n",
    "    plt.close(fig)\n",
    "\n",
    "\n",
    "def _get_plot_config(all_preds_raw, feature_names, cols):\n",
    "    if not all_preds_raw or not all_preds_raw[0].shape[1]:\n",
    "        return None\n",
    "\n",
    "    n_pred = all_preds_raw[0].shape[1]\n",
    "    n_names = len(feature_names)\n",
    "    effective_dim = min(n_pred, n_names)\n",
    "\n",
    "    if len(feature_names) < effective_dim:\n",
    "        feature_names = feature_names + [\n",
    "            f\"F{i}\" for i in range(len(feature_names), effective_dim)\n",
    "        ]\n",
    "\n",
    "    feature_names = feature_names[:effective_dim]\n",
    "    rows = (effective_dim + cols - 1) // cols\n",
    "\n",
    "    colors_errors = (\n",
    "        plt.rcParams[\"axes.prop_cycle\"]\n",
    "        .by_key()\n",
    "        .get(\"color\", [f\"C{i}\" for i in range(10)])\n",
    "    )\n",
    "    colors_residuals = [\n",
    "        \"#1f77b4\",\n",
    "        \"#ff7f0e\",\n",
    "        \"#2ca02c\",\n",
    "        \"#d62728\",\n",
    "        \"#9467bd\",\n",
    "        \"#8c564b\",\n",
    "        \"#e377c2\",\n",
    "        \"#7f7f7f\",\n",
    "        \"#bcbd22\",\n",
    "        \"#17becf\",\n",
    "        \"#aec7e8\",\n",
    "        \"#ffbb78\",\n",
    "        \"#98df8a\",\n",
    "        \"#ff9896\",\n",
    "        \"#c5b0d5\",\n",
    "        \"#c49c94\",\n",
    "        \"#f7b6d2\",\n",
    "        \"#c7c7c7\",\n",
    "        \"#dbdb8d\",\n",
    "        \"#9edae5\",\n",
    "        \"#393b79\",\n",
    "        \"#637939\",\n",
    "        \"#8c6d31\",\n",
    "        \"#843c39\",\n",
    "        \"#7b4173\",\n",
    "        \"#5254a3\",\n",
    "        \"#6b6ecf\",\n",
    "        \"#ce6dbd\",\n",
    "        \"#de9ed6\",\n",
    "        \"#a55194\",\n",
    "        \"#d6616b\",\n",
    "        \"#e7969c\",\n",
    "        \"#dadaeb\",\n",
    "        \"#fdd0a2\",\n",
    "        \"#31a354\",\n",
    "        \"#74c476\",\n",
    "        \"#a1d99b\",\n",
    "        \"#c7e9c0\",\n",
    "        \"#756bb1\",\n",
    "        \"#9e9ac8\",\n",
    "    ]\n",
    "\n",
    "    return {\n",
    "        \"effective_dim\": effective_dim,\n",
    "        \"feature_names\": feature_names,\n",
    "        \"rows\": rows,\n",
    "        \"colors_errors\": colors_errors,\n",
    "        \"colors_residuals\": colors_residuals,\n",
    "    }\n",
    "\n",
    "\n",
    "def plot_multi_stock_errors(\n",
    "    all_preds_raw,\n",
    "    all_trues_raw,\n",
    "    stock_labels,\n",
    "    feature_names,\n",
    "    title=\"\",\n",
    "    cols=4,\n",
    "    figsize_per_cell=4,\n",
    "    config=None,\n",
    "):\n",
    "    if config is None:\n",
    "        config = _get_plot_config(all_preds_raw, feature_names, cols)\n",
    "\n",
    "    if not config:\n",
    "        print(\"No data available for plotting.\")\n",
    "        return\n",
    "\n",
    "    effective_dim = config[\"effective_dim\"]\n",
    "    feature_names = config[\"feature_names\"]\n",
    "    rows = config[\"rows\"]\n",
    "    colors = config[\"colors_errors\"]\n",
    "\n",
    "    fig_height = rows * figsize_per_cell\n",
    "    top_margin = 0.905 + rows * 0.005\n",
    "    if not title:\n",
    "        top_margin += 0.02\n",
    "\n",
    "    fig = plt.figure(figsize=(cols * figsize_per_cell, fig_height))\n",
    "    outer = gridspec.GridSpec(rows, cols, wspace=0.25, hspace=0.4 if rows < 5 else 0.5)\n",
    "\n",
    "    for i in range(effective_dim):\n",
    "        fname = feature_names[i]\n",
    "        r, c = divmod(i, cols)\n",
    "        ax = fig.add_subplot(outer[r, c])\n",
    "\n",
    "        t_all = []\n",
    "        e_all = []\n",
    "\n",
    "        for j, (preds_reg, trues_reg) in enumerate(zip(all_preds_raw, all_trues_raw)):\n",
    "            t = trues_reg[:, i]\n",
    "            p = preds_reg[:, i]\n",
    "            mask = ~np.isnan(t) & ~np.isnan(p)\n",
    "            t = t[mask]\n",
    "            p = p[mask]\n",
    "            if t.size == 0:\n",
    "                continue\n",
    "\n",
    "            e = p - t\n",
    "            t_all.append(t)\n",
    "            e_all.append(e)\n",
    "\n",
    "            color = colors[j % len(colors)]\n",
    "            ax.scatter(\n",
    "                t,\n",
    "                e,\n",
    "                s=4,\n",
    "                alpha=0.4,\n",
    "                color=color,\n",
    "                label=stock_labels[j] if i == 0 else None,\n",
    "                zorder=2,\n",
    "            )\n",
    "\n",
    "        if not t_all:\n",
    "            ax.set_title(fname)\n",
    "            ax.axis(\"off\")\n",
    "            continue\n",
    "\n",
    "        t_all = np.concatenate(t_all)\n",
    "        e_all = np.concatenate(e_all)\n",
    "\n",
    "        ax.axhline(0.0, color=\"k\", linestyle=\"--\", linewidth=0.8, alpha=0.7)\n",
    "\n",
    "        try:\n",
    "            if np.unique(t_all).size > 1:\n",
    "                slope, intercept = np.polyfit(t_all, e_all, 1)\n",
    "                x_fit = np.array([np.min(t_all), np.max(t_all)])\n",
    "                y_fit = slope * x_fit + intercept\n",
    "                ax.plot(\n",
    "                    x_fit,\n",
    "                    y_fit,\n",
    "                    linestyle=\"-.\",\n",
    "                    linewidth=1.0,\n",
    "                    color=\"tab:orange\",\n",
    "                )\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "        mae = float(np.mean(np.abs(e_all)))\n",
    "        rmse = float(np.sqrt(np.mean(e_all**2)))\n",
    "        over_mask = e_all > 0\n",
    "        under_mask = e_all < 0\n",
    "        over_frac = float(np.mean(over_mask)) if over_mask.size else 0.0\n",
    "        under_frac = float(np.mean(under_mask)) if under_mask.size else 0.0\n",
    "        over_mae = float(np.mean(np.abs(e_all[over_mask]))) if over_mask.any() else 0.0\n",
    "        under_mae = (\n",
    "            float(np.mean(np.abs(e_all[under_mask]))) if under_mask.any() else 0.0\n",
    "        )\n",
    "\n",
    "        metrics_text = (\n",
    "            f\"RMSE: {rmse:.4g}\\n\"\n",
    "            f\"MAE: {mae:.4g}\\n\"\n",
    "            f\"over%: {over_frac*100:4.1f}\\n\"\n",
    "            f\"MAE_over: {over_mae:.4g}\\n\"\n",
    "            f\"MAE_under: {under_mae:.4g}\"\n",
    "        )\n",
    "\n",
    "        ax.text(\n",
    "            0.03,\n",
    "            0.97,\n",
    "            metrics_text,\n",
    "            transform=ax.transAxes,\n",
    "            fontsize=8,\n",
    "            va=\"top\",\n",
    "            ha=\"left\",\n",
    "            bbox=dict(boxstyle=\"round\", facecolor=\"white\", alpha=0.8),\n",
    "        )\n",
    "\n",
    "        ax.set_title(fname, fontsize=10)\n",
    "        ax.set_xlabel(\"true\")\n",
    "        ax.set_ylabel(\"error = pred - true\")\n",
    "        ax.grid(True, linestyle=\"--\", alpha=0.4)\n",
    "\n",
    "        if i == 0:\n",
    "            ax.legend(fontsize=7, loc=\"lower right\", framealpha=0.5)\n",
    "\n",
    "    if title:\n",
    "        title_y = 0.99 if rows > 5 else 0.96\n",
    "        fig.suptitle(title, fontsize=14, y=title_y)\n",
    "\n",
    "    bottom_margin = 0.08\n",
    "    left_margin = 0.05\n",
    "    right_margin = 0.98\n",
    "    fig.subplots_adjust(\n",
    "        top=top_margin,\n",
    "        bottom=bottom_margin,\n",
    "        left=left_margin,\n",
    "        right=right_margin,\n",
    "        hspace=0.35,\n",
    "        wspace=0.25,\n",
    "    )\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_multi_stock_residuals(\n",
    "    all_preds_raw,\n",
    "    all_trues_raw,\n",
    "    stock_labels,\n",
    "    feature_names,\n",
    "    ycat=0,\n",
    "    title=\"\",\n",
    "    bins=80,\n",
    "    cols=4,\n",
    "    figsize_per_cell=4,\n",
    "):\n",
    "    config = _get_plot_config(all_preds_raw, feature_names, cols)\n",
    "    if not config:\n",
    "        print(\"No data available for plotting.\")\n",
    "        return\n",
    "\n",
    "    effective_dim = config[\"effective_dim\"]\n",
    "    feature_names = config[\"feature_names\"]\n",
    "    rows = config[\"rows\"]\n",
    "    colors = config[\"colors_residuals\"]\n",
    "\n",
    "    fig_height = rows * figsize_per_cell\n",
    "    top_margin = 0.905 + rows * 0.005\n",
    "    if not title:\n",
    "        top_margin += 0.02\n",
    "\n",
    "    fig = plt.figure(figsize=(cols * figsize_per_cell, fig_height))\n",
    "    outer = gridspec.GridSpec(rows, cols, wspace=0.25, hspace=0.4 if rows < 5 else 0.5)\n",
    "\n",
    "    for i in range(effective_dim):\n",
    "        fname = feature_names[i]\n",
    "        left, right = 999, -999\n",
    "\n",
    "        r, c = divmod(i, cols)\n",
    "        ax_main = fig.add_subplot(outer[r, c])\n",
    "        ax_hist = ax_main.twinx()\n",
    "        max_hist_density = 0\n",
    "        legend_handles = []\n",
    "\n",
    "        for j, (preds_reg, trues_reg) in enumerate(zip(all_preds_raw, all_trues_raw)):\n",
    "            t, p = trues_reg[:, i], preds_reg[:, i]\n",
    "            mask = ~np.isnan(t) & ~np.isnan(p)\n",
    "            t, p = t[mask], p[mask]\n",
    "            if len(t) == 0:\n",
    "                continue\n",
    "\n",
    "            color = colors[j % len(colors)]\n",
    "\n",
    "            try:\n",
    "                h_vals, _, _ = ax_hist.hist(\n",
    "                    t, bins=bins, density=True, alpha=0.15, color=color, zorder=1\n",
    "                )\n",
    "                if len(h_vals) > 0:\n",
    "                    max_hist_density = max(max_hist_density, np.max(h_vals))\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "            if fname[:3] not in [\"dtm\", \"pmc\"]:\n",
    "                left = min(left, max(np.min(t), -5))\n",
    "                right = max(right, min(np.max(t), 5))\n",
    "            else:\n",
    "                left = min(left, np.min(t))\n",
    "                right = max(right, np.max(t))\n",
    "\n",
    "            ax_main.scatter(t, p, s=0.5, alpha=0.4, color=color, zorder=2)\n",
    "\n",
    "            try:\n",
    "                slope, intercept = np.polyfit(t, p, 1)\n",
    "                x_fit = np.array([np.min(t), np.max(t)])\n",
    "                y_fit = slope * x_fit + intercept\n",
    "                (line,) = ax_main.plot(\n",
    "                    x_fit,\n",
    "                    y_fit,\n",
    "                    color=color,\n",
    "                    linestyle=\"--\",\n",
    "                    lw=1.5,\n",
    "                    label=stock_labels[j],\n",
    "                    alpha=0.4,\n",
    "                )\n",
    "                legend_handles.append(line)\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "        cur_xlim = ax_main.get_xlim()\n",
    "        cur_ylim = ax_main.get_ylim()\n",
    "        if left == 999:\n",
    "            left = cur_xlim[0]\n",
    "        if right == -999:\n",
    "            right = cur_xlim[1]\n",
    "\n",
    "        final_min = min(-0.01, min(left, cur_xlim[0], cur_ylim[0]))\n",
    "        final_max = max(0.01, max(right, cur_xlim[1], cur_ylim[1]))\n",
    "\n",
    "        ax_main.set_xlim(final_min, final_max)\n",
    "        ax_main.set_ylim(final_min, final_max)\n",
    "\n",
    "        ax_hist.set_ylim(0, max_hist_density * 3 if max_hist_density > 0 else 1)\n",
    "        ax_hist.axis(\"off\")\n",
    "\n",
    "        all_t_list = []\n",
    "        all_p_list = []\n",
    "        for p_raw, t_raw in zip(all_preds_raw, all_trues_raw):\n",
    "            if t_raw.shape[1] > i:\n",
    "                all_t_list.append(t_raw[:, i])\n",
    "            if p_raw.shape[1] > i:\n",
    "                all_p_list.append(p_raw[:, i])\n",
    "\n",
    "        if all_t_list and all_p_list:\n",
    "            all_t = np.concatenate(all_t_list)\n",
    "            all_p = np.concatenate(all_p_list)\n",
    "            mask = ~np.isnan(all_t) & ~np.isnan(all_p)\n",
    "\n",
    "            if np.any(mask):\n",
    "                rmse = np.sqrt(np.mean((all_t[mask] - all_p[mask]) ** 2))\n",
    "                mae = np.mean(np.abs(all_t[mask] - all_p[mask]))\n",
    "                metrics_text = f\"RMSE: {rmse:.4f}\\nMAE: {mae:.4f}\"\n",
    "                ax_main.text(\n",
    "                    0.05,\n",
    "                    0.95,\n",
    "                    metrics_text,\n",
    "                    transform=ax_main.transAxes,\n",
    "                    fontsize=9,\n",
    "                    va=\"top\",\n",
    "                    bbox=dict(boxstyle=\"round\", fc=\"white\", alpha=0.85),\n",
    "                )\n",
    "\n",
    "        ax_main.set_title(fname, y=1.01, fontsize=11)\n",
    "        ax_main.legend(handles=legend_handles, fontsize=8, loc=\"best\")\n",
    "\n",
    "    if title:\n",
    "        title_y = 0.99 if rows > 5 else 0.96\n",
    "        fig.suptitle(title, fontsize=14, y=title_y)\n",
    "\n",
    "    bottom_margin = 0.08\n",
    "    left_margin = 0.05\n",
    "    right_margin = 0.98\n",
    "    fig.subplots_adjust(\n",
    "        top=top_margin,\n",
    "        bottom=bottom_margin,\n",
    "        left=left_margin,\n",
    "        right=right_margin,\n",
    "        hspace=0.35,\n",
    "        wspace=0.25,\n",
    "    )\n",
    "    plt.show()\n",
    "\n",
    "    # == 调用 plot_multi_stock_errors，并传入配置 (避免重复计算) ==\n",
    "    if all_preds_raw and len(all_preds_raw) > 0:\n",
    "        plot_multi_stock_errors(\n",
    "            all_preds_raw,\n",
    "            all_trues_raw,\n",
    "            stock_labels,\n",
    "            feature_names,\n",
    "            title=f\"{title} - Prediction Errors\" if title else \"Prediction Errors\",\n",
    "            cols=cols,\n",
    "            figsize_per_cell=figsize_per_cell,\n",
    "            config=config,\n",
    "        )\n",
    "    # ======================================\n",
    "\n",
    "\n",
    "def plot_prcs_distribution_detailed(\n",
    "    results_list,\n",
    "    model_idx,\n",
    "    ycat,\n",
    "    dep_var,\n",
    "    tables_list,\n",
    "    cols=4,\n",
    "    title_prefix=\"PRCS Distribution\",\n",
    "):\n",
    "    if not results_list or ycat == 0:\n",
    "        print(\"No PRCS results or ycat=0, skipping detailed distribution plot.\")\n",
    "        return\n",
    "    n_categories = ycat\n",
    "    x = np.arange(1, n_categories + 1)\n",
    "    n_tables = len(results_list)\n",
    "    outer_rows = (n_tables - 1) // cols + 1\n",
    "    fig = plt.figure(figsize=(16, 4 * outer_rows))\n",
    "    outer = gridspec.GridSpec(outer_rows, cols, wspace=0.3, hspace=0.45)\n",
    "    ls = [\"-\", \"--\", \":\"]\n",
    "    print(f\"\\n--- Plotting {title_prefix} for Model m{model_idx} ---\")\n",
    "    for j, result in enumerate(results_list):\n",
    "        preds_raw, trues_raw, _ = result\n",
    "        preds = np.asarray(preds_raw)\n",
    "        trues = np.asarray(trues_raw)\n",
    "        probs = preds[:, -n_categories:]\n",
    "        true_labels = np.round(trues[:, 0]).astype(int)\n",
    "        valid_mask = (\n",
    "            (~np.isnan(true_labels))\n",
    "            & (true_labels >= 1)\n",
    "            & (true_labels <= n_categories)\n",
    "        )\n",
    "        if np.sum(valid_mask) == 0:\n",
    "            continue\n",
    "        probs = probs[valid_mask]\n",
    "        true_labels = true_labels[valid_mask]\n",
    "        if np.size(probs) > 0 and (np.max(probs) > 1.05 or np.min(probs) < -0.05):\n",
    "            exp_probs = np.exp(probs - np.max(probs, axis=1, keepdims=True))\n",
    "            probs = exp_probs / (np.sum(exp_probs, axis=1, keepdims=True) + 1e-12)\n",
    "        df = pd.DataFrame(probs, columns=[str(i) for i in range(1, n_categories + 1)])\n",
    "        df[\"True_Label\"] = true_labels\n",
    "        summed_probs = df.groupby(\"True_Label\").mean().T\n",
    "        xi = [int(x) for x in summed_probs.index]\n",
    "        third = n_categories // 3 + 1\n",
    "        r_outer = j // cols\n",
    "        c_outer = j % cols\n",
    "        sub_gs = outer[r_outer, c_outer].subgridspec(2, 1, hspace=0.0)\n",
    "        valid_true_labels = sorted(\n",
    "            [c for c in summed_probs.columns if 1 <= c <= n_categories]\n",
    "        )\n",
    "        for k in (0, 1):\n",
    "            ax = fig.add_subplot(sub_gs[k, 0])\n",
    "            hist_bins = np.arange(1, n_categories + 2) - 0.5\n",
    "            ax.hist(\n",
    "                true_labels,\n",
    "                bins=hist_bins,\n",
    "                alpha=0.2,\n",
    "                density=True,\n",
    "                color=\"gray\",\n",
    "                label=\"True\",\n",
    "                zorder=1,\n",
    "            )\n",
    "            ci = 0\n",
    "            for m in range(k, len(valid_true_labels), 2):\n",
    "                col = valid_true_labels[m]\n",
    "                ax.plot(\n",
    "                    xi,\n",
    "                    summed_probs[col],\n",
    "                    label=f\"cat {col}\",\n",
    "                    linestyle=ls[col // third % 3],\n",
    "                    color=f\"C{ci % 10}\",\n",
    "                    alpha=0.7,\n",
    "                    zorder=2,\n",
    "                )\n",
    "                pred_prob_at_true_class = summed_probs[col][str(col)]\n",
    "                ax.text(\n",
    "                    col,\n",
    "                    pred_prob_at_true_class,\n",
    "                    f\"{col}\",\n",
    "                    fontsize=8,\n",
    "                    va=\"bottom\",\n",
    "                    ha=\"center\",\n",
    "                    color=f\"C{(ci) % 10}\",\n",
    "                    zorder=3,\n",
    "                )\n",
    "                ci += 1\n",
    "            ax.set_title(\n",
    "                (\n",
    "                    f'{tables_list[j]} - {\"Odd\" if k == 0 else \"Even\"})'\n",
    "                    if k == 0\n",
    "                    else \"\"\n",
    "                ),\n",
    "                fontsize=10,\n",
    "            )\n",
    "            ax.set_ylim(0.0, 0.2)\n",
    "            ax.set_xlim(0.5, n_categories + 1.5)\n",
    "            ax.set_xticks(x)\n",
    "            ax.set_xticklabels([str(i) for i in x], rotation=-45, fontsize=8)\n",
    "            ax.legend(\n",
    "                loc=\"center left\",\n",
    "                bbox_to_anchor=(1.05, 0.5),\n",
    "                fontsize=7,\n",
    "                framealpha=0.6,\n",
    "            )\n",
    "            ax.grid(axis=\"y\", linestyle=\"--\", alpha=0.3)\n",
    "            if k == 0:\n",
    "                plt.setp(ax.get_xticklabels(), visible=False)\n",
    "                ax.set_xlabel(\"\")\n",
    "            else:\n",
    "                ax.set_xlabel(\"Predicted Class Index\", fontsize=9)\n",
    "    fig.suptitle(f\"{title_prefix} - Model m{model_idx}\", fontsize=14)\n",
    "    plt.tight_layout(rect=[0, 0.03, 1, 0.97])\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "def generate_final_summary(summary_records):\n",
    "    if not summary_records:\n",
    "        print(\"No records to summarize.\")\n",
    "        return\n",
    "    df = pd.DataFrame(summary_records)\n",
    "    fixed_info_cols = [\"dataset\", \"idx\", \"horizon\", \"epochs\"]\n",
    "    metric_cols = [\"mae\", \"mse\", \"rmse\", \"mape\", \"mdst\", \"accr\"]\n",
    "    all_cols = df.columns.tolist()\n",
    "    param_cols = [\n",
    "        c for c in all_cols if c not in fixed_info_cols and c not in metric_cols\n",
    "    ]\n",
    "    final_order = []\n",
    "    for c in fixed_info_cols:\n",
    "        if c in df.columns:\n",
    "            final_order.append(c)\n",
    "    final_order += sorted(param_cols)\n",
    "    final_order += [c for c in metric_cols if c in df.columns]\n",
    "    print(df[final_order].to_string(float_format=lambda x: \"{:.4g}\".format(x)))\n",
    "\n",
    "\n",
    "def _init_exp_and_setting(parser_config: dict, ds: str):\n",
    "    \"\"\"Initializes args, creates setting string, and instantiates Exp_crossformer.\"\"\"\n",
    "    args = init_args()\n",
    "    setting_str = update_args(args, parser_config, itr=0, arg_set=ds)\n",
    "    exp = Exp_crossformer(args)\n",
    "    return args, setting_str, exp\n",
    "\n",
    "\n",
    "def run_test_one_setting(\n",
    "    exp,\n",
    "    setting_str,\n",
    "    ds,\n",
    "    dep_var,\n",
    "    ycat,\n",
    "    title_prefix,\n",
    "    by_stock=False,\n",
    "    stock_tables=None,\n",
    "    plot_individual_heatmaps=True,\n",
    "    test_data=None,\n",
    "):\n",
    "    metrics_list, all_preds, all_trues = [], [], []\n",
    "\n",
    "    def _plot_results(p_raw, t_raw, current_title):\n",
    "        if not plot_individual_heatmaps:\n",
    "            return\n",
    "        print(f\"\\n--- Residual Heatmap: {current_title} ---\")\n",
    "        plot_residual_heatmap_family(\n",
    "            p_raw, t_raw, dep_var, title=current_title, ycat=ycat\n",
    "        )\n",
    "\n",
    "    if by_stock:\n",
    "        for tb in stock_tables:\n",
    "            preds, trues, m = exp.test(\n",
    "                setting_str, ds, True, data_path=[tb], inverse=True\n",
    "            )\n",
    "            metrics_list.append(m)\n",
    "            all_preds.append(preds)\n",
    "            all_trues.append(trues)\n",
    "            _plot_results(preds, trues, f\"{title_prefix} {tb}\")\n",
    "        return metrics_list, all_preds, all_trues\n",
    "    else:\n",
    "        preds, trues, m = exp.test(\n",
    "            setting_str, ds, True, inverse=True, test_data=test_data\n",
    "        )\n",
    "        metrics_list.append(m)\n",
    "        _plot_results(preds, trues, title_prefix)\n",
    "        if test_data is not None and isinstance(preds, list):\n",
    "            return metrics_list, preds, trues\n",
    "\n",
    "        return metrics_list, [preds], [trues]\n",
    "\n",
    "\n",
    "def train_unified_all():\n",
    "    global args, data_parser, MODE, epochs, TRAIN_EPOCHS, itr, tables, UNIFIED_CONFIGS, active_grid_indices, DO_TRAIN_VOLS, DO_TRAIN_PRCS\n",
    "\n",
    "    base_parser = build_train_parser()\n",
    "\n",
    "    if not UNIFIED_CONFIGS:\n",
    "        print(\"No configs generated. Skipping training.\")\n",
    "        return\n",
    "\n",
    "    print(\n",
    "        f\"\\n=== Starting UNIFIED Training (Mode: {MODE}, Active Configs: {len(active_grid_indices)}) ===\"\n",
    "    )\n",
    "\n",
    "    for idx in active_grid_indices:\n",
    "        if idx >= len(UNIFIED_CONFIGS):\n",
    "            break\n",
    "\n",
    "        full_cfg = UNIFIED_CONFIGS[idx].copy()\n",
    "        target_ds = full_cfg.pop(\"target_ds\")\n",
    "\n",
    "        if target_ds == \"vols\" and not DO_TRAIN_VOLS:\n",
    "            continue\n",
    "        if target_ds == \"prcs\" and not DO_TRAIN_PRCS:\n",
    "            continue\n",
    "\n",
    "        current_parser = {k: v.copy() for k, v in base_parser.items()}\n",
    "        current_parser[target_ds] = apply_config_override(\n",
    "            current_parser[target_ds], target_ds, full_cfg\n",
    "        )\n",
    "\n",
    "        start_lr = base_parser[target_ds][\"learning_rate\"]\n",
    "        num_cycles = 1 if MODE == \"tuning\" else epochs[2]\n",
    "\n",
    "        for cycle in range(num_cycles):\n",
    "            current_lr = start_lr / (3.0**cycle)\n",
    "            current_parser[target_ds][\"learning_rate\"] = current_lr\n",
    "\n",
    "            args, setting_str, exp = _init_exp_and_setting(current_parser, target_ds)\n",
    "\n",
    "            cfg_display = \", \".join([f\"{k}={v}\" for k, v in full_cfg.items()])\n",
    "\n",
    "            print(\n",
    "                f\"\\n[Idx {idx} | DS: {target_ds.upper()} | Cyc {cycle+1}] Setting: {setting_str}\"\n",
    "            )\n",
    "            print(f\"   LR={current_lr:.6f} | Params: {{{cfg_display}}}\")\n",
    "\n",
    "            try:\n",
    "                exp.train(setting_str, target_ds)\n",
    "            except Exception as e:\n",
    "                print(f\"--- FAILED TRAINING Idx {idx} ({target_ds}) --- Error: {e}\")\n",
    "                traceback.print_exc()\n",
    "\n",
    "\n",
    "def test_unified(\n",
    "    mode: str,\n",
    "    target_ds_filter: str,\n",
    "    by_stock: bool = True,\n",
    "    plot_residuals: bool = True,\n",
    "    plot_stock: bool = False,\n",
    "):\n",
    "    global args, UNIFIED_CONFIGS, active_grid_indices, tables\n",
    "\n",
    "    summary_data = []\n",
    "    if not UNIFIED_CONFIGS:\n",
    "        return\n",
    "\n",
    "    relevant_indices = [\n",
    "        i\n",
    "        for i in active_grid_indices\n",
    "        if i < len(UNIFIED_CONFIGS)\n",
    "        and UNIFIED_CONFIGS[i][\"target_ds\"] == target_ds_filter\n",
    "    ]\n",
    "\n",
    "    if not relevant_indices:\n",
    "        print(\n",
    "            f\"No active configs found for target_ds='{target_ds_filter}' in current index range.\"\n",
    "        )\n",
    "        return\n",
    "\n",
    "    print(\n",
    "        f\"\\n=== Starting {target_ds_filter.upper()} Testing ({mode}) (Found {len(relevant_indices)} relevant configs) ===\"\n",
    "    )\n",
    "\n",
    "    for idx in active_grid_indices:\n",
    "        if idx >= len(UNIFIED_CONFIGS):\n",
    "            break\n",
    "\n",
    "        full_cfg = UNIFIED_CONFIGS[idx].copy()\n",
    "        this_ds = full_cfg.pop(\"target_ds\")\n",
    "\n",
    "        if this_ds != target_ds_filter:\n",
    "            continue\n",
    "        ycat = data_columns(this_ds).get(\"ycat\", 0) if this_ds == \"prcs\" else 0\n",
    "\n",
    "        # 使用修正后的 build_parser，确保 mode 的 date 过滤正确\n",
    "        base_parser = build_parser(mode, this_ds)\n",
    "        ds_config = apply_config_override(\n",
    "            base_parser[this_ds].copy(), this_ds, full_cfg\n",
    "        )\n",
    "        ds_config[\"data\"] = this_ds\n",
    "        base_parser[this_ds] = ds_config\n",
    "\n",
    "        args, setting_str, exp = _init_exp_and_setting(base_parser, this_ds)\n",
    "        trained_epochs = get_trained_epochs(setting_str, this_ds)\n",
    "\n",
    "        if trained_epochs == \"Not Fnd\":\n",
    "            print(f\"[Idx {idx} | {this_ds}] Skipping {setting_str}, model not found.\")\n",
    "            continue\n",
    "\n",
    "        dep_var = get_feature_names(this_ds, getattr(args, \"seq_len\", 1))\n",
    "\n",
    "        try:\n",
    "            cfg_str = \", \".join([f\"{k}={v}\" for k, v in full_cfg.items()])\n",
    "            title = f\"{this_ds.upper()} {mode} [Idx {idx}] {cfg_str}\"\n",
    "\n",
    "            m_list, preds_fam, trues_fam = run_test_one_setting(\n",
    "                exp,\n",
    "                setting_str,\n",
    "                this_ds,\n",
    "                dep_var,\n",
    "                ycat,\n",
    "                title,\n",
    "                by_stock=by_stock,\n",
    "                stock_tables=tables,\n",
    "                plot_individual_heatmaps=plot_stock,\n",
    "            )\n",
    "\n",
    "            if by_stock and preds_fam is not None and plot_residuals:\n",
    "                print(f\"\\n--- AGGREGATED RESIDUAL PLOT: {title} ---\")\n",
    "                plot_multi_stock_residuals(\n",
    "                    preds_fam,\n",
    "                    trues_fam,\n",
    "                    tables,\n",
    "                    dep_var,\n",
    "                    ycat=ycat,\n",
    "                    title=f\"AGGREGATED {title}\",\n",
    "                )\n",
    "                if this_ds == \"prcs\" and ycat > 0:\n",
    "                    results_list = list(zip(preds_fam, trues_fam, m_list))\n",
    "                    plot_prcs_distribution_detailed(\n",
    "                        results_list,\n",
    "                        idx,\n",
    "                        ycat,\n",
    "                        dep_var,\n",
    "                        tables,\n",
    "                        title_prefix=f\"AGG {title}\",\n",
    "                    )\n",
    "\n",
    "            avg_metrics = np.mean(np.array(m_list), axis=0)\n",
    "            rec = {\n",
    "                \"dataset\": this_ds,\n",
    "                \"idx\": idx,\n",
    "                \"epochs\": trained_epochs,\n",
    "                **full_cfg,\n",
    "                \"mae\": avg_metrics[0],\n",
    "                \"mse\": avg_metrics[1],\n",
    "                \"rmse\": avg_metrics[2],\n",
    "                \"mape\": avg_metrics[3],\n",
    "                \"mdst\": avg_metrics[4],\n",
    "                \"accr\": avg_metrics[5],\n",
    "            }\n",
    "            summary_data.append(rec)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"--- FAILED TESTING Idx {idx} ({this_ds}) --- Error: {e}\")\n",
    "            traceback.print_exc()\n",
    "\n",
    "    generate_final_summary(summary_data)\n",
    "    if len(summary_data) > 1:\n",
    "        print(\"\\n--- Plotting Metric Comparisons ---\")\n",
    "        plot_metric_summary(summary_data)\n",
    "    return summary_data\n",
    "\n",
    "\n",
    "def test_vols_per_horizon(\n",
    "    mode: str,\n",
    "    plot_residuals: bool = True,\n",
    "    best_idx: int = -1,\n",
    "    plot_stock: bool = False,\n",
    "):\n",
    "    global args, UNIFIED_CONFIGS, tables\n",
    "    import numpy as np\n",
    "    import traceback\n",
    "\n",
    "    summary_data = []\n",
    "    ds = \"vols\"\n",
    "    horizons = [1, 2, 3, 4, 5]\n",
    "\n",
    "    if not UNIFIED_CONFIGS:\n",
    "        print(\"UNIFIED_CONFIGS is not initialized. Skipping.\")\n",
    "        return\n",
    "\n",
    "    relevant_indices = [\n",
    "        i\n",
    "        for i in range(len(UNIFIED_CONFIGS))\n",
    "        if UNIFIED_CONFIGS[i].get(\"target_ds\") == ds\n",
    "    ]\n",
    "\n",
    "    if best_idx != -1:\n",
    "        if best_idx in relevant_indices:\n",
    "            indices_to_run = [best_idx]\n",
    "        else:\n",
    "            indices_to_run = relevant_indices\n",
    "    else:\n",
    "        indices_to_run = relevant_indices\n",
    "\n",
    "    if not indices_to_run:\n",
    "        return\n",
    "\n",
    "    print(\n",
    "        f\"\\n--- Running VOLS per-horizon test (Total Configs: {len(indices_to_run)}) ---\"\n",
    "    )\n",
    "\n",
    "    for cfg_idx in indices_to_run:\n",
    "        cfg_record = UNIFIED_CONFIGS[cfg_idx]\n",
    "        this_ds = cfg_record.get(\"target_ds\")\n",
    "\n",
    "        if \"config\" in cfg_record:\n",
    "            full_cfg = cfg_record[\"config\"]\n",
    "        else:\n",
    "            full_cfg = cfg_record.copy()\n",
    "            full_cfg.pop(\"target_ds\", None)\n",
    "\n",
    "        if this_ds != ds:\n",
    "            continue\n",
    "\n",
    "        cfg_display = \", \".join([f\"{k}={v}\" for k, v in full_cfg.items()])\n",
    "        print(f\"\\n[VOLS Horizon Test | Idx {cfg_idx}] Params: {{{cfg_display}}}\")\n",
    "\n",
    "        base_parser = build_parser(mode, ds)  # 基础 parser，不含 horizon query\n",
    "        parser_for_loading = {k: v.copy() for k, v in base_parser.items()}\n",
    "        parser_for_loading[ds] = apply_config_override(\n",
    "            parser_for_loading[ds].copy(), ds, full_cfg\n",
    "        )\n",
    "\n",
    "        args, setting_str, exp = _init_exp_and_setting(parser_for_loading, ds)\n",
    "        trained_epochs = get_trained_epochs(setting_str, ds)\n",
    "        dep_var = get_feature_names(ds, getattr(args, \"seq_len\", 1))\n",
    "\n",
    "        if trained_epochs == \"Not Fnd\":\n",
    "            print(f\"  Skipping Idx {cfg_idx}, model not found.\")\n",
    "            continue\n",
    "\n",
    "        original_query = exp.args.query\n",
    "\n",
    "        horizon_preds = []\n",
    "        horizon_trues = []\n",
    "        horizon_names = []\n",
    "        all_feature_names = None\n",
    "\n",
    "        for h_len in horizons:\n",
    "            hq = f\"floor(horizon)=={h_len}\"\n",
    "            temp_parser = build_parser(mode, ds, extra_query=hq)\n",
    "\n",
    "            exp.args.query = temp_parser[ds].get(\"query\", \"\")\n",
    "\n",
    "            try:\n",
    "                dataset, loader = exp._get_data(flag=\"test\", data=ds)\n",
    "\n",
    "                m_list, preds_fam, trues_fam = run_test_one_setting(\n",
    "                    exp,\n",
    "                    setting_str,\n",
    "                    ds,\n",
    "                    dep_var,\n",
    "                    ycat=0,\n",
    "                    title_prefix=f\"\",\n",
    "                    by_stock=False,\n",
    "                    plot_individual_heatmaps=False,\n",
    "                    test_data=(dataset, loader),\n",
    "                )\n",
    "\n",
    "                if all_feature_names is None:\n",
    "                    all_feature_names = dep_var\n",
    "\n",
    "                if m_list and preds_fam:\n",
    "                    metrics = m_list[0]\n",
    "                    rec = {\n",
    "                        \"dataset\": ds,\n",
    "                        \"idx\": cfg_idx,\n",
    "                        \"horizon\": h_len,\n",
    "                        \"epochs\": trained_epochs,\n",
    "                        **full_cfg,\n",
    "                        \"mae\": metrics[0],\n",
    "                        \"rmse\": metrics[2],\n",
    "                        \"accr\": metrics[5],\n",
    "                    }\n",
    "                    summary_data.append(rec)\n",
    "\n",
    "                    horizon_preds.append(preds_fam[0])\n",
    "                    horizon_trues.append(trues_fam[0])\n",
    "                    horizon_names.append(f\"Horizon {h_len}\")\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"--- FAILED TESTING H={h_len} --- Error: {e}\")\n",
    "                traceback.print_exc()\n",
    "\n",
    "        exp.args.query = original_query\n",
    "\n",
    "        if plot_residuals and len(horizon_preds) > 0 and all_feature_names:\n",
    "            title = f\"VOLS {mode} Horizons [Idx {cfg_idx}]\"\n",
    "            print(f\"--- Plotting Aggregated Horizons (Multi-Color): {title} ---\")\n",
    "            plot_multi_stock_residuals(\n",
    "                horizon_preds,\n",
    "                horizon_trues,\n",
    "                horizon_names,\n",
    "                feature_names=all_feature_names,\n",
    "                ycat=0,\n",
    "                title=title,\n",
    "            )\n",
    "        elif plot_residuals and not all_feature_names:\n",
    "            print(\"Warning: Could not retrieve feature names. Skipping plot.\")\n",
    "\n",
    "    generate_final_summary(summary_data)\n",
    "    if len(summary_data) > 1:\n",
    "        plot_metric_summary(summary_data)\n",
    "\n",
    "    return summary_data\n",
    "\n",
    "\n",
    "def plot_metric_summary(summary_records):\n",
    "    if not summary_records:\n",
    "        return\n",
    "    df = pd.DataFrame(summary_records)\n",
    "    metrics = [\"mae\", \"mse\", \"rmse\", \"mape\", \"accr\"]\n",
    "    metrics = [m for m in metrics if m in df.columns]\n",
    "    if not metrics:\n",
    "        return\n",
    "    cols = 2\n",
    "    rows = int(np.ceil(len(metrics) / cols))\n",
    "    fig, axes = plt.subplots(rows, cols, figsize=(15, 5 * rows))\n",
    "    axes = axes.flatten()\n",
    "    cmap = plt.get_cmap(\"tab10\")\n",
    "    for i, metric in enumerate(metrics):\n",
    "        ax = axes[i]\n",
    "        if \"horizon\" in df.columns:\n",
    "            for idx_val in sorted(df[\"idx\"].unique()):\n",
    "                sub = df[df[\"idx\"] == idx_val].sort_values(\"horizon\")\n",
    "                ax.plot(\n",
    "                    sub[\"horizon\"],\n",
    "                    sub[metric],\n",
    "                    marker=\"o\",\n",
    "                    label=f\"Cfg {idx_val}\",\n",
    "                    linewidth=2,\n",
    "                )\n",
    "            ax.set_xlabel(\"Horizon\")\n",
    "        else:\n",
    "            ax.plot(df[\"idx\"], df[metric], marker=\"o\", linestyle=\"-\", color=cmap(i))\n",
    "            ax.set_xlabel(\"Config Index\")\n",
    "            ax.set_xticks(df[\"idx\"].unique())\n",
    "        ax.set_title(metric.upper())\n",
    "        ax.set_ylabel(metric)\n",
    "        ax.grid(True, linestyle=\"--\", alpha=0.5)\n",
    "        if \"horizon\" in df.columns:\n",
    "            ax.legend()\n",
    "    for i in range(len(metrics), len(axes)):\n",
    "        axes[i].axis(\"off\")\n",
    "    plt.suptitle(\"Metric Comparison Summary\", fontsize=16)\n",
    "    plt.tight_layout(rect=[0, 0.03, 1, 0.97])\n",
    "    plt.show()\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-bmjLRHTfVt-"
   },
   "source": [
    "# Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mJovfe3GfVt-"
   },
   "outputs": [],
   "source": [
    "PARAM_GRID_VOLS = {\n",
    "    \"lambda_var\":  ([0.00050, 0.00055, 0.00060], True, True),\n",
    "    \"gain_reg\":    ([1.5, 2.0], True, True),\n",
    "    \"weight_over\": ([1.4, 1.5, 1.6], True, True),\n",
    "\n",
    "    # 固定的最优值，不再扫描\n",
    "    \"lambda_tail\": ([0.0], False, True),\n",
    "    \"lambda_anti\": ([0.1], False, True),\n",
    "    \"dist_alpha\":  ([1.0], False, True),\n",
    "    \"lambda_dist\": ([0.0], False, True),\n",
    "}\n",
    "\n",
    "PARAM_GRID_PRCS = {\n",
    "    # 围绕 0.0004 做轻微上下微调\n",
    "    \"lambda_var\":  ([0.00035, 0.00040, 0.00045], False, True),\n",
    "\n",
    "    # gain_reg 只看 0.8 / 1.0 / 1.2，都是“正常有梯度”的范围\n",
    "    \"gain_reg\":    ([0.8, 1.0, 1.2],             False, True),\n",
    "\n",
    "    # weight_over：基准 1.2，再看看 1.0 会不会稍微放松一点\n",
    "    \"weight_over\": ([1.0, 1.2],                  False, True),\n",
    "\n",
    "    # 这一轮先严格完全兼容老版：这些都锁死为 0\n",
    "    \"lambda_tail\": ([0.0],                       False, True),\n",
    "    \"lambda_anti\": ([0.0],                       False, True),\n",
    "    \"lambda_dist\": ([0.0],                       False, True),\n",
    "\n",
    "    # 老 baseline 用的是分类 + 回归等权\n",
    "    \"lambda_mse\":  ([1.0],                       False, True),\n",
    "\n",
    "    # 先固定为 1.0（和之前老跑法一致），下一轮再单独扫 dist_alpha\n",
    "    \"dist_alpha\":  ([1.0],                       False, True),\n",
    "}\n",
    "\n",
    "\n",
    "prcs_configs_raw = generate_configs(PARAM_GRID_PRCS, 2)\n",
    "\n",
    "\n",
    "vols_configs_raw = generate_configs(PARAM_GRID_VOLS, 1) if DO_TRAIN_VOLS else []\n",
    "prcs_configs_raw = generate_configs(PARAM_GRID_PRCS, 2) if DO_TRAIN_PRCS else []\n",
    "# vols_configs_raw = [\n",
    "#     # ---- Baseline (4组) ----\n",
    "#     {\"lambda_var\":0.0004, \"gain_reg\":1.0, \"weight_over\":1.2, \"lambda_tail\":0.0, \"lambda_anti\":0.0, \"dist_alpha\":1.0},\n",
    "# ]\n",
    "\n",
    "BEST_VOLS_CONFIG = {\n",
    "    \"lambda_var\": 0.0005,\n",
    "    \"gain_reg\": 1.5,\n",
    "    \"weight_over\": 1.4,\n",
    "\n",
    "    \"lambda_tail\": 0.0,\n",
    "    \"lambda_anti\": 0.1,\n",
    "    \"dist_alpha\": 1.0,\n",
    "    \"lambda_dist\": 0.0,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ESF8ae6wWyUS"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# 2. Tag and Merge\n",
    "UNIFIED_CONFIGS = []\n",
    "\n",
    "for cfg in vols_configs_raw:\n",
    "    c = cfg.copy()\n",
    "    c[\"target_ds\"] = \"vols\"  # Add identifier\n",
    "    UNIFIED_CONFIGS.append(c)\n",
    "\n",
    "for cfg in prcs_configs_raw:\n",
    "    c = cfg.copy()\n",
    "    c[\"target_ds\"] = \"prcs\"  # Add identifier\n",
    "    UNIFIED_CONFIGS.append(c)\n",
    "\n",
    "# 3. Provisional slicing\n",
    "if Provisional:\n",
    "    # Just take a few from each for testing\n",
    "    UNIFIED_CONFIGS = (\n",
    "        UNIFIED_CONFIGS[:2]\n",
    "        + UNIFIED_CONFIGS[len(vols_configs_raw) : len(vols_configs_raw) + 2]\n",
    "    )\n",
    "\n",
    "# 4. Set Indices based on Epochs\n",
    "total_configs = len(UNIFIED_CONFIGS)\n",
    "start_idx = epochs[3]\n",
    "# Ensure end_idx doesn't exceed total\n",
    "end_idx = min(start_idx + epochs[4], total_configs)\n",
    "active_grid_indices = range(start_idx, end_idx)\n",
    "\n",
    "if MODE == \"tuning\":\n",
    "    TRAIN_EPOCHS = min(30, epochs[1])\n",
    "else:\n",
    "    TRAIN_EPOCHS = epochs[1]\n",
    "\n",
    "print(\n",
    "    f\"--- Unified Config Preview (Total: {total_configs}, Active: {len(active_grid_indices)}) ---\"\n",
    ")\n",
    "for i in active_grid_indices:\n",
    "    if i < total_configs:\n",
    "        cfg_str = str(UNIFIED_CONFIGS[i])\n",
    "        # Shorten display\n",
    "        print(f\"  [{i}] {cfg_str}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qCfd-gU7JTzW"
   },
   "source": [
    "# train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "edfP8114fVuB"
   },
   "outputs": [],
   "source": [
    "if run_test == False:\n",
    "        train_unified_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4kj_rRG1J66H"
   },
   "outputs": [],
   "source": [
    "if not run_test:\n",
    "    from google.colab import runtime\n",
    "    runtime.unassign()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "84_0x76B135B"
   },
   "outputs": [],
   "source": [
    "if not run_test:\n",
    "    from cross_exp.exp_crossformer import Exp_crossformer\n",
    "    from data.data_loader import DatasetMTS\n",
    "    data_parser = {\n",
    "        \"vols\": {\n",
    "            'data':'vols',\n",
    "            \"patience\":epochs[0],\n",
    "            \"train_epochs\":epochs[1],\n",
    "            'learning_rate':0.01,\n",
    "            'data_split':[0.7,0.15,0.15],\n",
    "            'batch_size':batch_size*2//5,\n",
    "            'e_layers':5,\n",
    "            'd_model':512,\n",
    "            'lradj':'type2',\n",
    "            \"checkpoints\":checkpoints,\n",
    "            'root_path':mydrive+valData,\n",
    "            'data_path':tables,\n",
    "            'weight':weight[0],\n",
    "            'over_weight':weight[2],\n",
    "            'profile_mode':False,\n",
    "            'use_amp':use_amp\n",
    "        },\n",
    "        \"prcs\":{\n",
    "            'data':'prcs',\n",
    "            'weight':weight[1],\n",
    "            'over_weight':weight[3],\n",
    "        }\n",
    "        }\n",
    "    s=epochs[3]\n",
    "    for _ in range(epochs[2]):\n",
    "        data_parser[\"vols\"][\"learning_rate\"]=.01\n",
    "        for i in range(epochs[2]):\n",
    "            for ii in range(s,itr):\n",
    "                # setting record of experiments\n",
    "                # data_parser[\"vols\"]['weight']=weight[0]\n",
    "                setting=update_args(args,data_parser,ii)\n",
    "                DatasetMTS.clear()\n",
    "                # drive.mount('/content/drive/',force_remount=True)\n",
    "                # !google-drive-ocamlfuse -cc # 注释掉这个bug行\n",
    "\n",
    "                exp = Exp_crossformer(args)  # set experiments\n",
    "                print(f\"start training :lr={data_parser[\"vols\"][\"learning_rate\"]} {setting}\")\n",
    "                exp.train(setting, \"vols\")\n",
    "\n",
    "                print(f\">>>>>>>testing : {setting}<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\")\n",
    "                preds, trues,_ = exp.test(setting, 'vols', True, data_path=[tables[-1]], inverse=True)\n",
    "                print(preds.shape, trues.shape)\n",
    "\n",
    "                # data_parser[\"vols\"]['weight']=weight[1]\n",
    "                setting=update_args(args,data_parser,ii,'prcs')\n",
    "                DatasetMTS.clear()\n",
    "                exp = Exp_crossformer(args)  # set experiments\n",
    "                print(f\"start training :lr={data_parser[\"vols\"][\"learning_rate\"]} {setting}\")\n",
    "                exp.train(setting, \"prcs\")\n",
    "                preds, trues,_ = exp.test(setting, 'prcs', True, data_path=[tables[-1]], inverse=True)\n",
    "                print(preds.shape, trues.shape)\n",
    "            data_parser[\"vols\"][\"learning_rate\"]/=3.\n",
    "            s=0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "066vGmCNJTzY"
   },
   "source": [
    "# test\n",
    "##  PART A — In-sample (test split of same source)\n",
    "Subparts:\n",
    "1. vols per-stock heatmap  \n",
    "2. prcs per-stock heatmap + avg prob by true class  \n",
    "3. vols per-horizon heatmap\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "w03KqC8jJTzY"
   },
   "outputs": [],
   "source": [
    "\n",
    "if run_test:\n",
    "            test_unified(\"insample\", \"vols\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wkGkKgp98ua9"
   },
   "source": [
    "## In-sample - Prcs Per-Stock\n",
    "\n",
    "Subparts:\n",
    "1. vols per-stock heatmap  \n",
    "2. prcs per-stock heatmap + avg prob by true class  \n",
    "3. vols per-horizon heatmap\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JKW9afa-cENf"
   },
   "outputs": [],
   "source": [
    "if run_test:\n",
    "\n",
    "           test_unified(\"insample\", \"prcs\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L9IXNP9K8ua-"
   },
   "source": [
    "## In-sample - Horizon\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rpzR-1aN8ua-"
   },
   "outputs": [],
   "source": [
    "if run_test:\n",
    "        test_vols_per_horizon(mode=\"insample\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KBfRZp9y8ua-"
   },
   "source": [
    "# PART B — Out-of-sample (testData, cutdate+)\n",
    "## OOS - Vols Per-Stock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "F6WWmBSmcENg"
   },
   "outputs": [],
   "source": [
    "if run_test:\n",
    "\n",
    "        test_unified(\"oos\", \"vols\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rWJgEQeu8ua_"
   },
   "source": [
    "## hlc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FFlVJgjocENh"
   },
   "outputs": [],
   "source": [
    "if run_test:\n",
    "        test_unified(\"oos\", \"prcs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ff1dksSt8ubA"
   },
   "source": [
    "## horizon\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VPL62tkj8ubA"
   },
   "outputs": [],
   "source": [
    "if run_test:\n",
    "\n",
    "        test_vols_per_horizon(mode=\"oos\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jI4GPCiA8ubA"
   },
   "source": [
    "# end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "45zLIW5xJTza"
   },
   "outputs": [],
   "source": [
    "plt.show()\n",
    "from google.colab import runtime\n",
    "runtime.unassign()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "L4",
   "machine_shape": "hm",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "s1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
