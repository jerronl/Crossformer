{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JaXYxzifbhst",
        "outputId": "3c5cb257-ad32-4567-d77f-76a871d69182"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "E:\\mydoc\\git\\trade\\analyics\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "d:\\ProgramData\\miniconda3\\envs\\e1\\Lib\\site-packages\\IPython\\core\\magics\\osm.py:417: UserWarning: using dhist requires you to install the `pickleshare` library.\n",
            "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
          ]
        }
      ],
      "source": [
        "\n",
        "if 'google.colab' in str(get_ipython()):\n",
        "  from google.colab import drive\n",
        "  drive.mount('/content/drive')\n",
        "  mydrive='/content/drive/MyDrive/volrt/'\n",
        "  source_path=mydrive+\"git/Crossformer\"\n",
        "  tables = ['volvN.csv', 'volvT.csv', 'volvA.csv', 'volvG.csv', ]\n",
        "  data_parser = {\n",
        "    \"vols\": {\n",
        "        \"patience\":30,\n",
        "        \"train_epochs\":100,\n",
        "    },\n",
        "    }\n",
        "  import os,sys\n",
        "  if not os.path.exists(source_path):\n",
        "    %cd $mydrive/git\n",
        "    !git clone https://github.com/jerronl/Crossformer.git\n",
        "    %cd $source_path\n",
        "  else:\n",
        "    %cd $source_path\n",
        "    !git checkout\n",
        "  !pip install einops\n",
        "\n",
        "  sys.path.append( source_path)\n",
        "else:\n",
        "  tables = ['volvA.csv']\n",
        "  mydrive= 'E:/mydoc/git/trade/analyics/'\n",
        "%cd $mydrive\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YeTQzMtGy8Ih",
        "outputId": "b18c6db6-6c0f-4e0b-bda6-3de95867e04e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Args in experiment:\n",
            "Namespace(data='vols', root_path='./datasets/', data_path=['volvN.csv'], data_split=[34560, 11520, 11520], checkpoints='./checkpoints/', in_len=20, out_len=50, seg_len=6, win_size=2, factor=10, data_dim=22, d_model=256, d_ff=512, n_heads=4, e_layers=3, dropout=0.2, baseline=False, num_workers=0, batch_size=32, train_epochs=20, patience=3, learning_rate=0.0001, lradj='type1', itr=5, save_pred=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3')\n",
            "Use GPU: cuda:0\n",
            ">>>>>>>start training : Crossformer_vols_il20_ol50_sl6_win2_fa10_dm256_nh4_el3_itr0>>>>>>>>>>>>>>>>>>>>>>>>>>\n"
          ]
        },
        {
          "ename": "NameError",
          "evalue": "name 'Dataset_MTS' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[5], line 82\u001b[0m\n\u001b[0;32m     80\u001b[0m exp \u001b[38;5;241m=\u001b[39m Exp(args) \u001b[38;5;66;03m# set experiments\u001b[39;00m\n\u001b[0;32m     81\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m>>>>>>>start training : \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m>>>>>>>>>>>>>>>>>>>>>>>>>>\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(setting))\n\u001b[1;32m---> 82\u001b[0m exp\u001b[38;5;241m.\u001b[39mtrain(setting)\n\u001b[0;32m     84\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m>>>>>>>testing : \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(setting))\n\u001b[0;32m     85\u001b[0m exp\u001b[38;5;241m.\u001b[39mtest(setting, args\u001b[38;5;241m.\u001b[39msave_pred)\n",
            "File \u001b[1;32mg:\\git\\Crossformer1\\cross_exp\\exp_crossformer.py:96\u001b[0m, in \u001b[0;36mExp_crossformer.train\u001b[1;34m(self, setting)\u001b[0m\n\u001b[0;32m     95\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain\u001b[39m(\u001b[38;5;28mself\u001b[39m, setting):\n\u001b[1;32m---> 96\u001b[0m     train_data, train_loader \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_data(flag \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     97\u001b[0m     vali_data, vali_loader \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_data(flag \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     98\u001b[0m     test_data, test_loader \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_data(flag \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
            "File \u001b[1;32mg:\\git\\Crossformer1\\cross_exp\\exp_crossformer.py:56\u001b[0m, in \u001b[0;36mExp_crossformer._get_data\u001b[1;34m(self, flag)\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     55\u001b[0m     shuffle_flag \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m; drop_last \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m; batch_size \u001b[38;5;241m=\u001b[39m args\u001b[38;5;241m.\u001b[39mbatch_size;\n\u001b[1;32m---> 56\u001b[0m data_set \u001b[38;5;241m=\u001b[39m Dataset_MTS(\n\u001b[0;32m     57\u001b[0m     root_path\u001b[38;5;241m=\u001b[39margs\u001b[38;5;241m.\u001b[39mroot_path,\n\u001b[0;32m     58\u001b[0m     data_path\u001b[38;5;241m=\u001b[39margs\u001b[38;5;241m.\u001b[39mdata_path,\n\u001b[0;32m     59\u001b[0m     flag\u001b[38;5;241m=\u001b[39mflag,\n\u001b[0;32m     60\u001b[0m     size\u001b[38;5;241m=\u001b[39m[args\u001b[38;5;241m.\u001b[39min_len, args\u001b[38;5;241m.\u001b[39mout_len],  \n\u001b[0;32m     61\u001b[0m     data_split \u001b[38;5;241m=\u001b[39m args\u001b[38;5;241m.\u001b[39mdata_split,\n\u001b[0;32m     62\u001b[0m )\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28mprint\u001b[39m(flag, \u001b[38;5;28mlen\u001b[39m(data_set))\n\u001b[0;32m     65\u001b[0m data_loader \u001b[38;5;241m=\u001b[39m DataLoader(\n\u001b[0;32m     66\u001b[0m     data_set,\n\u001b[0;32m     67\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[0;32m     68\u001b[0m     shuffle\u001b[38;5;241m=\u001b[39mshuffle_flag,\n\u001b[0;32m     69\u001b[0m     num_workers\u001b[38;5;241m=\u001b[39margs\u001b[38;5;241m.\u001b[39mnum_workers,\n\u001b[0;32m     70\u001b[0m     drop_last\u001b[38;5;241m=\u001b[39mdrop_last)\n",
            "\u001b[1;31mNameError\u001b[0m: name 'Dataset_MTS' is not defined"
          ]
        }
      ],
      "source": [
        "import argparse\n",
        "import torch\n",
        "\n",
        "from cross_exp.exp_crossformer import Exp_crossformer\n",
        "from utils.tools import string_split\n",
        "\n",
        "tables = [\"volvA.csv\"]\n",
        "mydrive = \"E:/mydoc/git/trade/analyics/\"\n",
        "\n",
        "parser = argparse.ArgumentParser(description=\"CrossFormer\")\n",
        "\n",
        "parser.add_argument(\"--data\", type=str, default=\"vols\", help=\"data\")\n",
        "parser.add_argument(\n",
        "    \"--root_path\", type=str, default=mydrive, help=\"root path of the data file\"\n",
        ")\n",
        "parser.add_argument(\"--data_path\", type=list, default=tables, help=\"data file\")\n",
        "parser.add_argument(\n",
        "    \"--data_split\",\n",
        "    type=str,\n",
        "    default=\"0.7,0.1,0.2\",\n",
        "    help=\"train/val/test split, can be ratio or number\",\n",
        ")\n",
        "parser.add_argument(\n",
        "    \"--checkpoints\",\n",
        "    type=str,\n",
        "    default=\"./checkpoints/\",\n",
        "    help=\"location to store model checkpoints\",\n",
        ")\n",
        "\n",
        "parser.add_argument(\"--in_len\", type=int, default=20, help=\"input MTS length (T)\")\n",
        "parser.add_argument(\"--out_len\", type=int, default=1, help=\"output MTS length (\\tau)\")\n",
        "parser.add_argument(\"--seg_len\", type=int, default=5, help=\"segment length (L_seg)\")\n",
        "parser.add_argument(\n",
        "    \"--win_size\", type=int, default=2, help=\"window size for segment merge\"\n",
        ")\n",
        "parser.add_argument(\n",
        "    \"--factor\",\n",
        "    type=int,\n",
        "    default=10,\n",
        "    help=\"num of routers in Cross-Dimension Stage of TSA (c)\",\n",
        ")\n",
        "\n",
        "parser.add_argument(\n",
        "    \"--data_dim\", type=int, default=32, help=\"Number of dimensions of the MTS data (D)\"\n",
        ")\n",
        "parser.add_argument(\n",
        "    \"--out_dim\", type=int, default=3*4+4+22, help=\"Number of dimensions of the output\"\n",
        ")\n",
        "parser.add_argument(\n",
        "    \"--d_model\", type=int, default=256, help=\"dimension of hidden states (d_model)\"\n",
        ")\n",
        "parser.add_argument(\n",
        "    \"--d_ff\", type=int, default=512, help=\"dimension of MLP in transformer\"\n",
        ")\n",
        "parser.add_argument(\"--n_heads\", type=int, default=4, help=\"num of heads\")\n",
        "parser.add_argument(\"--e_layers\", type=int, default=3, help=\"num of encoder layers (N)\")\n",
        "parser.add_argument(\"--dropout\", type=float, default=0.2, help=\"dropout\")\n",
        "\n",
        "parser.add_argument(\n",
        "    \"--baseline\",\n",
        "    action=\"store_true\",\n",
        "    help=\"whether to use mean of past series as baseline for prediction\",\n",
        "    default=False,\n",
        ")\n",
        "\n",
        "parser.add_argument(\n",
        "    \"--num_workers\", type=int, default=0, help=\"data loader num workers\"\n",
        ")\n",
        "parser.add_argument(\n",
        "    \"--batch_size\", type=int, default=32, help=\"batch size of train input data\"\n",
        ")\n",
        "parser.add_argument(\"--train_epochs\", type=int, default=20, help=\"train epochs\")\n",
        "parser.add_argument(\"--patience\", type=int, default=3, help=\"early stopping patience\")\n",
        "parser.add_argument(\n",
        "    \"--learning_rate\", type=float, default=1e-4, help=\"optimizer initial learning rate\"\n",
        ")\n",
        "parser.add_argument(\"--lradj\", type=str, default=\"type1\", help=\"adjust learning rate\")\n",
        "parser.add_argument(\"--itr\", type=int, default=5, help=\"experiments times\")\n",
        "\n",
        "parser.add_argument(\n",
        "    \"--save_pred\",\n",
        "    action=\"store_true\",\n",
        "    help=\"whether to save the predicted future MTS\",\n",
        "    default=False,\n",
        ")\n",
        "\n",
        "parser.add_argument(\"--use_gpu\", type=bool, default=True, help=\"use gpu\")\n",
        "# parser.add_argument(\"--use_gpu\", type=bool, default=False, help=\"use gpu\")\n",
        "parser.add_argument(\"--gpu\", type=int, default=0, help=\"gpu\")\n",
        "parser.add_argument(\n",
        "    \"--use_multi_gpu\", action=\"store_true\", help=\"use multiple gpus\", default=False\n",
        ")\n",
        "parser.add_argument(\n",
        "    \"--devices\", type=str, default=\"0,1,2,3\", help=\"device ids of multile gpus\"\n",
        ")\n",
        "\n",
        "args = parser.parse_args(args=[])\n",
        "\n",
        "args.use_gpu = True if torch.cuda.is_available() and args.use_gpu else False\n",
        "\n",
        "if args.use_gpu and args.use_multi_gpu:\n",
        "    args.devices = args.devices.replace(\" \", \"\")\n",
        "    device_ids = args.devices.split(\",\")\n",
        "    args.device_ids = [int(id_) for id_ in device_ids]\n",
        "    args.gpu = args.device_ids[0]\n",
        "    print(args.gpu)\n",
        "\n",
        "data_parser = {\n",
        "    \"vols\": {\n",
        "        \"patience\": 30,\n",
        "        \"train_epochs\": 100,\n",
        "    },\n",
        "}\n",
        "if args.data in data_parser.keys():\n",
        "    data_info = data_parser[args.data]\n",
        "    for k,v in data_info.items():\n",
        "        args.__setattr__(k,v)\n",
        "else:\n",
        "    args.data_split = string_split(args.data_split)\n",
        "\n",
        "print(\"Args in experiment:\")\n",
        "print(args)\n",
        "\n",
        "Exp = Exp_crossformer\n",
        "\n",
        "for ii in range(args.itr):\n",
        "    # setting record of experiments\n",
        "    setting = \"Crossformer_{}_il{}_ol{}_sl{}_win{}_fa{}_dm{}_nh{}_el{}_itr{}\".format(\n",
        "        args.data,\n",
        "        args.in_len,\n",
        "        args.out_len,\n",
        "        args.seg_len,\n",
        "        args.win_size,\n",
        "        args.factor,\n",
        "        args.d_model,\n",
        "        args.n_heads,\n",
        "        args.e_layers,\n",
        "        ii,\n",
        "    )\n",
        "\n",
        "    exp = Exp(args)  # set experiments\n",
        "    print(f\">>>>>>>start training : {setting}>>>>>>>>>>>>>>>>>>>>>>>>>>\")\n",
        "    exp.train(setting)\n",
        "\n",
        "    print(f\">>>>>>>testing : {setting}<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\")\n",
        "    exp.test(setting, args.save_pred)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
