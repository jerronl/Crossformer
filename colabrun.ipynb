{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5KB0_RDrJTzT"
   },
   "source": [
    "# setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JaXYxzifbhst"
   },
   "outputs": [],
   "source": [
    "run_test=True\n",
    "# run_test=False\n",
    "DO_TRAIN_VOLS = True   # 是否运行 VOLS 的 VOL_GRID 训练\n",
    "# DO_TRAIN_VOLS = False   # 是否运行 VOLS 的 VOL_GRID 训练\n",
    "DO_TRAIN_PRCS = True  # 是否运行 PRCS 的 LMSE x VOL_GRID 交叉训练\n",
    "# DO_TRAIN_PRCS = False  # 是否运行 PRCS 的 LMSE x VOL_GRID 交叉训练\n",
    "Provisional=True\n",
    "# Provisional=False\n",
    "\n",
    "\n",
    "epochs=(1,1,1,0,100) if Provisional else (15,500,3,10,100)\n",
    "\n",
    "cutdate='2025-11-18'\n",
    "valData=''\n",
    "use_amp=True\n",
    "use_amp=False\n",
    "# valData='2512'\n",
    "testData=''\n",
    "testData='new/'\n",
    "\n",
    "weight=(0.81,1.01,0.03,0)\n",
    "itr=5\n",
    "metrics_cnt=6\n",
    "import torch,sys\n",
    "\n",
    "if 'google.colab' in str(get_ipython()):\n",
    "  from google.colab import drive\n",
    "  drive.mount('/content/drive')\n",
    "  mydrive='/content/drive/MyDrive/volrt/'\n",
    "  checkpoints=mydrive+\"checkpoints/\"\n",
    "  source_path=mydrive+\"git/Crossformer\"\n",
    "  Provisional=Provisional and run_test\n",
    "  tables = [ 'volvTSLA.csv', 'volvAAPL.csv'] if Provisional else [ 'volvTSLA.csv', 'volvAAPL.csv', 'volvGOOG.csv','volvNVDA.csv', 'volvMETA.csv', 'volvMSFT.csv', 'volvAMZN.csv', ]\n",
    "  batch_size=int(torch.cuda.get_device_properties(0).total_memory/1e9+.5)*32\n",
    "  import os,sys\n",
    "  if not os.path.exists(source_path):\n",
    "    %cd $mydrive/git\n",
    "    !git clone https://github.com/jerronl/Crossformer.git\n",
    "    %cd $source_path\n",
    "  else:\n",
    "    %cd $source_path\n",
    "    # !git reset --hard HEAD\n",
    "    # !git pull origin master\n",
    "  %pip install einops #scikit-learn\n",
    "  sys.path.append( source_path)\n",
    "else:\n",
    "  tables = [ 'volvAAPL.csv']\n",
    "  testData=''\n",
    "  mydrive= 'E:/mydoc/git/trade/analyics/'\n",
    "  batch_size=32\n",
    "  sys.path.append(\"G:/git/Crossformer1/\")\n",
    "  itr=1\n",
    "  %load_ext autoreload\n",
    "  %autoreload 2\n",
    "%cd $mydrive\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-bmjLRHTfVt-"
   },
   "source": [
    "# Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mJovfe3GfVt-"
   },
   "outputs": [],
   "source": [
    "# === Mode Settings ===\n",
    "MODE = 'tuning'\n",
    "# MODE = 'prod'\n",
    "\n",
    "# Define Training Epochs based on Mode\n",
    "# Note: Prod uses epochs[1] from the setup tuple\n",
    "if MODE == 'tuning':\n",
    "    TRAIN_EPOCHS = min(30,epochs[1])\n",
    "else:\n",
    "    TRAIN_EPOCHS = epochs[1]\n",
    "\n",
    "# === Hyperparameter Grids ===\n",
    "lambda_vars = [0.0004, 0.0005, 0.0005]\n",
    "weight_overs = [1.4, 1.5]\n",
    "\n",
    "# VOL_GRID: Used for 'vols' training and general grid search\n",
    "# Format: (name, lambda_var, lambda_ce, lambda_shape, weight_over)\n",
    "VOL_GRID = []\n",
    "for lv in lambda_vars:\n",
    "    for wo in weight_overs:\n",
    "        name = f\"LV{lv}_WO{wo}\"\n",
    "        VOL_GRID.append((name, lv, 2.0, 0.0, wo))\n",
    "\n",
    "# LAMBDA_MSE_GRID: Used specifically for 'prcs' tuning if needed\n",
    "LAMBDA_MSE_GRID = [\n",
    "    (\"lmse0.2\", 0.2),\n",
    "    (\"lmse0.5\", 0.5),\n",
    "    (\"lmse1.0\", 1.0),\n",
    "]\n",
    "if Provisional:\n",
    "  VOL_GRID = VOL_GRID[:2]\n",
    "# Determine active grid slice based on epochs[3] (start) and epochs[4] (count)\n",
    "start_idx = epochs[3]\n",
    "end_idx = min(start_idx + epochs[4], len(VOL_GRID))\n",
    "active_grid_indices = range(start_idx, end_idx)\n",
    "\n",
    "print(f\"Mode: {MODE} | Train Epochs: {TRAIN_EPOCHS}\")\n",
    "print(f\"Active Grid Range: {start_idx} to {end_idx} (Total {len(active_grid_indices)} configs)\")\n",
    "for i in active_grid_indices:\n",
    "    print(f\"  [{i}] {VOL_GRID[i][0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NwWfFDUcfVt_"
   },
   "source": [
    "# Funcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dQsiHS9i8ua4"
   },
   "outputs": [],
   "source": [
    "from typing import Optional, Tuple\n",
    "from cross_exp.exp_crossformer import Exp_crossformer\n",
    "from data.data_loader import DatasetMTS, data_columns, data_names\n",
    "from data.data_def import set_cat\n",
    "import numpy as np, pandas as pd, matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# === Setup ===\n",
    "set_cat(20)\n",
    "from utils.tools import init_args, update_args\n",
    "\n",
    "args = init_args()\n",
    "data_parser = {}\n",
    "\n",
    "# =============================================================================\n",
    "# 1. 核心配置函数\n",
    "# =============================================================================\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# 2. 绘图与辅助函数 (修复了 IndexError)\n",
    "# =============================================================================\n",
    "\n",
    "\n",
    "def get_feature_names(ds_name, in_len):\n",
    "    cols = data_columns(ds_name)\n",
    "    return data_names(cols, 1)[0]\n",
    "\n",
    "\n",
    "def prepare_preds_trues_for_plot(preds_raw, trues_raw, ycat=0):\n",
    "    # 此函数将原始输出 (N, 20+5) 转换为用于绘制回归图的 (N, 5) 数组，并保留 IC 预测标签用于指标计算\n",
    "    preds = np.asarray(preds_raw)\n",
    "    trues = np.asarray(trues_raw)\n",
    "\n",
    "    if ycat > 0 and preds.shape[1] > trues.shape[1]:\n",
    "        # trues.shape[1] = 5\n",
    "        logits = preds[:, :ycat]  # (N, 20)\n",
    "\n",
    "        # 提取 5 个回归预测值 (IV_1 到 AUX)\n",
    "        # 假设原始 preds 结构是 [Logits (20), IV_1_Pred, ..., AUX_Pred (5)]\n",
    "        reg_preds = preds[:, ycat : ycat + trues.shape[1]].copy()  # (N, 5)\n",
    "\n",
    "        # 计算预测标签\n",
    "        logits_safe = np.where(np.isnan(logits), -np.inf, logits)\n",
    "        cls_pred = (\n",
    "            np.argmax(logits_safe, axis=1).astype(float) + 1.0\n",
    "        )  # 假设真实标签是 1-20，预测标签也转换为 1-20\n",
    "\n",
    "        # **将 IC 预测标签存储在第 5 列 (索引 4) 的位置**\n",
    "        # 这一列是辅助列，在绘图循环中会被跳过，但其值可用于 i=0 时的 ACCR 计算\n",
    "        reg_preds[:, 4] = cls_pred\n",
    "\n",
    "        # reg_preds 现在是 [IV_1_Pred, IV_2_Pred, IV_3_Pred, IV_4_Pred, IC_Pred_Label]\n",
    "        return reg_preds, trues\n",
    "\n",
    "    return preds, trues\n",
    "\n",
    "\n",
    "def _metrics_text(t, p):\n",
    "    # 标准回归指标 (用于 i=1, 2, 3)\n",
    "    diff = p - t\n",
    "    mae = np.mean(np.abs(diff))\n",
    "    mse = np.mean(diff**2)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mape = np.mean(np.abs(diff) / (np.abs(t) + 1e-12))\n",
    "\n",
    "    # ACCR 检查（此处应失败，但保留原始逻辑以防万一）\n",
    "    accr = np.nan\n",
    "    if (\n",
    "        len(t) > 0\n",
    "        and (np.unique(t).size <= 20)\n",
    "        and (np.unique(t).size == np.unique(p).size)\n",
    "    ):\n",
    "        accr = np.mean((p.round() == t.round())[~np.isnan(p) & ~np.isnan(t)])\n",
    "\n",
    "    if np.isnan(accr):\n",
    "        return f\"mae={mae:.4g}\\nrmse={rmse:.4g}\\nmape={mape:.3g}\"\n",
    "    else:\n",
    "        return f\"accr={accr:.3f}\\nmae={mae:.4g}\\nrmse={rmse:.4g}\"\n",
    "\n",
    "\n",
    "def _metrics_text_prcs_ic_iv(t_iv, p_iv, t_ic, p_ic_label):\n",
    "    # 组合指标 (用于 i=0)\n",
    "    # 1. 回归指标 (t_iv=trues[:, 0], p_iv=preds[:, 0])\n",
    "    diff = p_iv - t_iv\n",
    "    mae = np.mean(np.abs(diff))\n",
    "    mse = np.mean(diff**2)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mape = np.mean(np.abs(diff) / (np.abs(t_iv) + 1e-12))\n",
    "\n",
    "    # 2. 分类指标 (t_ic=trues[:, 0], p_ic_label=preds[:, 4])\n",
    "    accr = np.nan\n",
    "    if len(t_ic) > 0 and (np.unique(t_ic).size <= 20) and (~np.isnan(t_ic)).sum() > 0:\n",
    "        if np.unique(p_ic_label).size <= 20:\n",
    "            # t_ic 是真实标签 (1-20)，p_ic_label 是预测标签 (1-20)\n",
    "            accr = np.mean(\n",
    "                (p_ic_label.round() == t_ic.round())[\n",
    "                    ~np.isnan(p_ic_label) & ~np.isnan(t_ic)\n",
    "                ]\n",
    "            )\n",
    "\n",
    "    if not np.isnan(accr):\n",
    "        return f\"accr(IC)={accr:.3f}\\nmae(IV)={mae:.4g}\\nrmse(IV)={rmse:.4g}\"\n",
    "    else:\n",
    "        return f\"mae(IV)={mae:.4g}\\nrmse(IV)={rmse:.4g}\\nmape(IV)={mape:.3g}\"\n",
    "\n",
    "\n",
    "def _compute_limits_like_old_regplot(trues_list, preds_list, feat_idx, feat_name):\n",
    "    left, right = np.inf, -np.inf\n",
    "    for trues, preds in zip(trues_list, preds_list):\n",
    "        t = trues[:, feat_idx]\n",
    "        p = preds[:, feat_idx]\n",
    "        mask = ~np.isnan(t) & ~np.isnan(p)\n",
    "        if not mask.any():\n",
    "            continue\n",
    "        t, p = t[mask], p[mask]\n",
    "        if feat_name[:3] not in [\"dtm\", \"pmc\"]:\n",
    "            left = min(left, max(np.min(t), -5), max(np.min(p), -5))\n",
    "            right = max(right, min(np.max(t), 5), min(np.max(p), 5))\n",
    "        else:\n",
    "            left = min(left, np.min(t), np.min(p))\n",
    "            right = max(right, np.max(t), np.max(p))\n",
    "    if not np.isfinite(left) or not np.isfinite(right) or left == right:\n",
    "        left, right = -1, 1\n",
    "    return left, right\n",
    "\n",
    "\n",
    "def plot_residual_heatmap_family(\n",
    "    preds_raw,\n",
    "    trues_raw,\n",
    "    feature_names,\n",
    "    title,\n",
    "    bins=80,\n",
    "    ycat=0,\n",
    "    cols=4,\n",
    "    figsize_per_cell=4,\n",
    "):\n",
    "    preds, trues = prepare_preds_trues_for_plot(preds_raw, trues_raw, ycat=ycat)\n",
    "    out_dim = trues.shape[1]\n",
    "\n",
    "    # 修复 IndexError: 确保绘图维度不超过特征名称列表的长度\n",
    "    max_plot_dim = len(feature_names)\n",
    "    effective_dim = min(out_dim, max_plot_dim)\n",
    "    rows = int(np.ceil(effective_dim / cols))\n",
    "    fig, axes = plt.subplots(\n",
    "        rows,\n",
    "        cols,\n",
    "        figsize=(figsize_per_cell * cols, figsize_per_cell * rows),\n",
    "        squeeze=False,\n",
    "        constrained_layout=True,\n",
    "    )\n",
    "\n",
    "    for i in range(effective_dim):\n",
    "        r, c = divmod(i, cols)\n",
    "        ax = axes[r, c]\n",
    "        fname = feature_names[i]\n",
    "\n",
    "        # trues[:, i] 是 IV 真实值/IC 真实标签\n",
    "        t = trues[:, i]\n",
    "        # preds[:, i] 是 IV 预测值\n",
    "        p = preds[:, i]\n",
    "        mask = ~np.isnan(t) & ~np.isnan(p)\n",
    "        t, p = t[mask], p[mask]\n",
    "\n",
    "        if len(t) == 0:\n",
    "            ax.set_title(fname)\n",
    "            ax.axis(\"off\")\n",
    "            continue\n",
    "\n",
    "        # --- [i=0 处，同时显示 IC/IV 指标] ---\n",
    "        if ycat > 0 and i == 0:\n",
    "            # Classification True Label: t (trues[:, 0])\n",
    "            # Classification Pred Label: preds[:, 4] (IC_Pred_Label)\n",
    "            p_cls = preds[mask, 4]\n",
    "            metrics_text = _metrics_text_prcs_ic_iv(t, p, t, p_cls)\n",
    "        else:\n",
    "            # i=1, 2, 3 处，只显示回归指标\n",
    "            metrics_text = _metrics_text(t, p)\n",
    "        # --- [i=0 热力图现在可以绘制了] ---\n",
    "\n",
    "        left, right = _compute_limits_like_old_regplot(\n",
    "            [trues_raw], [preds_raw], i, fname\n",
    "        )\n",
    "        ax.hist2d(t, p, bins=bins, range=[[left, right], [left, right]], norm=\"log\")\n",
    "        ax.plot([left, right], [left, right], \"w--\", alpha=0.45)\n",
    "        ax.set_xlim(left, right)\n",
    "        ax.set_ylim(left, right)\n",
    "        ax.set_xlabel(\"True\")\n",
    "        ax.set_ylabel(\"Pred\")\n",
    "        ax.set_title(fname, fontsize=12)\n",
    "        ax.text(\n",
    "            0.02,\n",
    "            0.98,\n",
    "            metrics_text,\n",
    "            transform=ax.transAxes,\n",
    "            va=\"top\",\n",
    "            ha=\"left\",\n",
    "            fontsize=9,\n",
    "            bbox=dict(boxstyle=\"round,pad=0.25\", fc=\"black\", ec=\"none\", alpha=0.35),\n",
    "            color=\"white\",\n",
    "            zorder=3,\n",
    "        )\n",
    "\n",
    "    for i in range(effective_dim, rows * cols):\n",
    "        axes.flatten()[i].axis(\"off\")\n",
    "    # 移除 suptitle 的 y 参数，依靠外部 print 语句创建间距\n",
    "    if title:\n",
    "        fig.suptitle(title, fontsize=14)\n",
    "    plt.show()\n",
    "    plt.close(fig)\n",
    "\n",
    "\n",
    "def plot_multi_stock_residuals(\n",
    "    all_preds_raw,\n",
    "    all_trues_raw,\n",
    "    stock_labels,\n",
    "    feature_names,\n",
    "    ycat=0,\n",
    "    title=\"\",\n",
    "    bins=80,\n",
    "    cols=4,\n",
    "    figsize_per_cell=4,\n",
    "):\n",
    "    if not all_trues_raw:\n",
    "        return\n",
    "    out_dim = all_trues_raw[0].shape[1]\n",
    "\n",
    "    # 修复 IndexError: 确保绘图维度不超过特征名称列表的长度\n",
    "    max_plot_dim = len(feature_names)\n",
    "    effective_dim = min(out_dim, max_plot_dim)\n",
    "    rows = int(np.ceil(effective_dim / cols))\n",
    "    import matplotlib.gridspec as gridspec\n",
    "\n",
    "    fig = plt.figure(figsize=(figsize_per_cell * cols, figsize_per_cell * rows))\n",
    "    outer = gridspec.GridSpec(rows, cols, wspace=0.25, hspace=0.35)\n",
    "    cmap = plt.get_cmap(\"tab10\") if len(stock_labels) <= 10 else plt.get_cmap(\"tab20\")\n",
    "    colors = [cmap(i) for i in range(len(stock_labels))]\n",
    "\n",
    "    # 预处理所有数据，获取回归 preds 和 IC 预测标签\n",
    "    all_preds_reg, all_trues_reg = [], []\n",
    "    for preds_raw, trues_raw in zip(all_preds_raw, all_trues_raw):\n",
    "        p_reg, t_reg = prepare_preds_trues_for_plot(preds_raw, trues_raw, ycat=ycat)\n",
    "        all_preds_reg.append(p_reg)\n",
    "        all_trues_reg.append(t_reg)\n",
    "\n",
    "    for i in range(effective_dim):\n",
    "        r, c = divmod(i, cols)\n",
    "        ax_main = fig.add_subplot(outer[r, c])\n",
    "        ax_hist_bg = ax_main.twinx()\n",
    "        fname = feature_names[i]\n",
    "\n",
    "        # 1. 聚合所有数据用于指标计算和轴限制\n",
    "        combined_t, combined_p = all_trues_reg, all_preds_reg\n",
    "        left, right = _compute_limits_like_old_regplot(combined_t, combined_p, i, fname)\n",
    "        max_hist = 0\n",
    "\n",
    "        for j, (preds_reg, trues_reg) in enumerate(zip(all_preds_reg, all_trues_reg)):\n",
    "            t, p = trues_reg[:, i], preds_reg[:, i]\n",
    "            mask = ~np.isnan(t) & ~np.isnan(p)\n",
    "            t, p = t[mask], p[mask]\n",
    "\n",
    "            # 2. 绘制散点图和背景直方图\n",
    "            ax_main.scatter(\n",
    "                t,\n",
    "                p,\n",
    "                s=5,\n",
    "                alpha=0.4,\n",
    "                label=stock_labels[j],\n",
    "                color=colors[j % len(colors)],\n",
    "                zorder=2,\n",
    "            )\n",
    "            if len(t) > 1:\n",
    "                h, _, _ = ax_hist_bg.hist(\n",
    "                    t,\n",
    "                    bins=bins,\n",
    "                    density=True,\n",
    "                    alpha=0.15,\n",
    "                    color=colors[j % len(colors)],\n",
    "                    zorder=1,\n",
    "                )\n",
    "                max_hist = max(max_hist, np.max(h))\n",
    "\n",
    "        # 3. 计算聚合指标\n",
    "        all_t = np.concatenate([t[:, i] for t in combined_t])\n",
    "        all_p = np.concatenate([p[:, i] for p in combined_p])\n",
    "        mask = ~np.isnan(all_t) & ~np.isnan(all_p)\n",
    "        t_all, p_all = all_t[mask], all_p[mask]\n",
    "\n",
    "        if len(t_all) == 0:\n",
    "            ax_main.set_title(fname)\n",
    "            ax_main.axis(\"off\")\n",
    "            continue\n",
    "\n",
    "        if ycat > 0 and i == 0:\n",
    "            # Classification True Label: t_all (trues[:, 0])\n",
    "            # Classification Pred Label: preds[:, 4]\n",
    "            all_p_cls = np.concatenate([p[:, 4] for p in combined_p])\n",
    "            p_cls_all = all_p_cls[mask]\n",
    "            metrics_text = _metrics_text_prcs_ic_iv(t_all, p_all, t_all, p_cls_all)\n",
    "        else:\n",
    "            metrics_text = _metrics_text(t_all, p_all)\n",
    "\n",
    "        # 4. 绘制轴线和文本\n",
    "        ax_hist_bg.tick_params(\n",
    "            axis=\"y\", left=False, right=False, labelleft=False, labelright=False\n",
    "        )\n",
    "        ax_hist_bg.set_ylim(0, max_hist * 3.0 if max_hist > 0 else 1)\n",
    "        ax_hist_bg.set_ylabel(\"\")\n",
    "\n",
    "        ax_main.plot([left, right], [left, right], \"k--\", alpha=0.45)\n",
    "        ax_main.set_xlim(left, right)\n",
    "        ax_main.set_ylim(left, right)\n",
    "        ax_main.set_title(fname, fontsize=10)\n",
    "        ax_main.text(\n",
    "            0.02,\n",
    "            0.98,\n",
    "            metrics_text,\n",
    "            transform=ax_main.transAxes,\n",
    "            va=\"top\",\n",
    "            ha=\"left\",\n",
    "            fontsize=9,\n",
    "            bbox=dict(boxstyle=\"round,pad=0.25\", fc=\"black\", ec=\"none\", alpha=0.35),\n",
    "            color=\"white\",\n",
    "            zorder=3,\n",
    "        )\n",
    "        ax_main.legend(fontsize=7, loc=\"lower right\", framealpha=0.5)\n",
    "\n",
    "    for i in range(effective_dim, rows * cols):\n",
    "        fig.add_subplot(outer[i]).axis(\"off\")\n",
    "    # 移除 suptitle 的 y 参数，依靠外部 print 语句创建间距\n",
    "    if title:\n",
    "        fig.suptitle(title, fontsize=14)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "def plot_prcs_avg_prob_by_true_class(preds_raw, trues_raw, ycat, title=\"\"):\n",
    "    # 此函数接收原始 preds (包含 logits) 和 trues (包含真实标签)\n",
    "    preds = np.asarray(preds_raw)\n",
    "    trues = np.asarray(trues_raw)\n",
    "\n",
    "    # 提取 logits\n",
    "    logits = preds[:, :ycat]\n",
    "\n",
    "    logits = np.where(np.isnan(logits), -np.inf, logits)\n",
    "    probs = np.exp(logits - np.max(logits, axis=1, keepdims=True))\n",
    "    probs = probs / (np.sum(probs, axis=1, keepdims=True) + 1e-12)\n",
    "\n",
    "    # trues[:, 0] 是 IC label (1-20)\n",
    "    true_cls = trues[:, 0].astype(int)\n",
    "    x = np.arange(1, ycat + 1)\n",
    "    fig, ax = plt.subplots(figsize=(6, 4))\n",
    "\n",
    "    for k in range(1, ycat + 1):\n",
    "        m = true_cls == k\n",
    "        if m.any():\n",
    "            ax.plot(x, probs[m].mean(axis=0), marker=\"o\", label=f\"True={k}\", alpha=0.85)\n",
    "\n",
    "    ax.set_title(title)\n",
    "    ax.set_xlabel(\"Predicted Class\")\n",
    "    ax.set_ylabel(\"Average Probability\")\n",
    "    ax.legend(fontsize=8, loc=\"upper right\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# 3. 配置与构建 Parsers & Training Functions (重构 train_models_for_volgrid)\n",
    "# =============================================================================\n",
    "\n",
    "COMMON_SETTINGS = {\n",
    "    \"e_layers\": 5,\n",
    "    \"d_model\": 512,\n",
    "    \"lradj\": \"type2\",\n",
    "    \"checkpoints\": checkpoints,\n",
    "}\n",
    "\n",
    "\n",
    "def build_parser(mode, ds, extra_query=\"\", root_override=None):\n",
    "    root = mydrive + valData if mode == \"insample\" else mydrive + testData\n",
    "    if root_override:\n",
    "        root = root_override\n",
    "    q = (\n",
    "        extra_query\n",
    "        if mode == \"insample\"\n",
    "        else (f\"date>'#{cutdate}'\" + (\" and \" + extra_query if extra_query else \"\"))\n",
    "    )\n",
    "    ds_config = COMMON_SETTINGS.copy()\n",
    "    ds_config[\"root_path\"] = root\n",
    "    ds_config[\"data_path\"] = tables\n",
    "    ds_config[\"weight\"] = weight[0] if ds == \"vols\" else weight[1]\n",
    "    if q:\n",
    "        ds_config[\"query\"] = q\n",
    "    parser = {}\n",
    "    if ds != \"vols\":\n",
    "        parser[\"vols\"] = {\"checkpoints\": checkpoints}\n",
    "    parser[ds] = ds_config\n",
    "    return parser\n",
    "\n",
    "\n",
    "def apply_volgrid_override(parser_config: dict, ds: str, grid_entry: list) -> dict:\n",
    "    if ds in parser_config and isinstance(parser_config[ds], dict):\n",
    "        temp_config = parser_config[ds].copy()\n",
    "        is_full_parser = True\n",
    "    else:\n",
    "        temp_config = parser_config.copy()\n",
    "        is_full_parser = False\n",
    "\n",
    "    param_tag, lv, lce, lshape, wo = grid_entry\n",
    "    temp_config[\"param_tag\"] = param_tag\n",
    "    temp_config[\"lambda_var\"] = lv\n",
    "    temp_config[\"lambda_ce\"] = lce\n",
    "    temp_config[\"lambda_shape\"] = lshape\n",
    "    temp_config[\"weight_overs\"] = wo\n",
    "\n",
    "    if is_full_parser:\n",
    "        parser_config[ds] = temp_config\n",
    "        return parser_config\n",
    "    else:\n",
    "        return temp_config\n",
    "\n",
    "\n",
    "def build_train_parser(root_path=None):\n",
    "    if root_path == None:\n",
    "        root_path = mydrive + valData\n",
    "    base = {\n",
    "        \"patience\": epochs[0],\n",
    "        \"train_epochs\": TRAIN_EPOCHS,\n",
    "        \"learning_rate\": 0.01,\n",
    "        \"data_split\": [0.7, 0.15, 0.15],\n",
    "        \"batch_size\": batch_size * 2 // 5,\n",
    "        \"e_layers\": 5,\n",
    "        \"d_model\": 512,\n",
    "        \"lradj\": \"type2\",\n",
    "        \"checkpoints\": checkpoints,\n",
    "        \"root_path\": root_path,\n",
    "        \"data_path\": tables,\n",
    "        \"profile_mode\": False,\n",
    "        \"use_amp\": use_amp,\n",
    "    }\n",
    "    return {\n",
    "        \"vols\": {**base, \"data\": \"vols\", \"weight\": weight[0], \"over_weight\": weight[2]},\n",
    "        \"prcs\": {**base, \"data\": \"prcs\", \"weight\": weight[1], \"over_weight\": weight[3]},\n",
    "    }\n",
    "\n",
    "\n",
    "def train_models_for_volgrid(mode: str):\n",
    "    \"\"\"\n",
    "    只运行 VOLS 的 VOL_GRID 训练。\n",
    "    \"\"\"\n",
    "    global args, data_parser\n",
    "    print(f\"--- Starting VOLS_GRID Training (Mode: {mode}) ---\")\n",
    "    data_parser = build_train_parser(mydrive + valData)\n",
    "    num_cycles = epochs[2]\n",
    "\n",
    "    # 1. Train VOLS\n",
    "    print(\n",
    "        f\"\\n=== Starting VOLS Training ({len(active_grid_indices)} configs over {num_cycles} cycles) ===\"\n",
    "    )\n",
    "    lr_vols = data_parser[\"vols\"][\"learning_rate\"]\n",
    "    SWEEP_KEYS_VOLS = [\"lambda_ce\", \"lambda_shape\", \"over_weight\"]\n",
    "\n",
    "    for cycle in range(num_cycles):\n",
    "        current_lr = lr_vols / (3.0**cycle)\n",
    "        data_parser[\"vols\"][\"learning_rate\"] = current_lr\n",
    "\n",
    "        for p_idx in active_grid_indices:\n",
    "            param_entry = VOL_GRID[p_idx]\n",
    "            param_tag = param_entry[0]\n",
    "\n",
    "            parser_v = apply_volgrid_override(\n",
    "                data_parser[\"vols\"].copy(), \"vols\", param_entry\n",
    "            )\n",
    "            setting_v = update_args(\n",
    "                args, {\"vols\": parser_v}, 0, \"vols\", SWEEP_KEYS=SWEEP_KEYS_VOLS\n",
    "            )\n",
    "\n",
    "            exp_v = Exp_crossformer(args)\n",
    "            # 打印当前参数组的下标\n",
    "            print(\n",
    "                f\"[VOLS | Cycle {cycle+1}/{num_cycles} | IDX {p_idx} | {param_tag}] lr={current_lr:.6f} {setting_v}\"\n",
    "            )\n",
    "            exp_v.train(setting_v, \"vols\")\n",
    "\n",
    "\n",
    "def train_models_for_lmse_grid(mode: str):\n",
    "    \"\"\"\n",
    "    运行 PRCS 的 LMSE_GRID x VOL_GRID 交叉训练。\n",
    "    \"\"\"\n",
    "    if not LAMBDA_MSE_GRID or not VOL_GRID:\n",
    "        print(\"Error: 训练网格未定义或为空。退出 LMSE grid 训练。\")\n",
    "        return\n",
    "\n",
    "    data_parser = build_train_parser()\n",
    "    num_cycles = epochs[2]\n",
    "    num_lmse_settings = len(LAMBDA_MSE_GRID)\n",
    "    lr_prcs = data_parser[\"prcs\"][\"learning_rate\"]\n",
    "    SWEEP_KEYS_PRCS_LMSE = [\"lambda_ce\", \"lambda_shape\", \"over_weight\", \"lambda_mse\"]\n",
    "\n",
    "    print(\"\\n--- Starting PRCS (LMSE + VOL) Cross-Grid Training (Idx >= 1000) ---\")\n",
    "\n",
    "    for cycle in range(num_cycles):\n",
    "        current_lr = lr_prcs / (3.0**cycle)\n",
    "        data_parser[\"prcs\"][\"learning_rate\"] = current_lr\n",
    "\n",
    "        for vol_idx_inner, vol_entry in enumerate(VOL_GRID):\n",
    "            for lmse_idx, (lmse_tag, lambda_mse_value) in enumerate(LAMBDA_MSE_GRID):\n",
    "\n",
    "                parser_p = data_parser[\"prcs\"].copy()\n",
    "                # 应用 VOL_GRID 参数\n",
    "                parser_p = apply_volgrid_override(parser_p, \"prcs\", vol_entry)\n",
    "\n",
    "                combined_tag = f\"{parser_p['param_tag']}_{lmse_tag}\"\n",
    "                parser_p[\"param_tag\"] = combined_tag\n",
    "                # 应用 LMSE 参数\n",
    "                parser_p[\"lambda_mse\"] = lambda_mse_value\n",
    "\n",
    "                unique_p_idx = (vol_idx_inner * num_lmse_settings) + lmse_idx + 1000\n",
    "                full_parser = {\"vols\": {\"checkpoints\": checkpoints}, \"prcs\": parser_p}\n",
    "\n",
    "                setting_p = update_args(\n",
    "                    args, full_parser, 0, \"prcs\", SWEEP_KEYS=SWEEP_KEYS_PRCS_LMSE\n",
    "                )\n",
    "                exp_p = Exp_crossformer(args)\n",
    "\n",
    "                # 打印当前参数组的下标\n",
    "                print(\n",
    "                    f\"[PRCS(LMSE+VOL) | Cycle {cycle+1}/{num_cycles} | IDX {unique_p_idx} | Tag {combined_tag}] lr={current_lr:.6f}, L_MSE={lambda_mse_value:.4f}\"\n",
    "                )\n",
    "                exp_p.train(setting_p, \"prcs\")\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# 4. Testing Functions (添加了标题空行和 test_prcs_lmse_settings 汇总)\n",
    "# =============================================================================\n",
    "\n",
    "\n",
    "def run_test_one_setting(\n",
    "    exp,\n",
    "    setting_str,\n",
    "    ds,\n",
    "    dep_var,\n",
    "    ycat,\n",
    "    title_prefix,\n",
    "    by_stock=False,\n",
    "    stock_tables=None,\n",
    "    plot_individual_heatmaps=True,\n",
    "):\n",
    "    metrics_list, all_preds, all_trues = [], [], []\n",
    "    if by_stock:\n",
    "        for tb in stock_tables:\n",
    "            # exp.test returns raw preds and trues (inverse=True)\n",
    "            preds, trues, m = exp.test(\n",
    "                setting_str, ds, True, data_path=[tb], inverse=True\n",
    "            )\n",
    "            metrics_list.append(m)\n",
    "            all_preds.append(preds)\n",
    "            all_trues.append(trues)\n",
    "            if plot_individual_heatmaps:\n",
    "                # 添加空行和标题，满足用户要求\n",
    "                print(f\"\\n--- Residual Heatmap: {title_prefix} {tb} ---\")\n",
    "                plot_residual_heatmap_family(\n",
    "                    preds, trues, dep_var, title=f\"{title_prefix} {tb}\", ycat=ycat\n",
    "                )\n",
    "                if ds == \"prcs\":\n",
    "                    print(f\"\\n--- Avg Prob Plot: {title_prefix} avg prob {tb} ---\")\n",
    "                    plot_prcs_avg_prob_by_true_class(\n",
    "                        preds, trues, ycat=ycat, title=f\"{title_prefix} avg prob {tb}\"\n",
    "                    )\n",
    "        return metrics_list, all_preds, all_trues\n",
    "    else:\n",
    "        preds, trues, m = exp.test(setting_str, ds, True, inverse=True)\n",
    "        metrics_list.append(m)\n",
    "        # 添加空行和标题，满足用户要求\n",
    "        print(f\"\\n--- Residual Heatmap: {title_prefix} ---\")\n",
    "        plot_residual_heatmap_family(\n",
    "            preds, trues, dep_var, title=title_prefix, ycat=ycat\n",
    "        )\n",
    "        if ds == \"prcs\":\n",
    "            print(f\"\\n--- Avg Prob Plot: {title_prefix} avg prob ---\")\n",
    "            plot_prcs_avg_prob_by_true_class(\n",
    "                preds, trues, ycat=ycat, title=f\"{title_prefix} avg prob\"\n",
    "            )\n",
    "        return metrics_list, None, None\n",
    "\n",
    "\n",
    "def generate_final_summary(summary_records):\n",
    "    if not summary_records:\n",
    "        print(\"No records to summarize.\")\n",
    "        return\n",
    "    df = pd.DataFrame(summary_records)\n",
    "    cols_order = [\n",
    "        \"exp\",\n",
    "        \"dataset\",\n",
    "        \"setting\",\n",
    "        \"base_lr\",\n",
    "        \"lambda_var\",\n",
    "        \"weight_over\",\n",
    "        \"lambda_ce\",\n",
    "        \"lambda_shape\",\n",
    "        \"lambda_mse\",\n",
    "        \"mae\",\n",
    "        \"mse\",\n",
    "        \"rmse\",\n",
    "        \"mape\",\n",
    "        \"mdst\",\n",
    "        \"accr\",\n",
    "        \"epochs\",\n",
    "    ]\n",
    "    print(df[[c for c in cols_order if c in df.columns]].to_string())\n",
    "\n",
    "\n",
    "def test_all_volgrid_settings(\n",
    "    mode: str, ds: str, by_stock: bool = True, plot_residuals: bool = True\n",
    "):\n",
    "    base_parser = build_parser(mode, ds)\n",
    "    dep_var = get_feature_names(ds, getattr(args, \"seq_len\", 1))\n",
    "    ycat = data_columns(ds).get(\"ycat\", 0) if ds == \"prcs\" else 0\n",
    "    summary_data = []\n",
    "    print(\n",
    "        f\"\\n--- Testing {ds} in {mode} ({len(active_grid_indices)} configurations) ---\"\n",
    "    )\n",
    "    SWEEP_KEYS = []\n",
    "    if ds == \"vols\":\n",
    "        SWEEP_KEYS = [\"lambda_ce\", \"lambda_shape\", \"over_weight\"]\n",
    "\n",
    "    for p_idx in active_grid_indices:\n",
    "        ps = VOL_GRID[p_idx]\n",
    "        param_name, lv, lce, lshape, wo = ps\n",
    "        parser_config = apply_volgrid_override(base_parser.copy(), ds, ps)\n",
    "        setting_str = update_args(args, parser_config, 0, ds, SWEEP_KEYS=SWEEP_KEYS)\n",
    "        args.param_tag = param_name\n",
    "        exp = Exp_crossformer(args)\n",
    "        title = f\"{ds} {mode} {param_name}\"\n",
    "\n",
    "        m_list, preds_fam, trues_fam = run_test_one_setting(\n",
    "            exp,\n",
    "            setting_str,\n",
    "            ds,\n",
    "            dep_var,\n",
    "            ycat,\n",
    "            title,\n",
    "            by_stock=by_stock,\n",
    "            stock_tables=tables,\n",
    "            plot_individual_heatmaps=plot_residuals,\n",
    "        )\n",
    "\n",
    "        if by_stock and preds_fam and plot_residuals:\n",
    "            # 绘制汇总图\n",
    "            print(f\"\\n--- AGGREGATED RESIDUAL PLOT: {title} ---\")\n",
    "            plot_multi_stock_residuals(\n",
    "                preds_fam,\n",
    "                trues_fam,\n",
    "                tables,\n",
    "                dep_var,\n",
    "                ycat=ycat,\n",
    "                title=f\"AGGREGATED {title}\",\n",
    "            )\n",
    "\n",
    "        avg_metrics = np.mean(np.array(m_list), axis=0)\n",
    "        rec = {\n",
    "            \"exp\": param_name,\n",
    "            \"dataset\": ds,\n",
    "            \"setting\": setting_str,\n",
    "            \"base_lr\": 0.01,\n",
    "            \"lambda_var\": lv,\n",
    "            \"weight_over\": wo,\n",
    "            \"lambda_ce\": lce,\n",
    "            \"lambda_shape\": lshape,\n",
    "            \"mae\": avg_metrics[0],\n",
    "            \"mse\": avg_metrics[1],\n",
    "            \"rmse\": avg_metrics[2],\n",
    "            \"mape\": avg_metrics[3],\n",
    "            \"mdst\": avg_metrics[4],\n",
    "            \"accr\": avg_metrics[5],\n",
    "            \"epochs\": TRAIN_EPOCHS,\n",
    "        }\n",
    "        summary_data.append(rec)\n",
    "    generate_final_summary(summary_data)\n",
    "    return summary_data\n",
    "\n",
    "\n",
    "def test_prcs_lmse_settings(\n",
    "    mode: str, by_stock: bool = True, plot_residuals: bool = True\n",
    "):\n",
    "    ds = \"prcs\"\n",
    "    dep_var = get_feature_names(ds, getattr(args, \"seq_len\", 1))\n",
    "    ycat = data_columns(ds).get(\"ycat\", 0)\n",
    "    num_lmse_settings = len(LAMBDA_MSE_GRID)\n",
    "    summary_data = []  # 初始化汇总列表\n",
    "    print(f\"\\n--- Starting PRCS LMSE/VOL Cross Grid Testing ({mode}) ---\")\n",
    "    SWEEP_KEYS_PRCS_LMSE = [\"lambda_ce\", \"lambda_shape\", \"over_weight\", \"lambda_mse\"]\n",
    "\n",
    "    for vol_idx_inner, vol_entry in enumerate(VOL_GRID):\n",
    "        for lmse_idx, (lmse_tag, lambda_mse_value) in enumerate(LAMBDA_MSE_GRID):\n",
    "            unique_p_idx = (vol_idx_inner * num_lmse_settings) + lmse_idx + 1000\n",
    "            test_parser = build_parser(mode, ds)\n",
    "            ds_config = apply_volgrid_override(test_parser[ds].copy(), ds, vol_entry)\n",
    "            combined_tag = f\"{ds_config['param_tag']}_{lmse_tag}\"\n",
    "            ds_config[\"param_tag\"] = combined_tag\n",
    "            ds_config[\"lambda_mse\"] = lambda_mse_value\n",
    "            test_parser[ds] = ds_config\n",
    "            setting = update_args(\n",
    "                args, test_parser, 0, ds, SWEEP_KEYS=SWEEP_KEYS_PRCS_LMSE\n",
    "            )\n",
    "            print(f\"[TEST PRCS | Idx {unique_p_idx} | {combined_tag}]\")\n",
    "            exp = Exp_crossformer(args)\n",
    "\n",
    "            # 运行测试并获取指标和数据\n",
    "            m_list, preds_fam, trues_fam = run_test_one_setting(\n",
    "                exp,\n",
    "                setting,\n",
    "                ds,\n",
    "                dep_var,\n",
    "                ycat,\n",
    "                f\"{mode} {combined_tag}\",\n",
    "                by_stock,\n",
    "                tables,\n",
    "                plot_residuals,\n",
    "            )\n",
    "\n",
    "            # 绘制汇总图\n",
    "            if by_stock and preds_fam and plot_residuals:\n",
    "                print(f\"\\n--- AGGREGATED RESIDUAL PLOT: {mode} {combined_tag} ---\")\n",
    "                plot_multi_stock_residuals(\n",
    "                    preds_fam,\n",
    "                    trues_fam,\n",
    "                    tables,\n",
    "                    dep_var,\n",
    "                    ycat=ycat,\n",
    "                    title=f\"AGGREGATED {mode} {combined_tag}\",\n",
    "                )\n",
    "\n",
    "            # 收集汇总数据\n",
    "            avg_metrics = np.mean(np.array(m_list), axis=0)\n",
    "            lv, lce, lshape, wo = vol_entry[1:]\n",
    "            rec = {\n",
    "                \"exp\": combined_tag,\n",
    "                \"dataset\": ds,\n",
    "                \"setting\": setting,\n",
    "                \"base_lr\": 0.01,\n",
    "                \"lambda_var\": lv,\n",
    "                \"weight_over\": wo,\n",
    "                \"lambda_ce\": lce,\n",
    "                \"lambda_shape\": lshape,\n",
    "                \"lambda_mse\": lambda_mse_value,\n",
    "                \"mae\": avg_metrics[0],\n",
    "                \"mse\": avg_metrics[1],\n",
    "                \"rmse\": avg_metrics[2],\n",
    "                \"mape\": avg_metrics[3],\n",
    "                \"mdst\": avg_metrics[4],\n",
    "                \"accr\": avg_metrics[5],\n",
    "                \"epochs\": TRAIN_EPOCHS,\n",
    "            }\n",
    "            summary_data.append(rec)\n",
    "\n",
    "    print(f\"--- PRCS LMSE/VOL Cross Grid Testing Completed ({mode}) ---\")\n",
    "    generate_final_summary(summary_data)  # 输出汇总表格\n",
    "    return summary_data\n",
    "\n",
    "\n",
    "def test_vols_per_horizon(\n",
    "    mode: str, param_entry: Optional[Tuple[str, float, float, float, float]] = None\n",
    "):\n",
    "    ds = \"vols\"\n",
    "    dep_var = get_feature_names(ds, getattr(args, \"seq_len\", 1))\n",
    "    horizons = [5, 10, 20]\n",
    "    param_list = (\n",
    "        [param_entry] if param_entry else [VOL_GRID[i] for i in active_grid_indices]\n",
    "    )\n",
    "    print(f\"\\n--- Running {mode} VOLS Per-Horizon Test (Horizons: {horizons}) ---\")\n",
    "    SWEEP_KEYS = [\"lambda_ce\", \"lambda_shape\", \"over_weight\"]\n",
    "\n",
    "    for ps in param_list:\n",
    "        param_name = ps[0]\n",
    "        for h_len in horizons:\n",
    "            base_parser = build_parser(mode, ds)\n",
    "            parser = apply_volgrid_override(base_parser.copy(), ds, ps)\n",
    "            hq = f\"floor(horizon)=={h_len}\"\n",
    "            existing_query = parser[ds].get(\"query\", \"\")\n",
    "            parser[ds][\"query\"] = (existing_query + \" and \" + hq).lstrip(\" and \")\n",
    "            setting_str = update_args(args, parser, 0, ds, SWEEP_KEYS=SWEEP_KEYS)\n",
    "            args.param_tag = param_name\n",
    "            exp = Exp_crossformer(args)\n",
    "            run_test_one_setting(\n",
    "                exp,\n",
    "                setting_str,\n",
    "                ds,\n",
    "                dep_var,\n",
    "                0,\n",
    "                title_prefix=f\"{ds} {mode} {param_name} H{h_len}\",\n",
    "                by_stock=False,\n",
    "                plot_individual_heatmaps=True,\n",
    "            )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qCfd-gU7JTzW"
   },
   "source": [
    "# train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "edfP8114fVuB"
   },
   "outputs": [],
   "source": [
    "# --- [Train] ---\n",
    "if run_test == False:\n",
    "    # ... (其他初始化代码, 如 drive.mount) ...\n",
    "\n",
    "    if DO_TRAIN_VOLS:\n",
    "        print(\"\\n--- [Train VOLS with VOL_GRID] ---\")\n",
    "        train_models_for_volgrid(\"insample\") # 仅训练 VOLS\n",
    "\n",
    "    if DO_TRAIN_PRCS:\n",
    "        print(\"\\n--- [Train PRCS with LMSE x VOL_GRID] ---\")\n",
    "        train_models_for_lmse_grid(\"insample\") # 训练 PRCS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4kj_rRG1J66H"
   },
   "outputs": [],
   "source": [
    "if not run_test:\n",
    "    from google.colab import runtime\n",
    "    runtime.unassign()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "84_0x76B135B"
   },
   "outputs": [],
   "source": [
    "if not run_test:\n",
    "    from cross_exp.exp_crossformer import Exp_crossformer\n",
    "    from data.data_loader import DatasetMTS\n",
    "    data_parser = {\n",
    "        \"vols\": {\n",
    "            'data':'vols',\n",
    "            \"patience\":epochs[0],\n",
    "            \"train_epochs\":epochs[1],\n",
    "            'learning_rate':0.01,\n",
    "            'data_split':[0.7,0.15,0.15],\n",
    "            'batch_size':batch_size*2//5,\n",
    "            'e_layers':5,\n",
    "            'd_model':512,\n",
    "            'lradj':'type2',\n",
    "            \"checkpoints\":checkpoints,\n",
    "            'root_path':mydrive+valData,\n",
    "            'data_path':tables,\n",
    "            'weight':weight[0],\n",
    "            'over_weight':weight[2],\n",
    "            'profile_mode':False,\n",
    "            'use_amp':use_amp\n",
    "        },\n",
    "        \"prcs\":{\n",
    "            'data':'prcs',\n",
    "            'weight':weight[1],\n",
    "            'over_weight':weight[3],\n",
    "        }\n",
    "        }\n",
    "    s=epochs[3]\n",
    "    for _ in range(epochs[2]):\n",
    "        data_parser[\"vols\"][\"learning_rate\"]=.01\n",
    "        for i in range(epochs[2]):\n",
    "            for ii in range(s,itr):\n",
    "                # setting record of experiments\n",
    "                # data_parser[\"vols\"]['weight']=weight[0]\n",
    "                setting=update_args(args,data_parser,ii)\n",
    "                DatasetMTS.clear()\n",
    "                # drive.mount('/content/drive/',force_remount=True)\n",
    "                # !google-drive-ocamlfuse -cc # 注释掉这个bug行\n",
    "\n",
    "                exp = Exp_crossformer(args)  # set experiments\n",
    "                print(f\"start training :lr={data_parser[\"vols\"][\"learning_rate\"]} {setting}\")\n",
    "                exp.train(setting, \"vols\")\n",
    "\n",
    "                print(f\">>>>>>>testing : {setting}<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\")\n",
    "                preds, trues,_ = exp.test(setting, 'vols', True, data_path=[tables[-1]], inverse=True)\n",
    "                print(preds.shape, trues.shape)\n",
    "\n",
    "                # data_parser[\"vols\"]['weight']=weight[1]\n",
    "                setting=update_args(args,data_parser,ii,'prcs')\n",
    "                DatasetMTS.clear()\n",
    "                exp = Exp_crossformer(args)  # set experiments\n",
    "                print(f\"start training :lr={data_parser[\"vols\"][\"learning_rate\"]} {setting}\")\n",
    "                exp.train(setting, \"prcs\")\n",
    "                preds, trues,_ = exp.test(setting, 'prcs', True, data_path=[tables[-1]], inverse=True)\n",
    "                print(preds.shape, trues.shape)\n",
    "            data_parser[\"vols\"][\"learning_rate\"]/=3.\n",
    "            s=0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "066vGmCNJTzY"
   },
   "source": [
    "# test\n",
    "##  PART A — In-sample (test split of same source)\n",
    "Subparts:\n",
    "1. vols per-stock heatmap  \n",
    "2. prcs per-stock heatmap + avg prob by true class  \n",
    "3. vols per-horizon heatmap\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "w03KqC8jJTzY"
   },
   "outputs": [],
   "source": [
    "\n",
    "if run_test:\n",
    "            test_all_volgrid_settings(mode=\"insample\", ds=\"vols\", by_stock=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wkGkKgp98ua9"
   },
   "source": [
    "## In-sample - Prcs Per-Stock\n",
    "\n",
    "Subparts:\n",
    "1. vols per-stock heatmap  \n",
    "2. prcs per-stock heatmap + avg prob by true class  \n",
    "3. vols per-horizon heatmap\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JKW9afa-cENf"
   },
   "outputs": [],
   "source": [
    "if run_test:\n",
    "\n",
    "            test_prcs_lmse_settings(mode=\"insample\", by_stock=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L9IXNP9K8ua-"
   },
   "source": [
    "## In-sample - Horizon\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rpzR-1aN8ua-"
   },
   "outputs": [],
   "source": [
    "if run_test:\n",
    "        test_vols_per_horizon(mode=\"insample\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KBfRZp9y8ua-"
   },
   "source": [
    "# PART B — Out-of-sample (testData, cutdate+)\n",
    "## OOS - Vols Per-Stock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "F6WWmBSmcENg"
   },
   "outputs": [],
   "source": [
    "if run_test:\n",
    "\n",
    "        test_all_volgrid_settings(mode=\"oos\", ds=\"vols\", by_stock=True, plot_residuals=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rWJgEQeu8ua_"
   },
   "source": [
    "## hlc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FFlVJgjocENh"
   },
   "outputs": [],
   "source": [
    "if run_test:\n",
    "        test_all_volgrid_settings(mode=\"oos\", ds=\"prcs\", by_stock=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ff1dksSt8ubA"
   },
   "source": [
    "## horizon\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VPL62tkj8ubA"
   },
   "outputs": [],
   "source": [
    "if run_test:\n",
    "\n",
    "        test_vols_per_horizon(mode=\"oos\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jI4GPCiA8ubA"
   },
   "source": [
    "# end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "45zLIW5xJTza"
   },
   "outputs": [],
   "source": [
    "plt.show()\n",
    "from google.colab import runtime\n",
    "runtime.unassign()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "s1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
