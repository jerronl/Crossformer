{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JaXYxzifbhst",
        "outputId": "3c5cb257-ad32-4567-d77f-76a871d69182"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "E:\\mydoc\\git\\trade\\analyics\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "d:\\ProgramData\\miniconda3\\envs\\e1\\Lib\\site-packages\\IPython\\core\\magics\\osm.py:417: UserWarning: using dhist requires you to install the `pickleshare` library.\n",
            "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
          ]
        }
      ],
      "source": [
        "\n",
        "if 'google.colab' in str(get_ipython()):\n",
        "  from google.colab import drive\n",
        "  drive.mount('/content/drive')\n",
        "  mydrive='/content/drive/MyDrive/volrt/'\n",
        "  source_path=mydrive+\"git/Crossformer\"\n",
        "  import os,sys\n",
        "  if not os.path.exists(source_path):\n",
        "    %cd $mydrive/git\n",
        "    !git clone https://github.com/jerronl/Crossformer.git\n",
        "    %cd $source_path\n",
        "  else:\n",
        "    %cd $source_path\n",
        "    !git checkout\n",
        "  !pip install einops\n",
        "\n",
        "  sys.path.append( source_path)\n",
        "else:\n",
        "  tables = ['volvA.csv']\n",
        "  mydrive= 'E:/mydoc/git/trade/analyics/'\n",
        "%cd $mydrive\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YeTQzMtGy8Ih",
        "outputId": "b18c6db6-6c0f-4e0b-bda6-3de95867e04e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Args in experiment:\n",
            "Namespace(data='vols', root_path='./datasets/', data_path=['volvN.csv'], data_split=[34560, 11520, 11520], checkpoints='./checkpoints/', in_len=20, out_len=50, seg_len=6, win_size=2, factor=10, data_dim=22, d_model=256, d_ff=512, n_heads=4, e_layers=3, dropout=0.2, baseline=False, num_workers=0, batch_size=32, train_epochs=20, patience=3, learning_rate=0.0001, lradj='type1', itr=5, save_pred=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3')\n",
            "Use GPU: cuda:0\n",
            ">>>>>>>start training : Crossformer_vols_il20_ol50_sl6_win2_fa10_dm256_nh4_el3_itr0>>>>>>>>>>>>>>>>>>>>>>>>>>\n"
          ]
        },
        {
          "ename": "NameError",
          "evalue": "name 'Dataset_MTS' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[5], line 82\u001b[0m\n\u001b[0;32m     80\u001b[0m exp \u001b[38;5;241m=\u001b[39m Exp(args) \u001b[38;5;66;03m# set experiments\u001b[39;00m\n\u001b[0;32m     81\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m>>>>>>>start training : \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m>>>>>>>>>>>>>>>>>>>>>>>>>>\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(setting))\n\u001b[1;32m---> 82\u001b[0m exp\u001b[38;5;241m.\u001b[39mtrain(setting)\n\u001b[0;32m     84\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m>>>>>>>testing : \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(setting))\n\u001b[0;32m     85\u001b[0m exp\u001b[38;5;241m.\u001b[39mtest(setting, args\u001b[38;5;241m.\u001b[39msave_pred)\n",
            "File \u001b[1;32mg:\\git\\Crossformer1\\cross_exp\\exp_crossformer.py:96\u001b[0m, in \u001b[0;36mExp_crossformer.train\u001b[1;34m(self, setting)\u001b[0m\n\u001b[0;32m     95\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain\u001b[39m(\u001b[38;5;28mself\u001b[39m, setting):\n\u001b[1;32m---> 96\u001b[0m     train_data, train_loader \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_data(flag \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     97\u001b[0m     vali_data, vali_loader \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_data(flag \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     98\u001b[0m     test_data, test_loader \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_data(flag \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
            "File \u001b[1;32mg:\\git\\Crossformer1\\cross_exp\\exp_crossformer.py:56\u001b[0m, in \u001b[0;36mExp_crossformer._get_data\u001b[1;34m(self, flag)\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     55\u001b[0m     shuffle_flag \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m; drop_last \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m; batch_size \u001b[38;5;241m=\u001b[39m args\u001b[38;5;241m.\u001b[39mbatch_size;\n\u001b[1;32m---> 56\u001b[0m data_set \u001b[38;5;241m=\u001b[39m Dataset_MTS(\n\u001b[0;32m     57\u001b[0m     root_path\u001b[38;5;241m=\u001b[39margs\u001b[38;5;241m.\u001b[39mroot_path,\n\u001b[0;32m     58\u001b[0m     data_path\u001b[38;5;241m=\u001b[39margs\u001b[38;5;241m.\u001b[39mdata_path,\n\u001b[0;32m     59\u001b[0m     flag\u001b[38;5;241m=\u001b[39mflag,\n\u001b[0;32m     60\u001b[0m     size\u001b[38;5;241m=\u001b[39m[args\u001b[38;5;241m.\u001b[39min_len, args\u001b[38;5;241m.\u001b[39mout_len],  \n\u001b[0;32m     61\u001b[0m     data_split \u001b[38;5;241m=\u001b[39m args\u001b[38;5;241m.\u001b[39mdata_split,\n\u001b[0;32m     62\u001b[0m )\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28mprint\u001b[39m(flag, \u001b[38;5;28mlen\u001b[39m(data_set))\n\u001b[0;32m     65\u001b[0m data_loader \u001b[38;5;241m=\u001b[39m DataLoader(\n\u001b[0;32m     66\u001b[0m     data_set,\n\u001b[0;32m     67\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[0;32m     68\u001b[0m     shuffle\u001b[38;5;241m=\u001b[39mshuffle_flag,\n\u001b[0;32m     69\u001b[0m     num_workers\u001b[38;5;241m=\u001b[39margs\u001b[38;5;241m.\u001b[39mnum_workers,\n\u001b[0;32m     70\u001b[0m     drop_last\u001b[38;5;241m=\u001b[39mdrop_last)\n",
            "\u001b[1;31mNameError\u001b[0m: name 'Dataset_MTS' is not defined"
          ]
        }
      ],
      "source": [
        "import argparse\n",
        "import torch\n",
        "\n",
        "from cross_exp.exp_crossformer import Exp_crossformer\n",
        "from utils.tools import string_split\n",
        "\n",
        "\n",
        "parser = argparse.ArgumentParser(description='CrossFormer')\n",
        "\n",
        "parser.add_argument('--data', type=str,  default='vols', help='data')\n",
        "parser.add_argument('--root_path', type=str, default='./datasets/', help='root path of the data file')\n",
        "parser.add_argument('--data_path', type=list, default=tables, help='data file')\n",
        "parser.add_argument('--data_split', type=str, default='0.7,0.1,0.2',help='train/val/test split, can be ratio or number')\n",
        "parser.add_argument('--checkpoints', type=str, default='./checkpoints/', help='location to store model checkpoints')\n",
        "\n",
        "parser.add_argument('--in_len', type=int, default=20, help='input MTS length (T)')\n",
        "parser.add_argument('--out_len', type=int, default=50, help='output MTS length (\\tau)')\n",
        "parser.add_argument('--seg_len', type=int, default=6, help='segment length (L_seg)')\n",
        "parser.add_argument('--win_size', type=int, default=2, help='window size for segment merge')\n",
        "parser.add_argument('--factor', type=int, default=10, help='num of routers in Cross-Dimension Stage of TSA (c)')\n",
        "\n",
        "parser.add_argument('--data_dim', type=int, default=22, help='Number of dimensions of the MTS data (D)')\n",
        "parser.add_argument('--d_model', type=int, default=256, help='dimension of hidden states (d_model)')\n",
        "parser.add_argument('--d_ff', type=int, default=512, help='dimension of MLP in transformer')\n",
        "parser.add_argument('--n_heads', type=int, default=4, help='num of heads')\n",
        "parser.add_argument('--e_layers', type=int, default=3, help='num of encoder layers (N)')\n",
        "parser.add_argument('--dropout', type=float, default=0.2, help='dropout')\n",
        "\n",
        "parser.add_argument('--baseline', action='store_true', help='whether to use mean of past series as baseline for prediction', default=False)\n",
        "\n",
        "parser.add_argument('--num_workers', type=int, default=0, help='data loader num workers')\n",
        "parser.add_argument('--batch_size', type=int, default=32, help='batch size of train input data')\n",
        "parser.add_argument('--train_epochs', type=int, default=20, help='train epochs')\n",
        "parser.add_argument('--patience', type=int, default=3, help='early stopping patience')\n",
        "parser.add_argument('--learning_rate', type=float, default=1e-4, help='optimizer initial learning rate')\n",
        "parser.add_argument('--lradj', type=str, default='type1',help='adjust learning rate')\n",
        "parser.add_argument('--itr', type=int, default=5, help='experiments times')\n",
        "\n",
        "parser.add_argument('--save_pred', action='store_true', help='whether to save the predicted future MTS', default=False)\n",
        "\n",
        "parser.add_argument('--use_gpu', type=bool, default=True, help='use gpu')\n",
        "parser.add_argument('--gpu', type=int, default=0, help='gpu')\n",
        "parser.add_argument('--use_multi_gpu', action='store_true', help='use multiple gpus', default=False)\n",
        "parser.add_argument('--devices', type=str, default='0,1,2,3',help='device ids of multile gpus')\n",
        "\n",
        "args = parser.parse_args(args=[])\n",
        "\n",
        "args.use_gpu = True if torch.cuda.is_available() and args.use_gpu else False\n",
        "\n",
        "if args.use_gpu and args.use_multi_gpu:\n",
        "    args.devices = args.devices.replace(' ','')\n",
        "    device_ids = args.devices.split(',')\n",
        "    args.device_ids = [int(id_) for id_ in device_ids]\n",
        "    args.gpu = args.device_ids[0]\n",
        "    print(args.gpu)\n",
        "\n",
        "data_parser = {\n",
        "    'ETTh1':{'data':'ETTh1.csv', 'data_dim':7, 'split':[12*30*24, 4*30*24, 4*30*24]},\n",
        "    'vols':{'data':tables, 'data_dim':22, 'split':[4*12*30*24, 4*4*30*24, 4*4*30*24]},\n",
        "}\n",
        "if args.data in data_parser.keys():\n",
        "    data_info = data_parser[args.data]\n",
        "    args.data_path = data_info['data']\n",
        "    args.data_dim = data_info['data_dim']\n",
        "    args.data_split = data_info['split']\n",
        "else:\n",
        "    args.data_split = string_split(args.data_split)\n",
        "\n",
        "print('Args in experiment:')\n",
        "print(args)\n",
        "\n",
        "Exp = Exp_crossformer\n",
        "\n",
        "for ii in range(args.itr):\n",
        "    # setting record of experiments\n",
        "    setting = 'Crossformer_{}_il{}_ol{}_sl{}_win{}_fa{}_dm{}_nh{}_el{}_itr{}'.format(args.data,\n",
        "                args.in_len, args.out_len, args.seg_len, args.win_size, args.factor,\n",
        "                args.d_model, args.n_heads, args.e_layers, ii)\n",
        "\n",
        "    exp = Exp(args) # set experiments\n",
        "    print('>>>>>>>start training : {}>>>>>>>>>>>>>>>>>>>>>>>>>>'.format(setting))\n",
        "    exp.train(setting)\n",
        "\n",
        "    print('>>>>>>>testing : {}<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<'.format(setting))\n",
        "    exp.test(setting, args.save_pred)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
