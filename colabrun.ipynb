{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5KB0_RDrJTzT"
   },
   "source": [
    "# setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JaXYxzifbhst"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E:\\mydoc\\git\\trade\\analyics\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\ProgramData\\miniconda3\\envs\\s1\\Lib\\site-packages\\IPython\\core\\magics\\osm.py:417: UserWarning: using dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    }
   ],
   "source": [
    "run_test=True\n",
    "DO_TRAIN_VOLS = True\n",
    "DO_TRAIN_PRCS = True\n",
    "Provisional=True\n",
    "MODE = 'tuning'\n",
    "\n",
    "# run_test=False\n",
    "# DO_TRAIN_VOLS = False   # 是否运行 VOLS 的 VOL_GRID 训练\n",
    "# DO_TRAIN_PRCS = False  # 是否运行 PRCS 的 LMSE x VOL_GRID 交叉训练\n",
    "Provisional=False\n",
    "MODE = 'prod'\n",
    "\n",
    "'''\n",
    "Provisional run_test \t \tMODE \t \tVOLS/PRCS \tTables itrs\n",
    "TRUE \t \tTRUE \t \ttuning \t完整网格→切片前2 \t 前2个表 0\n",
    "TRUE \t \tTRUE \t \tprod \t \tBEST配置 \t \t前2个表 \t \t0\n",
    "TRUE \t \tFALSE \ttuning \t完整网格→切片前2 \t 全部 \t \t0\n",
    "TRUE \t \tFALSE \tprod \t \tBEST配置 \t \t全部 \t \trange(itr)\n",
    "FALSE \t TRUE \t \ttuning \t完整网格 \t \t全部 \t 0\n",
    "FALSE \t TRUE \t \tprod \t \tBEST配置 \t \t全部 \t \trange(itr)\n",
    "FALSE \t FALSE \t tuning \t完整网格 \t \t全部 \t 0\n",
    "FALSE \t FALSE \t prod \t \tBEST配置 \t \t全部 \t \trange(itr)\n",
    "'''\n",
    "\n",
    "epochs=(1,1,1,0,12) if Provisional else (15,500,3,0,12)\n",
    "\n",
    "cutdate='2025-11-18'\n",
    "cutdateend='2026-11-18'\n",
    "cutdate='2024-12-18'\n",
    "cutdateend='2025-04-30'\n",
    "\n",
    "valData=''\n",
    "use_amp=True\n",
    "use_amp=False\n",
    "# valData='2512'\n",
    "testData=''\n",
    "testData='new/'\n",
    "initial_lr = .01\n",
    "\n",
    "weight=(0.81,1.01,0.03,0)\n",
    "itr=3\n",
    "metrics_cnt=6\n",
    "import torch,sys\n",
    "# Provisional=Provisional and run_test\n",
    "\n",
    "if 'google.colab' in str(get_ipython()):\n",
    "  from google.colab import drive\n",
    "  drive.mount('/content/drive')\n",
    "  mydrive='/content/drive/MyDrive/volrt/'\n",
    "  checkpoints=mydrive+\"checkpoints/\"\n",
    "  source_path=mydrive+\"git/Crossformer\"\n",
    "  tables = [ 'volvTSLA.csv', 'volvAAPL.csv'] if (Provisional and run_test) else [ 'volvTSLA.csv', 'volvAAPL.csv', 'volvGOOG.csv','volvNVDA.csv', 'volvMETA.csv', 'volvMSFT.csv', 'volvAMZN.csv', ]\n",
    "  batch_size=int(torch.cuda.get_device_properties(0).total_memory/1e9+.5)*25\n",
    "  import os,sys\n",
    "  if not os.path.exists(source_path):\n",
    "    %cd $mydrive/git\n",
    "    !git clone https://github.com/jerronl/Crossformer.git\n",
    "    %cd $source_path\n",
    "  else:\n",
    "    %cd $source_path\n",
    "    # !git reset --hard HEAD\n",
    "    # !git pull origin master\n",
    "  %pip install einops #scikit-learn\n",
    "  sys.path.append( source_path)\n",
    "else:\n",
    "  tables = [ 'volvAAPLt.csv']\n",
    "  use_amp=True\n",
    "  testData=''\n",
    "  mydrive= 'E:/mydoc/git/trade/analyics/'\n",
    "  checkpoints=\"G:/git/Crossformer1/checkpoints/\"\n",
    "  batch_size=32\n",
    "  sys.path.append(\"G:/git/Crossformer1/\")\n",
    "  # itr=1\n",
    "  %load_ext autoreload\n",
    "  %autoreload 2\n",
    "%cd $mydrive\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Funcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import traceback\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "from matplotlib.colors import LogNorm\n",
    "import torch\n",
    "\n",
    "from cross_exp.exp_crossformer import Exp_crossformer\n",
    "from data.data_loader import DatasetMTS, data_columns, data_names\n",
    "from data.data_def import set_cat\n",
    "from utils.tools import init_args, update_args\n",
    "from utils.metrics import metric_names\n",
    "\n",
    "set_cat(20)\n",
    "args = init_args()\n",
    "data_parser = {}\n",
    "\n",
    "COMMON_SETTINGS = {\n",
    "    \"e_layers\": 5,\n",
    "    \"d_model\": 512,\n",
    "    \"lradj\": \"type2\",\n",
    "    \"checkpoints\": checkpoints,\n",
    "}\n",
    "\n",
    "\n",
    "def generate_configs(grid, mode_idx):\n",
    "    active_keys = []\n",
    "    values_lists = []\n",
    "    for key, (vals, in_vols, in_prcs) in grid.items():\n",
    "        is_active = in_vols if mode_idx == 1 else in_prcs\n",
    "        if is_active:\n",
    "            active_keys.append(key)\n",
    "            values_lists.append(vals)\n",
    "    return [dict(zip(active_keys, c)) for c in itertools.product(*values_lists)]\n",
    "\n",
    "\n",
    "def apply_config_override(parser_config: dict, ds: str, config_dict: dict) -> dict:\n",
    "    temp_config = (\n",
    "        parser_config.copy() if ds not in parser_config else parser_config[ds].copy()\n",
    "    )\n",
    "    temp_config.update(config_dict)\n",
    "\n",
    "    if \"weight_over\" in config_dict and \"over_weight\" not in temp_config:\n",
    "        temp_config[\"over_weight\"] = config_dict[\"weight_over\"]\n",
    "\n",
    "    if ds not in parser_config:\n",
    "        return temp_config\n",
    "    parser_config[ds] = temp_config\n",
    "    return parser_config\n",
    "\n",
    "\n",
    "def build_parser(mode, ds, extra_query=\"\", root_override=None, config_defaults=None):\n",
    "    root = root_override or mydrive + (valData if mode == \"insample\" else testData)\n",
    "    q = \"\"\n",
    "    if mode == \"oos\":\n",
    "        q = f\"date>'#{cutdate}' and date<'#{cutdateend}'\"\n",
    "        if extra_query:\n",
    "            q += \" and \" + extra_query\n",
    "    elif mode == \"insample\":\n",
    "        q = extra_query\n",
    "\n",
    "    idx_w = 0 if ds == \"vols\" else 1\n",
    "    idx_ow = 2 if ds == \"vols\" else 3\n",
    "\n",
    "    defaults = config_defaults or {}\n",
    "\n",
    "    ds_config = {\n",
    "        **COMMON_SETTINGS,\n",
    "        \"root_path\": root,\n",
    "        \"data_path\": tables,\n",
    "        \"data\": ds,\n",
    "        \"weight\": defaults.get(\"weight\", weight[idx_w]),\n",
    "        \"over_weight\": defaults.get(\"weight_over\", weight[idx_ow]),\n",
    "        **defaults,\n",
    "    }\n",
    "\n",
    "    if q:\n",
    "        ds_config[\"query\"] = re.sub(r\"^\\s*and\\s+\", \"\", q)\n",
    "\n",
    "    parser = {} if ds == \"vols\" else {\"vols\": {\"checkpoints\": checkpoints}}\n",
    "    parser[ds] = ds_config\n",
    "    return parser\n",
    "\n",
    "\n",
    "def build_train_parser(root_path=None):\n",
    "    base = {\n",
    "        \"patience\": epochs[0],\n",
    "        \"train_epochs\": TRAIN_EPOCHS,\n",
    "        \"learning_rate\": initial_lr,\n",
    "        \"data_split\": [0.7, 0.15, 0.15],\n",
    "        \"batch_size\": batch_size * 2 // 5,\n",
    "        \"e_layers\": 5,\n",
    "        \"d_model\": 512,\n",
    "        \"lradj\": \"type2\",\n",
    "        \"checkpoints\": checkpoints,\n",
    "        \"root_path\": root_path or mydrive + valData,\n",
    "        \"data_path\": tables,\n",
    "        \"profile_mode\": False,\n",
    "        \"use_amp\": use_amp,\n",
    "    }\n",
    "    return {\n",
    "        \"vols\": {**base, \"data\": \"vols\", \"weight\": weight[0], \"over_weight\": weight[2]},\n",
    "        \"prcs\": {**base, \"data\": \"prcs\", \"weight\": weight[1], \"over_weight\": weight[3]},\n",
    "    }\n",
    "\n",
    "\n",
    "def get_feature_names(ds_name, in_len):\n",
    "    cols = data_columns(ds_name)\n",
    "    return data_names(cols, 1)[0]\n",
    "\n",
    "\n",
    "def get_trained_epochs(exp, setting_str, ds, idx):\n",
    "    trained_ep = exp.get_epochs()\n",
    "    if trained_ep != -1:\n",
    "        return trained_ep\n",
    "\n",
    "    folder_path = os.path.join(checkpoints, setting_str) + ds + str(idx)\n",
    "    file_path = os.path.join(folder_path, \"checkpoint.pth\")\n",
    "    if os.path.exists(file_path):\n",
    "        try:\n",
    "            state = torch.load(file_path, weights_only=False)\n",
    "            if isinstance(state, dict) and \"epoch\" in state:\n",
    "                return state[\"epoch\"]\n",
    "        except Exception:\n",
    "            return \"Err\"\n",
    "    return \"Not Fnd\"\n",
    "\n",
    "\n",
    "def prepare_preds_trues_for_plot(preds, trues, ycat=0):\n",
    "    preds, trues = np.asarray(preds), np.asarray(trues)\n",
    "    if ycat > 0:\n",
    "        reg_dim = preds.shape[1] - ycat\n",
    "        min_dim = min(trues.shape[1], reg_dim)\n",
    "        return preds[:, :min_dim], trues[:, :min_dim]\n",
    "    return preds, trues\n",
    "\n",
    "\n",
    "def _metrics_text(t, p):\n",
    "    diff = p - t\n",
    "    metrics = {\n",
    "        \"mae\": np.mean(np.abs(diff)),\n",
    "        \"rmse\": np.sqrt(np.mean(diff**2)),\n",
    "        \"mape\": np.mean(np.abs(diff) / (np.abs(t) + 1e-12)),\n",
    "    }\n",
    "    return f\"mae={metrics['mae']:.4g}\\nrmse={metrics['rmse']:.4g}\\nmape={metrics['mape']:.3g}\"\n",
    "\n",
    "\n",
    "def _metrics_text_prcs_ic_iv(t_iv, p_iv, t_ic, p_ic_label):\n",
    "    diff = p_iv - t_iv\n",
    "    mae = np.mean(np.abs(diff))\n",
    "    rmse = np.sqrt(np.mean(diff**2))\n",
    "    mape = np.mean(np.abs(diff) / (np.abs(t_iv) + 1e-12))\n",
    "\n",
    "    accr = np.nan\n",
    "    valid_mask = ~np.isnan(p_ic_label) & ~np.isnan(t_ic)\n",
    "    if len(t_ic) > 0 and (np.unique(t_ic).size <= 20) and (~np.isnan(t_ic)).sum() > 0:\n",
    "        if np.unique(p_ic_label).size <= 20:\n",
    "            accr = np.mean(p_ic_label.round()[valid_mask] == t_ic.round()[valid_mask])\n",
    "\n",
    "    base_text = f\"mae(IV)={mae:.4g}\\nrmse(IV)={rmse:.4g}\"\n",
    "    return (\n",
    "        f\"accr(IC)={accr:.3f}\\n{base_text}\"\n",
    "        if not np.isnan(accr)\n",
    "        else f\"{base_text}\\nmape(IV)={mape:.3g}\"\n",
    "    )\n",
    "\n",
    "\n",
    "def _compute_limits_like_old_regplot(trues_list, preds_list, feat_idx, feat_name):\n",
    "    left, right = np.inf, -np.inf\n",
    "    for trues, preds in zip(trues_list, preds_list):\n",
    "        t, p = trues[:, feat_idx], preds[:, feat_idx]\n",
    "        mask = ~np.isnan(t) & ~np.isnan(p)\n",
    "        if not mask.any():\n",
    "            continue\n",
    "        t, p = t[mask], p[mask]\n",
    "\n",
    "        l_curr, r_curr = (\n",
    "            (np.min(t), np.max(t))\n",
    "            if feat_name[:3] in [\"dtm\", \"pmc\"]\n",
    "            else (max(np.min(t), -5), min(np.max(t), 5))\n",
    "        )\n",
    "        p_min, p_max = (\n",
    "            (np.min(p), np.max(p))\n",
    "            if feat_name[:3] in [\"dtm\", \"pmc\"]\n",
    "            else (max(np.min(p), -5), min(np.max(p), 5))\n",
    "        )\n",
    "\n",
    "        left = min(left, l_curr, p_min)\n",
    "        right = max(right, r_curr, p_max)\n",
    "\n",
    "    if not np.isfinite(left) or not np.isfinite(right) or left == right:\n",
    "        return -1, 1\n",
    "    return left, right\n",
    "\n",
    "\n",
    "def plot_residual_heatmap_family(\n",
    "    preds_raw,\n",
    "    trues_raw,\n",
    "    feature_names,\n",
    "    title,\n",
    "    bins=80,\n",
    "    ycat=0,\n",
    "    cols=4,\n",
    "    figsize_per_cell=4,\n",
    "):\n",
    "    preds, trues = prepare_preds_trues_for_plot(preds_raw, trues_raw, ycat=ycat)\n",
    "    effective_dim = min(trues.shape[1], len(feature_names))\n",
    "    rows = int(np.ceil(effective_dim / cols))\n",
    "\n",
    "    fig, axes = plt.subplots(\n",
    "        rows,\n",
    "        cols,\n",
    "        figsize=(figsize_per_cell * cols, figsize_per_cell * rows),\n",
    "        squeeze=False,\n",
    "        constrained_layout=True,\n",
    "    )\n",
    "\n",
    "    for i in range(effective_dim):\n",
    "        ax = axes.flatten()[i]\n",
    "        t, p = trues[:, i], preds[:, i]\n",
    "        mask = ~np.isnan(t) & ~np.isnan(p)\n",
    "        t, p = t[mask], p[mask]\n",
    "\n",
    "        if len(t) == 0:\n",
    "            ax.set_title(feature_names[i])\n",
    "            ax.axis(\"off\")\n",
    "            continue\n",
    "\n",
    "        metrics_text = (\n",
    "            _metrics_text_prcs_ic_iv(t, p, t, preds[mask, 4])\n",
    "            if (ycat > 0 and i == 0)\n",
    "            else _metrics_text(t, p)\n",
    "        )\n",
    "        left, right = _compute_limits_like_old_regplot(\n",
    "            [trues_raw], [preds_raw], i, feature_names[i]\n",
    "        )\n",
    "\n",
    "        ax.hist2d(t, p, bins=bins, range=[[left, right], [left, right]], norm=\"log\")\n",
    "        ax.plot([left, right], [left, right], \"w--\", alpha=0.45)\n",
    "        ax.set_xlim(left, right)\n",
    "        ax.set_ylim(left, right)\n",
    "        ax.set_xlabel(\"True\")\n",
    "        ax.set_ylabel(\"Pred\")\n",
    "        ax.set_title(feature_names[i], fontsize=12)\n",
    "        ax.text(\n",
    "            0.02,\n",
    "            0.98,\n",
    "            metrics_text,\n",
    "            transform=ax.transAxes,\n",
    "            va=\"top\",\n",
    "            ha=\"left\",\n",
    "            fontsize=9,\n",
    "            bbox=dict(boxstyle=\"round,pad=0.25\", fc=\"black\", ec=\"none\", alpha=0.35),\n",
    "            color=\"white\",\n",
    "            zorder=3,\n",
    "        )\n",
    "\n",
    "    for i in range(effective_dim, rows * cols):\n",
    "        axes.flatten()[i].axis(\"off\")\n",
    "    if title:\n",
    "        fig.suptitle(title, fontsize=14)\n",
    "    plt.show()\n",
    "    plt.close(fig)\n",
    "\n",
    "\n",
    "def _get_plot_config(all_preds_raw, feature_names, cols):\n",
    "    if not all_preds_raw or not all_preds_raw[0].shape[1]:\n",
    "        return None\n",
    "    effective_dim = min(all_preds_raw[0].shape[1], len(feature_names))\n",
    "    if len(feature_names) < effective_dim:\n",
    "        feature_names += [f\"F{i}\" for i in range(len(feature_names), effective_dim)]\n",
    "\n",
    "    return {\n",
    "        \"effective_dim\": effective_dim,\n",
    "        \"feature_names\": feature_names[:effective_dim],\n",
    "        \"rows\": (effective_dim + cols - 1) // cols,\n",
    "        \"colors_errors\": plt.rcParams[\"axes.prop_cycle\"]\n",
    "        .by_key()\n",
    "        .get(\"color\", [f\"C{i}\" for i in range(10)]),\n",
    "        \"colors_residuals\": [\n",
    "            \"#1f77b4\",\n",
    "            \"#ff7f0e\",\n",
    "            \"#2ca02c\",\n",
    "            \"#d62728\",\n",
    "            \"#9467bd\",\n",
    "            \"#8c564b\",\n",
    "            \"#e377c2\",\n",
    "            \"#7f7f7f\",\n",
    "            \"#bcbd22\",\n",
    "            \"#17becf\",\n",
    "        ],  # truncated for brevity\n",
    "    }\n",
    "\n",
    "\n",
    "def plot_multi_stock_errors(\n",
    "    all_preds_raw,\n",
    "    all_trues_raw,\n",
    "    stock_labels,\n",
    "    feature_names,\n",
    "    title=\"\",\n",
    "    cols=4,\n",
    "    figsize_per_cell=4,\n",
    "    config=None,\n",
    "):\n",
    "    config = config or _get_plot_config(all_preds_raw, feature_names, cols)\n",
    "    if not config:\n",
    "        return\n",
    "\n",
    "    rows = config[\"rows\"]\n",
    "    top_margin = 0.905 + rows * 0.005\n",
    "    if not title:\n",
    "        top_margin += 0.02\n",
    "    fig = plt.figure(figsize=(cols * figsize_per_cell, rows * figsize_per_cell))\n",
    "    outer = gridspec.GridSpec(rows, cols, wspace=0.25, hspace=0.4)\n",
    "\n",
    "    for i in range(config[\"effective_dim\"]):\n",
    "        ax = fig.add_subplot(outer[divmod(i, cols)])\n",
    "        t_all, e_all = [], []\n",
    "\n",
    "        for j, (p_reg, t_reg) in enumerate(zip(all_preds_raw, all_trues_raw)):\n",
    "            t, p = t_reg[:, i], p_reg[:, i]\n",
    "            mask = ~np.isnan(t) & ~np.isnan(p)\n",
    "            if not mask.any():\n",
    "                continue\n",
    "            t, p = t[mask], p[mask]\n",
    "            e = p - t\n",
    "            t_all.append(t)\n",
    "            e_all.append(e)\n",
    "            ax.scatter(\n",
    "                t,\n",
    "                e,\n",
    "                s=4,\n",
    "                alpha=0.4,\n",
    "                color=config[\"colors_errors\"][j % len(config[\"colors_errors\"])],\n",
    "                label=stock_labels[j] if i == 0 else None,\n",
    "                zorder=2,\n",
    "            )\n",
    "\n",
    "        if not t_all:\n",
    "            ax.set_title(config[\"feature_names\"][i])\n",
    "            ax.axis(\"off\")\n",
    "            continue\n",
    "\n",
    "        t_all, e_all = np.concatenate(t_all), np.concatenate(e_all)\n",
    "        ax.axhline(0.0, color=\"k\", linestyle=\"--\", linewidth=0.8, alpha=0.7)\n",
    "\n",
    "        if np.unique(t_all).size > 1:\n",
    "            m, c = np.polyfit(t_all, e_all, 1)\n",
    "            ax.plot(\n",
    "                [t_all.min(), t_all.max()],\n",
    "                m * np.array([t_all.min(), t_all.max()]) + c,\n",
    "                \"-.\",\n",
    "                lw=1.0,\n",
    "                color=\"tab:orange\",\n",
    "            )\n",
    "\n",
    "        mae = float(np.mean(np.abs(e_all)))\n",
    "        rmse = float(np.sqrt(np.mean(e_all**2)))\n",
    "        over_mask = e_all > 0\n",
    "        under_mask = e_all < 0\n",
    "        over_frac = float(np.mean(over_mask)) if over_mask.size else 0.0\n",
    "        over_mae = float(np.mean(np.abs(e_all[over_mask]))) if over_mask.any() else 0.0\n",
    "        under_mae = (\n",
    "            float(np.mean(np.abs(e_all[under_mask]))) if under_mask.any() else 0.0\n",
    "        )\n",
    "\n",
    "        metrics = (\n",
    "            f\"RMSE: {rmse:.4g}\\n\"\n",
    "            f\"MAE: {mae:.4g}\\n\"\n",
    "            f\"over%: {over_frac*100:4.1f}\\n\"\n",
    "            f\"MAE_over: {over_mae:.4g}\\n\"\n",
    "            f\"MAE_under: {under_mae:.4g}\"\n",
    "        )\n",
    "        ax.text(\n",
    "            0.03,\n",
    "            0.97,\n",
    "            metrics,\n",
    "            transform=ax.transAxes,\n",
    "            fontsize=8,\n",
    "            va=\"top\",\n",
    "            bbox=dict(boxstyle=\"round\", facecolor=\"white\", alpha=0.8),\n",
    "        )\n",
    "        ax.set_title(config[\"feature_names\"][i], fontsize=10)\n",
    "        ax.set_xlabel(\"true\")\n",
    "        ax.set_ylabel(\"error = pred - true\")\n",
    "        ax.grid(True, linestyle=\"--\", alpha=0.4)\n",
    "        if i == 0:\n",
    "            ax.legend(fontsize=7, loc=\"lower right\")\n",
    "\n",
    "    if title:\n",
    "        fig.suptitle(title, fontsize=14, y=0.99)\n",
    "    fig.subplots_adjust(\n",
    "        top=top_margin,\n",
    "        hspace=0.35,\n",
    "        wspace=0.25,\n",
    "    )\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_multi_stock_residuals(\n",
    "    all_preds_raw,\n",
    "    all_trues_raw,\n",
    "    stock_labels,\n",
    "    feature_names,\n",
    "    ycat=0,\n",
    "    title=\"\",\n",
    "    bins=80,\n",
    "    cols=4,\n",
    "    figsize_per_cell=4,\n",
    "):\n",
    "    config = _get_plot_config(all_preds_raw, feature_names, cols)\n",
    "    if not config:\n",
    "        return\n",
    "\n",
    "    rows = config[\"rows\"]\n",
    "    top_margin = 0.905 + rows * 0.005\n",
    "    if not title:\n",
    "        top_margin += 0.02\n",
    "    fig = plt.figure(figsize=(cols * figsize_per_cell, rows * figsize_per_cell))\n",
    "    outer = gridspec.GridSpec(rows, cols, wspace=0.25, hspace=0.4)\n",
    "\n",
    "    for i in range(config[\"effective_dim\"]):\n",
    "        ax = fig.add_subplot(outer[divmod(i, cols)])\n",
    "        ax_hist = ax.twinx()\n",
    "        left, right = 999, -999\n",
    "        max_hist_density = 0\n",
    "        legend_handles = []\n",
    "\n",
    "        for j, (p_reg, t_reg) in enumerate(zip(all_preds_raw, all_trues_raw)):\n",
    "            t, p = t_reg[:, i], p_reg[:, i]\n",
    "            mask = ~np.isnan(t) & ~np.isnan(p)\n",
    "            if not mask.any():\n",
    "                continue\n",
    "            t, p = t[mask], p[mask]\n",
    "\n",
    "            color = config[\"colors_residuals\"][j % len(config[\"colors_residuals\"])]\n",
    "            try:\n",
    "                h_vals, _, _ = ax_hist.hist(\n",
    "                    t, bins=bins, density=True, alpha=0.15, color=color, zorder=1\n",
    "                )\n",
    "                if len(h_vals) > 0:\n",
    "                    max_hist_density = max(max_hist_density, np.max(h_vals))\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "            l_curr, r_curr = (\n",
    "                (np.min(t), np.max(t))\n",
    "                if feature_names[i][:3] in [\"dtm\", \"pmc\"]\n",
    "                else (max(np.min(t), -5), min(np.max(t), 5))\n",
    "            )\n",
    "            left, right = min(left, l_curr), max(right, r_curr)\n",
    "            ax.scatter(t, p, s=0.5, alpha=0.4, color=color, zorder=2)\n",
    "\n",
    "            try:\n",
    "                m, c = np.polyfit(t, p, 1)\n",
    "                (line,) = ax.plot(\n",
    "                    [t.min(), t.max()],\n",
    "                    m * np.array([t.min(), t.max()]) + c,\n",
    "                    \"--\",\n",
    "                    color=color,\n",
    "                    lw=1.5,\n",
    "                    alpha=0.4,\n",
    "                    label=stock_labels[j],\n",
    "                )\n",
    "                legend_handles.append(line)\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "        cur_xlim = ax.get_xlim()\n",
    "        cur_ylim = ax.get_ylim()\n",
    "        if left == 999:\n",
    "            left = cur_xlim[0]\n",
    "        if right == -999:\n",
    "            right = cur_xlim[1]\n",
    "        final_min = min(-0.01, min(left, cur_xlim[0], cur_ylim[0]))\n",
    "        final_max = max(0.01, max(right, cur_xlim[1], cur_ylim[1]))\n",
    "        ax.set_xlim(final_min, final_max)\n",
    "        ax.set_ylim(final_min, final_max)\n",
    "        ax_hist.set_ylim(0, max_hist_density * 3 if max_hist_density > 0 else 1)\n",
    "        ax_hist.axis(\"off\")\n",
    "        ax.set_title(config[\"feature_names\"][i], y=1.01, fontsize=11)\n",
    "        ax.legend(handles=legend_handles, fontsize=8, loc=\"best\")\n",
    "\n",
    "        all_t = np.concatenate([t[:, i] for t in all_trues_raw if t.shape[1] > i])\n",
    "        all_p = np.concatenate([p[:, i] for p in all_preds_raw if p.shape[1] > i])\n",
    "        mask = ~np.isnan(all_t) & ~np.isnan(all_p)\n",
    "        if mask.any():\n",
    "            rmse = np.sqrt(np.mean((all_t[mask] - all_p[mask]) ** 2))\n",
    "            mae = np.mean(np.abs(all_t[mask] - all_p[mask]))\n",
    "            metrics = f\"RMSE: {rmse:.4f}\\nMAE: {mae:.4f}\"\n",
    "            ax.text(\n",
    "                0.05,\n",
    "                0.95,\n",
    "                metrics,\n",
    "                transform=ax.transAxes,\n",
    "                fontsize=9,\n",
    "                va=\"top\",\n",
    "                bbox=dict(boxstyle=\"round\", fc=\"white\", alpha=0.85),\n",
    "            )\n",
    "\n",
    "    if title:\n",
    "        fig.suptitle(title, fontsize=14, y=0.99)\n",
    "    fig.subplots_adjust(\n",
    "        top=top_margin,\n",
    "        hspace=0.35,\n",
    "        wspace=0.25,\n",
    "    )\n",
    "    plt.show()\n",
    "\n",
    "    if all_preds_raw:\n",
    "        plot_multi_stock_errors(\n",
    "            all_preds_raw,\n",
    "            all_trues_raw,\n",
    "            stock_labels,\n",
    "            feature_names,\n",
    "            title=f\"{title} - Prediction Errors\",\n",
    "            cols=cols,\n",
    "            figsize_per_cell=figsize_per_cell,\n",
    "            config=config,\n",
    "        )\n",
    "\n",
    "\n",
    "def plot_prcs_distribution_detailed(\n",
    "    results_list,\n",
    "    model_idx,\n",
    "    ycat,\n",
    "    dep_var,\n",
    "    tables_list,\n",
    "    cols=4,\n",
    "    title_prefix=\"PRCS Distribution\",\n",
    "):\n",
    "    if not results_list or ycat == 0:\n",
    "        return\n",
    "\n",
    "    n_categories = ycat\n",
    "    x_ticks = np.arange(1, n_categories + 1)\n",
    "    outer_rows = (len(results_list) - 1) // cols + 1\n",
    "    fig = plt.figure(figsize=(16, 4 * outer_rows))\n",
    "    outer = gridspec.GridSpec(outer_rows, cols, wspace=0.3, hspace=0.45)\n",
    "    ls = [\"-\", \"--\", \":\"]\n",
    "\n",
    "    print(f\"\\n--- Plotting {title_prefix} for Model m{model_idx} ---\")\n",
    "    for j, (preds_raw, trues_raw, _) in enumerate(results_list):\n",
    "        probs, labels = np.asarray(preds_raw)[:, -ycat:], np.round(\n",
    "            np.asarray(trues_raw)[:, 0]\n",
    "        ).astype(int)\n",
    "        mask = (~np.isnan(labels)) & (labels >= 1) & (labels <= ycat)\n",
    "        if not mask.any():\n",
    "            continue\n",
    "\n",
    "        probs, labels = probs[mask], labels[mask]\n",
    "        if probs.size > 0 and (probs.max() > 1.05 or probs.min() < -0.05):\n",
    "            exp_probs = np.exp(probs - np.max(probs, axis=1, keepdims=True))\n",
    "            probs = exp_probs / (np.sum(exp_probs, axis=1, keepdims=True) + 1e-12)\n",
    "\n",
    "        df = pd.DataFrame(probs, columns=[str(i) for i in range(1, ycat + 1)]).assign(\n",
    "            True_Label=labels\n",
    "        )\n",
    "        summed = df.groupby(\"True_Label\").mean().T\n",
    "\n",
    "        sub_gs = outer[j // cols, j % cols].subgridspec(2, 1, hspace=0.0)\n",
    "        valid_cols = sorted([c for c in summed.columns if 1 <= c <= ycat])\n",
    "        for k in (0, 1):\n",
    "            ax = fig.add_subplot(sub_gs[k, 0])\n",
    "            ax.hist(\n",
    "                labels,\n",
    "                bins=np.arange(1, ycat + 2) - 0.5,\n",
    "                alpha=0.2,\n",
    "                density=True,\n",
    "                color=\"gray\",\n",
    "                label=\"True\",\n",
    "                zorder=1,\n",
    "            )\n",
    "\n",
    "            ci = 0\n",
    "            for m in range(k, len(valid_cols), 2):\n",
    "                col = valid_cols[m]\n",
    "                ax.plot(\n",
    "                    [int(x) for x in summed.index],\n",
    "                    summed[col],\n",
    "                    label=f\"cat {col}\",\n",
    "                    linestyle=ls[col // (ycat // 3 + 1) % 3],\n",
    "                    color=f\"C{ci % 10}\",\n",
    "                    alpha=0.7,\n",
    "                    zorder=2,\n",
    "                )\n",
    "                ax.text(\n",
    "                    col,\n",
    "                    summed[col][str(col)],\n",
    "                    f\"{col}\",\n",
    "                    fontsize=8,\n",
    "                    va=\"bottom\",\n",
    "                    ha=\"center\",\n",
    "                    color=f\"C{ci % 10}\",\n",
    "                    zorder=3,\n",
    "                )\n",
    "                ci += 1\n",
    "\n",
    "            ax.set_ylim(0, 0.2)\n",
    "            ax.set_xlim(0.5, ycat + 1.5)\n",
    "            ax.set_xticks(x_ticks)\n",
    "            ax.set_xticklabels([str(i) for i in x_ticks], rotation=-45, fontsize=8)\n",
    "            ax.grid(axis=\"y\", linestyle=\"--\", alpha=0.3)\n",
    "\n",
    "            if k == 0:\n",
    "                ax.set_title(tables_list[j], fontsize=10)\n",
    "                plt.setp(ax.get_xticklabels(), visible=False)\n",
    "                ax.set_xlabel(\"\")\n",
    "            else:\n",
    "                ax.set_xlabel(\"Predicted Class Index\", fontsize=9)\n",
    "\n",
    "            ax.legend(\n",
    "                loc=\"center left\",\n",
    "                bbox_to_anchor=(1.05, 0.5),\n",
    "                fontsize=7,\n",
    "                framealpha=0.6,\n",
    "            )\n",
    "\n",
    "    fig.suptitle(f\"{title_prefix} - Model m{model_idx}\", fontsize=14)\n",
    "    plt.tight_layout(rect=[0, 0.03, 1, 0.97])\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "def generate_final_summary(summary_records):\n",
    "    if not summary_records:\n",
    "        return\n",
    "    df = pd.DataFrame(summary_records)\n",
    "    meta = [c for c in [\"dataset\", \"idx\", \"horizon\", \"epochs\"] if c in df]\n",
    "    metrics = sorted(\n",
    "        [c for c in df.columns if c in set(metric_names[0] + metric_names[1])]\n",
    "    )\n",
    "    params = sorted([c for c in df.columns if c not in meta + metrics])\n",
    "    print(\n",
    "        df[meta + params + metrics].to_string(\n",
    "            float_format=lambda x: f\"{x:.4g}\" if isinstance(x, (float, int)) else str(x)\n",
    "        )\n",
    "    )\n",
    "\n",
    "\n",
    "def _init_exp_and_setting(parser_config: dict, ds: str, itr_idx: int = 0):\n",
    "    args = init_args()\n",
    "    return (\n",
    "        args,\n",
    "        update_args(args, parser_config, itr=itr_idx, arg_set=ds),\n",
    "        Exp_crossformer(args),\n",
    "    )\n",
    "\n",
    "\n",
    "def run_test_one_setting(\n",
    "    exp,\n",
    "    setting_str,\n",
    "    ds,\n",
    "    dep_var,\n",
    "    ycat,\n",
    "    title_prefix,\n",
    "    by_stock=False,\n",
    "    stock_tables=None,\n",
    "    plot_individual_heatmaps=True,\n",
    "    test_data=None,\n",
    "    itr_idx=0,\n",
    "):\n",
    "    m_list, all_p, all_t = [], [], []\n",
    "    ds_tag = ds + str(itr_idx)\n",
    "\n",
    "    def _plot(p, t, title):\n",
    "        if plot_individual_heatmaps:\n",
    "            print(f\"\\n--- Residual Heatmap: {title} ---\")\n",
    "            plot_residual_heatmap_family(p, t, dep_var, title=title, ycat=ycat)\n",
    "\n",
    "    if by_stock:\n",
    "        for tb in stock_tables:\n",
    "            p, t, m = exp.test(setting_str, ds_tag, True, data_path=[tb], inverse=True)\n",
    "            m_list.append(m)\n",
    "            all_p.append(p)\n",
    "            all_t.append(t)\n",
    "            _plot(p, t, f\"{title_prefix} {tb}\")\n",
    "        return m_list, all_p, all_t\n",
    "\n",
    "    p, t, m = exp.test(setting_str, ds_tag, True, inverse=True, test_data=test_data)\n",
    "    _plot(p, t, title_prefix)\n",
    "    return [m], ([p] if test_data else [p]), ([t] if test_data else [t])\n",
    "\n",
    "\n",
    "def train_unified_all():\n",
    "    global args, UNIFIED_CONFIGS, active_grid_indices, DO_TRAIN_VOLS, DO_TRAIN_PRCS\n",
    "    base_parser = build_train_parser()\n",
    "\n",
    "    print(\n",
    "        f\"\\n=== Unified Training (Mode: {MODE}, Active: {len(active_grid_indices)}) ===\"\n",
    "    )\n",
    "    for idx in active_grid_indices:\n",
    "        if idx >= len(UNIFIED_CONFIGS):\n",
    "            break\n",
    "        cfg = UNIFIED_CONFIGS[idx].copy()\n",
    "        ds, itr_idx = cfg.pop(\"target_ds\"), cfg.pop(\"itr_idx\", 0)\n",
    "\n",
    "        if (ds == \"vols\" and not DO_TRAIN_VOLS) or (ds == \"prcs\" and not DO_TRAIN_PRCS):\n",
    "            continue\n",
    "\n",
    "        DatasetMTS.clear()\n",
    "        curr_parser = {k: v.copy() for k, v in base_parser.items()}\n",
    "        curr_parser[ds] = apply_config_override(curr_parser[ds], ds, cfg)\n",
    "\n",
    "        # Training Cycles\n",
    "        start_lr = curr_parser[ds][\"learning_rate\"]\n",
    "        for cycle in range(epochs[2]):\n",
    "            curr_parser[ds][\"learning_rate\"] = start_lr / (3.0**cycle)\n",
    "            args, setting, exp = _init_exp_and_setting(curr_parser, ds, itr_idx)\n",
    "\n",
    "            print(\n",
    "                f\"\\n[Idx {idx}|Itr {itr_idx}|{ds.upper()}|Cyc {cycle+1}] LR={curr_parser[ds]['learning_rate']:.6f} | {setting}\"\n",
    "            )\n",
    "            try:\n",
    "                exp.train(setting, ds + str(itr_idx))\n",
    "                if MODE == \"prod\":\n",
    "                    exp.test(\n",
    "                        setting,\n",
    "                        ds + str(itr_idx),\n",
    "                        True,\n",
    "                        data_path=[tables[-1]],\n",
    "                        inverse=True,\n",
    "                    )\n",
    "            except Exception as e:\n",
    "                print(f\"--- FAILED Idx {idx} --- {e}\")\n",
    "                traceback.print_exc()\n",
    "\n",
    "\n",
    "def test_unified(\n",
    "    mode: str, target_ds: str, by_stock=True, plot_residuals=True, plot_stock=False\n",
    "):\n",
    "    global args, UNIFIED_CONFIGS, active_grid_indices, tables\n",
    "    summary = []\n",
    "\n",
    "    indices = [\n",
    "        i\n",
    "        for i in active_grid_indices\n",
    "        if i < len(UNIFIED_CONFIGS) and UNIFIED_CONFIGS[i][\"target_ds\"] == target_ds\n",
    "    ]\n",
    "    if not indices:\n",
    "        return print(f\"No configs for {target_ds}\")\n",
    "\n",
    "    print(f\"\\n=== Testing {target_ds.upper()} ({mode}) - {len(indices)} configs ===\")\n",
    "    for idx in indices:\n",
    "        cfg = UNIFIED_CONFIGS[idx].copy()\n",
    "        ds, itr_idx = cfg.pop(\"target_ds\"), cfg.pop(\"itr_idx\", 0)\n",
    "        ycat = data_columns(ds).get(\"ycat\", 0) if ds == \"prcs\" else 0\n",
    "\n",
    "        base_parser = build_parser(mode, ds)\n",
    "        base_parser[ds] = apply_config_override(base_parser[ds], ds, cfg)\n",
    "\n",
    "        args, setting, exp = _init_exp_and_setting(base_parser, ds, itr_idx)\n",
    "        trained_ep = get_trained_epochs(exp, setting, ds, itr_idx)\n",
    "\n",
    "        # if trained_ep == \"Not Fnd\": print(f\"Skipping {setting}, model not found\"); continue\n",
    "\n",
    "        try:\n",
    "            dep_var = get_feature_names(ds, getattr(args, \"seq_len\", 1))\n",
    "            title = f\"{ds.upper()} {mode} [Idx {idx}|Itr {itr_idx}]\"\n",
    "\n",
    "            m_list, p_fam, t_fam = run_test_one_setting(\n",
    "                exp,\n",
    "                setting,\n",
    "                ds,\n",
    "                dep_var,\n",
    "                ycat,\n",
    "                title,\n",
    "                by_stock,\n",
    "                tables,\n",
    "                plot_stock,\n",
    "                itr_idx=itr_idx,\n",
    "            )\n",
    "\n",
    "            if by_stock and p_fam and plot_residuals:\n",
    "                print(f\"\\n--- AGGREGATED: {title} ---\")\n",
    "                plot_multi_stock_residuals(\n",
    "                    p_fam, t_fam, tables, dep_var, ycat, title=f\"AGG {title}\"\n",
    "                )\n",
    "                if ds == \"prcs\" and ycat > 0:\n",
    "                    plot_prcs_distribution_detailed(\n",
    "                        list(zip(p_fam, t_fam, m_list)),\n",
    "                        idx,\n",
    "                        ycat,\n",
    "                        dep_var,\n",
    "                        tables,\n",
    "                        title_prefix=f\"AGG {title}\",\n",
    "                    )\n",
    "\n",
    "            summary.append(\n",
    "                {\n",
    "                    \"dataset\": ds,\n",
    "                    \"idx\": idx,\n",
    "                    \"itr\": itr_idx,\n",
    "                    \"epochs\": trained_ep,\n",
    "                    **cfg,\n",
    "                    **dict(\n",
    "                        zip(metric_names[1 if ycat > 0 else 0], np.mean(m_list, axis=0))\n",
    "                    ),\n",
    "                }\n",
    "            )\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"--- FAILED Test Idx {idx} --- {e}\")\n",
    "            traceback.print_exc()\n",
    "\n",
    "    generate_final_summary(summary)\n",
    "    if len(summary) > 1:\n",
    "        print(\"\\n--- Metrics Summary ---\")\n",
    "        plot_metric_summary(summary)\n",
    "    return summary\n",
    "\n",
    "\n",
    "def test_vols_per_horizon(mode=\"insample\", plot_residuals=True, best_idx=-1):\n",
    "    global args, UNIFIED_CONFIGS, tables\n",
    "    summary, ds, horizons = [], \"vols\", [1, 2, 3, 4, 5]\n",
    "\n",
    "    indices = [\n",
    "        i\n",
    "        for i in active_grid_indices\n",
    "        if i < len(UNIFIED_CONFIGS) and UNIFIED_CONFIGS[i][\"target_ds\"] == ds\n",
    "    ]\n",
    "    if best_idx != -1 and best_idx in range(len(UNIFIED_CONFIGS)):\n",
    "        indices = [best_idx]\n",
    "    if not indices:\n",
    "        return\n",
    "\n",
    "    print(f\"\\n--- VOLS Horizon Test ({len(indices)} configs) ---\")\n",
    "    for idx in indices:\n",
    "        cfg = UNIFIED_CONFIGS[idx].copy()\n",
    "        ds, itr_idx = cfg.pop(\"target_ds\"), cfg.pop(\"itr_idx\", 0)\n",
    "\n",
    "        base_parser = build_parser(mode, ds)\n",
    "        parser_load = base_parser.copy()\n",
    "        parser_load[ds] = apply_config_override(parser_load[ds], ds, cfg)\n",
    "\n",
    "        args, setting, exp = _init_exp_and_setting(parser_load, ds, itr_idx)\n",
    "        trained_ep = get_trained_epochs(exp, setting, ds, itr_idx)\n",
    "        # if trained_ep == \"Not Fnd\": continue\n",
    "\n",
    "        dep_var, orig_q = (\n",
    "            get_feature_names(ds, getattr(args, \"seq_len\", 1)),\n",
    "            exp.args.query,\n",
    "        )\n",
    "        h_preds, h_trues, h_names = [], [], []\n",
    "\n",
    "        for h in horizons:\n",
    "            exp.args.query = build_parser(mode, ds, extra_query=f\"floor(horizon)=={h}\")[\n",
    "                ds\n",
    "            ].get(\"query\", \"\")\n",
    "            try:\n",
    "                dataset, loader = exp._get_data(flag=\"test\", data=ds)\n",
    "                m_list, p, t = run_test_one_setting(\n",
    "                    exp,\n",
    "                    setting,\n",
    "                    ds,\n",
    "                    dep_var,\n",
    "                    0,\n",
    "                    \"\",\n",
    "                    False,\n",
    "                    None,\n",
    "                    False,\n",
    "                    (dataset, loader),\n",
    "                    itr_idx,\n",
    "                )\n",
    "\n",
    "                if m_list:\n",
    "                    summary.append(\n",
    "                        {\n",
    "                            \"dataset\": ds,\n",
    "                            \"idx\": idx,\n",
    "                            \"itr\": itr_idx,\n",
    "                            \"horizon\": h,\n",
    "                            \"epochs\": trained_ep,\n",
    "                            **cfg,\n",
    "                            **dict(zip(metric_names[0], m_list[0])),\n",
    "                        }\n",
    "                    )\n",
    "                    h_preds.append(p[0])\n",
    "                    h_trues.append(t[0])\n",
    "                    h_names.append(f\"H {h}\")\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "        exp.args.query = orig_q\n",
    "        if plot_residuals and h_preds:\n",
    "            plot_multi_stock_residuals(\n",
    "                h_preds,\n",
    "                h_trues,\n",
    "                h_names,\n",
    "                dep_var,\n",
    "                0,\n",
    "                title=f\"VOLS Horizons [Idx {idx}]\",\n",
    "            )\n",
    "\n",
    "    generate_final_summary(summary)\n",
    "    plot_metric_summary(summary)\n",
    "    return summary\n",
    "\n",
    "\n",
    "def plot_metric_summary(records):\n",
    "    if not records:\n",
    "        return\n",
    "    df = pd.DataFrame(records)\n",
    "    metrics = [m for m in metric_names[0] + metric_names[1] if m in df.columns]\n",
    "\n",
    "    rows = (len(metrics) + 1) // 2\n",
    "    fig, axes = plt.subplots(rows, 2, figsize=(15, 5 * rows))\n",
    "    for i, m in enumerate(metrics):\n",
    "        ax = axes.flatten()[i]\n",
    "        if \"horizon\" in df:\n",
    "            for idx in df[\"idx\"].unique():\n",
    "                sub = df[df[\"idx\"] == idx].sort_values(\"horizon\")\n",
    "                ax.plot(sub[\"horizon\"], sub[m], \"o-\", label=f\"Cfg {idx}\")\n",
    "            ax.legend()\n",
    "        else:\n",
    "            ax.plot(df[\"idx\"], df[m], \"o-\")\n",
    "        ax.set_title(m.upper())\n",
    "        ax.grid(True, linestyle=\"--\", alpha=0.5)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-bmjLRHTfVt-"
   },
   "source": [
    "# Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "mJovfe3GfVt-"
   },
   "outputs": [],
   "source": [
    "PARAM_GRID_VOLS = {\n",
    "    \"lambda_var\":  ([0.00050, 0.00055, 0.00060], True, True),\n",
    "    \"gain_reg\":    ([1.5, 2.0], True, True),\n",
    "    \"weight_over\": ([1.4, 1.5, 1.6], True, True),\n",
    "\n",
    "    # 固定的最优值，不再扫描\n",
    "    \"lambda_tail\": ([0.0], False, True),\n",
    "    \"lambda_anti\": ([0.1], False, True),\n",
    "    \"dist_alpha\":  ([1.0], False, True),\n",
    "    \"lambda_dist\": ([0.0], False, True),\n",
    "}\n",
    "\n",
    "PARAM_GRID_PRCS = {\n",
    "    # 围绕 0.0004 做轻微上下微调\n",
    "    \"lambda_var\":  ([0.00035, 0.00040, 0.00045], False, True),\n",
    "\n",
    "    # gain_reg 只看 0.8 / 1.0 / 1.2，都是“正常有梯度”的范围\n",
    "    \"gain_reg\":    ([0.8, 1.0, 1.2],             False, True),\n",
    "\n",
    "    # weight_over：基准 1.2，再看看 1.0 会不会稍微放松一点\n",
    "    \"weight_over\": ([1.0, 1.2],                  False, True),\n",
    "\n",
    "    # 这一轮先严格完全兼容老版：这些都锁死为 0\n",
    "    \"lambda_tail\": ([0.0],                       False, True),\n",
    "    \"lambda_anti\": ([0.0],                       False, True),\n",
    "    \"lambda_dist\": ([0.0],                       False, True),\n",
    "\n",
    "    # 老 baseline 用的是分类 + 回归等权\n",
    "    \"lambda_mse\":  ([1.0],                       False, True),\n",
    "\n",
    "    # 先固定为 1.0（和之前老跑法一致），下一轮再单独扫 dist_alpha\n",
    "    \"dist_alpha\":  ([1.0],                       False, True),\n",
    "}\n",
    "\n",
    "vols_configs_raw = []\n",
    "prcs_configs_raw = [\n",
    "    {\"dist_alpha\": 1.0, \"gain_reg\": 1.12, \"lambda_var\": 0.0004, \"weight_over\": 1.0},\n",
    "    {\"dist_alpha\": 1.0, \"gain_reg\": 1.18, \"lambda_var\": 0.0004, \"weight_over\": 1.0},\n",
    "    {\"dist_alpha\": 1.0, \"gain_reg\": 1.15, \"lambda_var\": 0.0004, \"weight_over\": 0.95},\n",
    "    {\"dist_alpha\": 1.0, \"gain_reg\": 1.15, \"lambda_var\": 0.0004, \"weight_over\": 1.05},\n",
    "    {\"dist_alpha\": 1.1, \"gain_reg\": 1.15, \"lambda_var\": 0.0004, \"weight_over\": 1.0},\n",
    "    {\"dist_alpha\": 1.1, \"gain_reg\": 1.12, \"lambda_var\": 0.0004, \"weight_over\": 0.95},\n",
    "    {\"dist_alpha\": 1.1, \"gain_reg\": 1.12, \"lambda_var\": 0.0004, \"weight_over\": 1.05},\n",
    "    {\"dist_alpha\": 1.1, \"gain_reg\": 1.18, \"lambda_var\": 0.0004, \"weight_over\": 1.0},\n",
    "    # A Group\n",
    "    {\"dist_alpha\": 1.15, \"gain_reg\": 1.15, \"lambda_var\": 0.0004, \"weight_over\": 1.0},\n",
    "    {\"dist_alpha\": 1.2,  \"gain_reg\": 1.15, \"lambda_var\": 0.0004, \"weight_over\": 1.0},\n",
    "    # B Group\n",
    "    {\"dist_alpha\": 1.0, \"gain_reg\": 1.15, \"lambda_var\": 0.0004, \"weight_over\": 1.02},\n",
    "    {\"dist_alpha\": 1.0, \"gain_reg\": 1.15, \"lambda_var\": 0.0004, \"weight_over\": 1.08},\n",
    "    # C Group\n",
    "    {\"dist_alpha\": 1.1,  \"gain_reg\": 1.15, \"lambda_var\": 0.0004, \"weight_over\": 1.02},\n",
    "    {\"dist_alpha\": 1.15, \"gain_reg\": 1.15, \"lambda_var\": 0.0004, \"weight_over\": 1.08},\n",
    "    # EMD Group\n",
    "    {\"dist_alpha\": 1.0, \"gain_reg\": 1.12, \"lambda_emd\": 0.001, \"weight_over\": 1.0},\n",
    "    {\"dist_alpha\": 1.0, \"gain_reg\": 1.18, \"lambda_emd\": 0.001, \"weight_over\": 1.0},\n",
    "    {\"dist_alpha\": 1.0, \"gain_reg\": 1.15, \"lambda_emd\": 0.001, \"weight_over\": 0.95},\n",
    "    {\"dist_alpha\": 1.0, \"gain_reg\": 1.15, \"lambda_emd\": 0.001, \"weight_over\": 1.05},\n",
    "    {\"dist_alpha\": 1.1, \"gain_reg\": 1.15, \"lambda_emd\": 0.001, \"weight_over\": 1.0},\n",
    "]\n",
    "\n",
    "\n",
    "BEST_VOLS = {\"lambda_var\": 0.0005, \"gain_reg\": 1.5, \"weight_over\": 1.4, \"lambda_anti\": 0.1, \"dist_alpha\": 1.0}\n",
    "BEST_PRCS = {\"dist_alpha\": 1.1, \"gain_reg\": 1.18, \"lambda_mse\": 1.0, \"lambda_var\": 0.0004, \"weight_over\": 1.0}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "ESF8ae6wWyUS"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "Config Summary: Total=6, Active=6, Epochs=500\n",
      "  Mode=prod, Test=True, Provisional=False\n",
      "================================================================================\n",
      "  [0] VOLS|itr0: weight=0.81, weight_over=1.4, lambda_var=0.0005, gain_reg=1.5, lambda_anti=0.1, dist_alpha=1\n",
      "  [1] VOLS|itr1: weight=0.81, weight_over=1.4, lambda_var=0.0005, gain_reg=1.5, lambda_anti=0.1, dist_alpha=1\n",
      "  [2] VOLS|itr2: weight=0.81, weight_over=1.4, lambda_var=0.0005, gain_reg=1.5, lambda_anti=0.1, dist_alpha=1\n",
      "  [3] PRCS|itr0: weight=1.01, weight_over=1, dist_alpha=1.1, gain_reg=1.18, lambda_mse=1, lambda_var=0.0004\n",
      "  [4] PRCS|itr1: weight=1.01, weight_over=1, dist_alpha=1.1, gain_reg=1.18, lambda_mse=1, lambda_var=0.0004\n",
      "  [5] PRCS|itr2: weight=1.01, weight_over=1, dist_alpha=1.1, gain_reg=1.18, lambda_mse=1, lambda_var=0.0004\n",
      "================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if MODE == \"prod\":\n",
    "    vols_configs_raw = [BEST_VOLS] if DO_TRAIN_VOLS else []\n",
    "    prcs_configs_raw = [BEST_PRCS] if DO_TRAIN_PRCS else []\n",
    "else:\n",
    "    if DO_TRAIN_VOLS and not vols_configs_raw: vols_configs_raw = generate_configs(PARAM_GRID_VOLS, 1)\n",
    "    if DO_TRAIN_PRCS and not prcs_configs_raw: prcs_configs_raw = generate_configs(PARAM_GRID_PRCS, 2)\n",
    "\n",
    "\n",
    "train_itr_list = [0] if (MODE == 'tuning' or (Provisional and run_test)) else list(range(itr))\n",
    "defaults_map = {\n",
    "    \"vols\": {\"weight\": weight[0], \"weight_over\": weight[2]},\n",
    "    \"prcs\": {\"weight\": weight[1], \"weight_over\": weight[3]}\n",
    "}\n",
    "\n",
    "loop_itrs = train_itr_list\n",
    "\n",
    "UNIFIED_CONFIGS = []\n",
    "for ds, configs in [(\"vols\", vols_configs_raw), (\"prcs\", prcs_configs_raw)]:\n",
    "    defaults = defaults_map[ds]\n",
    "    for cfg in configs:\n",
    "        full_cfg = {**defaults, **cfg} \n",
    "        \n",
    "        \n",
    "        for itr_idx in loop_itrs:\n",
    "            UNIFIED_CONFIGS.append({**full_cfg, \"target_ds\": ds, \"itr_idx\": itr_idx})\n",
    "\n",
    "# Provisional Filter\n",
    "if Provisional and MODE == \"tuning\":\n",
    "    v_cnt = len(vols_configs_raw) * len(loop_itrs)\n",
    "    p_cnt = len(prcs_configs_raw) * len(loop_itrs)\n",
    "    UNIFIED_CONFIGS = (UNIFIED_CONFIGS[:min(2, v_cnt)] if v_cnt else []) + \\\n",
    "                      (UNIFIED_CONFIGS[v_cnt:v_cnt+min(2, p_cnt)] if p_cnt else [])\n",
    "\n",
    "# Active Range Calculation\n",
    "TRAIN_EPOCHS = min(30, epochs[1]) if MODE == \"tuning\" else epochs[1]\n",
    "total = len(UNIFIED_CONFIGS)\n",
    "start, end = epochs[3], min(epochs[3] + epochs[4], total)\n",
    "active_grid_indices = [0] + list(range(start, end)) if (epochs[0] < 2 and start > 0) else list(range(start, end))\n",
    "\n",
    "print(f\"\\n{'='*80}\\nConfig Summary: Total={total}, Active={len(active_grid_indices)}, Epochs={TRAIN_EPOCHS}\")\n",
    "print(f\"  Mode={MODE}, Test={run_test}, Provisional={Provisional}\")\n",
    "print(f\"{'='*80}\")\n",
    "for i in active_grid_indices:\n",
    "    if i < total:\n",
    "        c = UNIFIED_CONFIGS[i]\n",
    "        p_str = \", \".join([f\"{k}={v:.4g}\" if isinstance(v, float) else f\"{k}={v}\" for k, v in c.items() if k not in [\"target_ds\", \"itr_idx\"]])\n",
    "        print(f\"  [{i}] {c['target_ds'].upper()}|itr{c['itr_idx']}: {p_str}\")\n",
    "print(f\"{'='*80}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qCfd-gU7JTzW"
   },
   "source": [
    "# train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "edfP8114fVuB"
   },
   "outputs": [],
   "source": [
    "if run_test == False:\n",
    "        train_unified_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4kj_rRG1J66H"
   },
   "outputs": [],
   "source": [
    "if not run_test:\n",
    "    from google.colab import runtime\n",
    "    runtime.unassign()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "066vGmCNJTzY"
   },
   "source": [
    "# test\n",
    "##  PART A — In-sample (test split of same source)\n",
    "Subparts:\n",
    "1. vols per-stock heatmap  \n",
    "2. prcs per-stock heatmap + avg prob by true class  \n",
    "3. vols per-horizon heatmap\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "w03KqC8jJTzY"
   },
   "outputs": [],
   "source": [
    "if run_test:\n",
    "            test_unified(\"insample\", \"vols\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wkGkKgp98ua9"
   },
   "source": [
    "## In-sample - Prcs Per-Stock\n",
    "\n",
    "Subparts:\n",
    "1. vols per-stock heatmap  \n",
    "2. prcs per-stock heatmap + avg prob by true class  \n",
    "3. vols per-horizon heatmap\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JKW9afa-cENf"
   },
   "outputs": [],
   "source": [
    "if run_test:\n",
    "\n",
    "           test_unified(\"insample\", \"prcs\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L9IXNP9K8ua-"
   },
   "source": [
    "## In-sample - Horizon\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rpzR-1aN8ua-"
   },
   "outputs": [],
   "source": [
    "if run_test:\n",
    "        test_vols_per_horizon(mode=\"insample\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KBfRZp9y8ua-"
   },
   "source": [
    "# PART B — Out-of-sample (testData, cutdate+)\n",
    "## OOS - Vols Per-Stock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "F6WWmBSmcENg"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Testing VOLS (oos) - 3 configs ===\n",
      "Use GPU: cuda:0\n",
      "\u001b[93m suc to load G:/git/Crossformer1/checkpoints/Cf_vols_itr0_sw_dist_alpha1.0_gain_reg1.5_lambda_anti0.1_lambda_var0.0005_over_weight0.03_weight0.81_weight_over1.4vols0/crossformer.pkl \u001b[0m\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m run_test:\n\u001b[1;32m----> 2\u001b[0m         test_unified(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moos\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvols\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[2], line 708\u001b[0m, in \u001b[0;36mtest_unified\u001b[1;34m(mode, target_ds, by_stock, plot_residuals, plot_stock)\u001b[0m\n\u001b[0;32m    705\u001b[0m dep_var \u001b[38;5;241m=\u001b[39m get_feature_names(ds, \u001b[38;5;28mgetattr\u001b[39m(args, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mseq_len\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m    706\u001b[0m title \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mds\u001b[38;5;241m.\u001b[39mupper()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmode\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m [Idx \u001b[39m\u001b[38;5;132;01m{\u001b[39;00midx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m|Itr \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mitr_idx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 708\u001b[0m m_list, p_fam, t_fam \u001b[38;5;241m=\u001b[39m run_test_one_setting(\n\u001b[0;32m    709\u001b[0m     exp,\n\u001b[0;32m    710\u001b[0m     setting,\n\u001b[0;32m    711\u001b[0m     ds,\n\u001b[0;32m    712\u001b[0m     dep_var,\n\u001b[0;32m    713\u001b[0m     ycat,\n\u001b[0;32m    714\u001b[0m     title,\n\u001b[0;32m    715\u001b[0m     by_stock,\n\u001b[0;32m    716\u001b[0m     tables,\n\u001b[0;32m    717\u001b[0m     plot_stock,\n\u001b[0;32m    718\u001b[0m     itr_idx\u001b[38;5;241m=\u001b[39mitr_idx,\n\u001b[0;32m    719\u001b[0m )\n\u001b[0;32m    721\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m by_stock \u001b[38;5;129;01mand\u001b[39;00m p_fam \u001b[38;5;129;01mand\u001b[39;00m plot_residuals:\n\u001b[0;32m    722\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m--- AGGREGATED: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtitle\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m ---\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[2], line 620\u001b[0m, in \u001b[0;36mrun_test_one_setting\u001b[1;34m(exp, setting_str, ds, dep_var, ycat, title_prefix, by_stock, stock_tables, plot_individual_heatmaps, test_data, itr_idx)\u001b[0m\n\u001b[0;32m    618\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m by_stock:\n\u001b[0;32m    619\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m tb \u001b[38;5;129;01min\u001b[39;00m stock_tables:\n\u001b[1;32m--> 620\u001b[0m         p, t, m \u001b[38;5;241m=\u001b[39m exp\u001b[38;5;241m.\u001b[39mtest(setting_str, ds_tag, \u001b[38;5;28;01mTrue\u001b[39;00m, data_path\u001b[38;5;241m=\u001b[39m[tb], inverse\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    621\u001b[0m         m_list\u001b[38;5;241m.\u001b[39mappend(m)\n\u001b[0;32m    622\u001b[0m         all_p\u001b[38;5;241m.\u001b[39mappend(p)\n",
      "File \u001b[1;32mG:\\git/Crossformer1\\cross_exp\\exp_crossformer.py:666\u001b[0m, in \u001b[0;36mExp_crossformer.test\u001b[1;34m(self, setting, data, save_pred, inverse, data_path, run_metric, test_data)\u001b[0m\n\u001b[0;32m    655\u001b[0m     scaler \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    656\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheckpoint[key][\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m    657\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheckpoint \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheckpoint[key]) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    658\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    659\u001b[0m     )\n\u001b[0;32m    660\u001b[0m     data_split \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    661\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheckpoint[key][\u001b[38;5;241m2\u001b[39m]\n\u001b[0;32m    662\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheckpoint \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheckpoint[key]) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m\n\u001b[0;32m    663\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    664\u001b[0m     )\n\u001b[1;32m--> 666\u001b[0m     test_data, test_loader \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_data(\n\u001b[0;32m    667\u001b[0m         data\u001b[38;5;241m=\u001b[39mdata,\n\u001b[0;32m    668\u001b[0m         flag\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    669\u001b[0m         scaler\u001b[38;5;241m=\u001b[39mscaler,\n\u001b[0;32m    670\u001b[0m         data_path\u001b[38;5;241m=\u001b[39mdata_path,\n\u001b[0;32m    671\u001b[0m         data_split\u001b[38;5;241m=\u001b[39mdata_split,\n\u001b[0;32m    672\u001b[0m     )\n\u001b[0;32m    673\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    674\u001b[0m     test_data, test_loader \u001b[38;5;241m=\u001b[39m test_data\n",
      "File \u001b[1;32mG:\\git/Crossformer1\\cross_exp\\exp_crossformer.py:291\u001b[0m, in \u001b[0;36mExp_crossformer._get_data\u001b[1;34m(self, flag, data, data_path, scaler, data_split)\u001b[0m\n\u001b[0;32m    289\u001b[0m     drop_last \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    290\u001b[0m     batch_size \u001b[38;5;241m=\u001b[39m args\u001b[38;5;241m.\u001b[39mbatch_size\n\u001b[1;32m--> 291\u001b[0m data_set \u001b[38;5;241m=\u001b[39m DatasetMTS(\n\u001b[0;32m    292\u001b[0m     root_path\u001b[38;5;241m=\u001b[39margs\u001b[38;5;241m.\u001b[39mroot_path,\n\u001b[0;32m    293\u001b[0m     data_path\u001b[38;5;241m=\u001b[39mdata_path \u001b[38;5;28;01mif\u001b[39;00m data_path \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m args\u001b[38;5;241m.\u001b[39mdata_path,\n\u001b[0;32m    294\u001b[0m     data_name\u001b[38;5;241m=\u001b[39mtarget_data,\n\u001b[0;32m    295\u001b[0m     flag\u001b[38;5;241m=\u001b[39mflag,\n\u001b[0;32m    296\u001b[0m     in_len\u001b[38;5;241m=\u001b[39margs\u001b[38;5;241m.\u001b[39min_len,\n\u001b[0;32m    297\u001b[0m     data_split\u001b[38;5;241m=\u001b[39mdata_split \u001b[38;5;129;01mor\u001b[39;00m args\u001b[38;5;241m.\u001b[39mdata_split,\n\u001b[0;32m    298\u001b[0m     query\u001b[38;5;241m=\u001b[39margs\u001b[38;5;241m.\u001b[39mquery,\n\u001b[0;32m    299\u001b[0m     scaler\u001b[38;5;241m=\u001b[39mscaler,\n\u001b[0;32m    300\u001b[0m )\n\u001b[0;32m    302\u001b[0m \u001b[38;5;28mprint\u001b[39m(flag, \u001b[38;5;28mlen\u001b[39m(data_set))\n\u001b[0;32m    303\u001b[0m data_loader \u001b[38;5;241m=\u001b[39m DataLoader(\n\u001b[0;32m    304\u001b[0m     data_set,\n\u001b[0;32m    305\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    308\u001b[0m     drop_last\u001b[38;5;241m=\u001b[39mdrop_last,\n\u001b[0;32m    309\u001b[0m )\n",
      "File \u001b[1;32mG:\\git/Crossformer1\\data\\data_loader.py:159\u001b[0m, in \u001b[0;36mDatasetMTS.__init__\u001b[1;34m(self, root_path, data_path, data_name, in_len, flag, data_split, query, scaler)\u001b[0m\n\u001b[0;32m    157\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mquery \u001b[38;5;241m=\u001b[39m query\n\u001b[0;32m    158\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscaler \u001b[38;5;241m=\u001b[39m scaler\n\u001b[1;32m--> 159\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__read_data__()\n\u001b[0;32m    160\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata[\u001b[38;5;241m2\u001b[39m][\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mset_type][\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    161\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscaler \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[1;32mG:\\git/Crossformer1\\data\\data_loader.py:455\u001b[0m, in \u001b[0;36mDatasetMTS.__read_data__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    453\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m cache_hit:\n\u001b[0;32m    454\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m--> 455\u001b[0m     df_raws \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_read_files_and_split(cols, cols[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtm0\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m    456\u001b[0m names \u001b[38;5;241m=\u001b[39m data_names(cols, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39min_len)\n\u001b[0;32m    457\u001b[0m arrays \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_extract_initial_arrays(df_raws, cols, names)\n",
      "File \u001b[1;32mG:\\git/Crossformer1\\data\\data_loader.py:280\u001b[0m, in \u001b[0;36mDatasetMTS._read_files_and_split\u001b[1;34m(self, cols, dtm0)\u001b[0m\n\u001b[0;32m    278\u001b[0m     df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhorizon\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdtm0\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39min_len\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m-\u001b[39m df[dtm0]\n\u001b[0;32m    279\u001b[0m     lasttime \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mgroupby([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mday\u001b[39m\u001b[38;5;124m\"\u001b[39m])[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdate\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mmax()\u001b[38;5;241m.\u001b[39mvalues\n\u001b[1;32m--> 280\u001b[0m     df \u001b[38;5;241m=\u001b[39m df[(df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdate\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39misin(lasttime)) \u001b[38;5;241m&\u001b[39m (df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhorizon\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m)]\n\u001b[0;32m    281\u001b[0m ds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    282\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mquery \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32md:\\ProgramData\\miniconda3\\envs\\s1\\Lib\\site-packages\\pandas\\core\\frame.py:4093\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4091\u001b[0m \u001b[38;5;66;03m# Do we have a (boolean) 1d indexer?\u001b[39;00m\n\u001b[0;32m   4092\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m com\u001b[38;5;241m.\u001b[39mis_bool_indexer(key):\n\u001b[1;32m-> 4093\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_bool_array(key)\n\u001b[0;32m   4095\u001b[0m \u001b[38;5;66;03m# We are left with two options: a single key, and a collection of keys,\u001b[39;00m\n\u001b[0;32m   4096\u001b[0m \u001b[38;5;66;03m# We interpret tuples as collections only for non-MultiIndex\u001b[39;00m\n\u001b[0;32m   4097\u001b[0m is_single_key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28misinstance\u001b[39m(key, \u001b[38;5;28mtuple\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_list_like(key)\n",
      "File \u001b[1;32md:\\ProgramData\\miniconda3\\envs\\s1\\Lib\\site-packages\\pandas\\core\\frame.py:4152\u001b[0m, in \u001b[0;36mDataFrame._getitem_bool_array\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4149\u001b[0m key \u001b[38;5;241m=\u001b[39m check_bool_indexer(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex, key)\n\u001b[0;32m   4151\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m key\u001b[38;5;241m.\u001b[39mall():\n\u001b[1;32m-> 4152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy(deep\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m   4154\u001b[0m indexer \u001b[38;5;241m=\u001b[39m key\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m   4155\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_take_with_is_copy(indexer, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[1;32md:\\ProgramData\\miniconda3\\envs\\s1\\Lib\\site-packages\\pandas\\core\\generic.py:6811\u001b[0m, in \u001b[0;36mNDFrame.copy\u001b[1;34m(self, deep)\u001b[0m\n\u001b[0;32m   6662\u001b[0m \u001b[38;5;129m@final\u001b[39m\n\u001b[0;32m   6663\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcopy\u001b[39m(\u001b[38;5;28mself\u001b[39m, deep: bool_t \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Self:\n\u001b[0;32m   6664\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   6665\u001b[0m \u001b[38;5;124;03m    Make a copy of this object's indices and data.\u001b[39;00m\n\u001b[0;32m   6666\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   6809\u001b[0m \u001b[38;5;124;03m    dtype: int64\u001b[39;00m\n\u001b[0;32m   6810\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 6811\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mgr\u001b[38;5;241m.\u001b[39mcopy(deep\u001b[38;5;241m=\u001b[39mdeep)\n\u001b[0;32m   6812\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_clear_item_cache()\n\u001b[0;32m   6813\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_constructor_from_mgr(data, axes\u001b[38;5;241m=\u001b[39mdata\u001b[38;5;241m.\u001b[39maxes)\u001b[38;5;241m.\u001b[39m__finalize__(\n\u001b[0;32m   6814\u001b[0m         \u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcopy\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   6815\u001b[0m     )\n",
      "File \u001b[1;32md:\\ProgramData\\miniconda3\\envs\\s1\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:593\u001b[0m, in \u001b[0;36mBaseBlockManager.copy\u001b[1;34m(self, deep)\u001b[0m\n\u001b[0;32m    590\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    591\u001b[0m         new_axes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes)\n\u001b[1;32m--> 593\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcopy\u001b[39m\u001b[38;5;124m\"\u001b[39m, deep\u001b[38;5;241m=\u001b[39mdeep)\n\u001b[0;32m    594\u001b[0m res\u001b[38;5;241m.\u001b[39maxes \u001b[38;5;241m=\u001b[39m new_axes\n\u001b[0;32m    596\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    597\u001b[0m     \u001b[38;5;66;03m# Avoid needing to re-compute these\u001b[39;00m\n",
      "File \u001b[1;32md:\\ProgramData\\miniconda3\\envs\\s1\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:363\u001b[0m, in \u001b[0;36mBaseBlockManager.apply\u001b[1;34m(self, f, align_keys, **kwargs)\u001b[0m\n\u001b[0;32m    361\u001b[0m         applied \u001b[38;5;241m=\u001b[39m b\u001b[38;5;241m.\u001b[39mapply(f, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    362\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 363\u001b[0m         applied \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(b, f)(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    364\u001b[0m     result_blocks \u001b[38;5;241m=\u001b[39m extend_blocks(applied, result_blocks)\n\u001b[0;32m    366\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mfrom_blocks(result_blocks, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes)\n",
      "File \u001b[1;32md:\\ProgramData\\miniconda3\\envs\\s1\\Lib\\site-packages\\pandas\\core\\internals\\blocks.py:796\u001b[0m, in \u001b[0;36mBlock.copy\u001b[1;34m(self, deep)\u001b[0m\n\u001b[0;32m    794\u001b[0m refs: BlockValuesRefs \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    795\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m deep:\n\u001b[1;32m--> 796\u001b[0m     values \u001b[38;5;241m=\u001b[39m values\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m    797\u001b[0m     refs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    798\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if run_test:\n",
    "        test_unified(\"oos\", \"vols\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rWJgEQeu8ua_"
   },
   "source": [
    "## hlc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FFlVJgjocENh"
   },
   "outputs": [],
   "source": [
    "if run_test:\n",
    "        test_unified(\"oos\", \"prcs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ff1dksSt8ubA"
   },
   "source": [
    "## horizon\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VPL62tkj8ubA"
   },
   "outputs": [],
   "source": [
    "if run_test:\n",
    "\n",
    "        test_vols_per_horizon(mode=\"oos\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jI4GPCiA8ubA"
   },
   "source": [
    "# end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "45zLIW5xJTza"
   },
   "outputs": [],
   "source": [
    "plt.show()\n",
    "from google.colab import runtime\n",
    "runtime.unassign()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "L4",
   "machine_shape": "hm",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "s1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
