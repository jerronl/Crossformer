{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5KB0_RDrJTzT"
   },
   "source": [
    "# setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JaXYxzifbhst"
   },
   "outputs": [],
   "source": [
    "run_test=True\n",
    "# run_test=False\n",
    "epochs=(1,1,1)\n",
    "epochs=(15,500,3)\n",
    "cutdate='2024-12-20'\n",
    "testData=''\n",
    "testData='new/'\n",
    "weight=(0.8,1.0)\n",
    "itr=5\n",
    "metrics_cnt=6\n",
    "import torch,sys\n",
    "\n",
    "if 'google.colab' in str(get_ipython()):\n",
    "  from google.colab import drive\n",
    "  drive.mount('/content/drive')\n",
    "  mydrive='/content/drive/MyDrive/volrt/'\n",
    "  source_path=mydrive+\"git/Crossformer\"\n",
    "  tables = ['volvNVDA.csv', 'volvTSLA.csv', 'volvAAPL.csv', 'volvGOOG.csv', ]\n",
    "  batch_size=int(torch.cuda.get_device_properties(0).total_memory/1e9+.5)*32\n",
    "  import os,sys\n",
    "  if not os.path.exists(source_path):\n",
    "    %cd $mydrive/git\n",
    "    !git clone https://github.com/jerronl/Crossformer.git\n",
    "    %cd $source_path\n",
    "  else:\n",
    "    %cd $source_path\n",
    "    # !git reset --hard HEAD\n",
    "    # !git pull origin master\n",
    "  %pip install einops #scikit-learn\n",
    "  sys.path.append( source_path)\n",
    "else:\n",
    "  tables = [ 'volvAAPL.csv']\n",
    "  testData=''\n",
    "  mydrive= 'E:/mydoc/git/trade/analyics/'\n",
    "  batch_size=32\n",
    "  sys.path.append(\"G:/git/Crossformer1/\")\n",
    "  itr=1\n",
    "%cd $mydrive\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dQsiHS9i8ua4"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import argparse\n",
    "# import torch\n",
    "\n",
    "from cross_exp.exp_crossformer import Exp_crossformer\n",
    "from utils.tools import string_split\n",
    "from data.data_def import set_cat\n",
    "set_cat(20)\n",
    "\n",
    "parser = argparse.ArgumentParser(description=\"CrossFormer\")\n",
    "\n",
    "parser.add_argument(\"--data\", type=str, default=\"vols\", help=\"data\")\n",
    "parser.add_argument(\"--weight\", type=str, default=weight[0], help=\"data\")\n",
    "parser.add_argument(\n",
    "    \"--root_path\", type=str, default=mydrive, help=\"root path of the data file\"\n",
    ")\n",
    "parser.add_argument(\"--delta\",        type=float, default=1.0, help=\"Huber 损失 δ\")\n",
    "# parser.add_argument(\"--thresh\",       type=float, default=0.03, help=\"加权 MSE 阈值\")\n",
    "# parser.add_argument(\"--alpha\",        type=float, default=1.0, help=\"极端样本权重 α\")\n",
    "# parser.add_argument(\"--tau\",          type=float, default=0.9, help=\"Quantile τ\")\n",
    "parser.add_argument(\"--lambda_huber\", type=float, default=1.0)\n",
    "parser.add_argument(\"--lambda_mse\", type=float, default=1.0)\n",
    "parser.add_argument(\"--lambda_reg\",   type=float, default=0.5)\n",
    "parser.add_argument(\"--lambda_q90\",   type=float, default=0.5)\n",
    "parser.add_argument(\"--data_path\", type=list, default=tables, help=\"data file\")\n",
    "parser.add_argument(\n",
    "    \"--data_split\",\n",
    "    type=str,\n",
    "    default=\"0.7,0.1,0.2\",\n",
    "    help=\"train/val/test split, can be ratio or number\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--checkpoints\",\n",
    "    type=str,\n",
    "    default=\"./checkpoints/\",\n",
    "    help=\"location to store model checkpoints\",\n",
    ")\n",
    "\n",
    "parser.add_argument(\"--in_len\", type=int, default=20, help=\"input MTS length (T)\")\n",
    "parser.add_argument(\"--out_len\", type=int, default=1, help=\"output MTS length (\\tau)\")\n",
    "parser.add_argument(\"--seg_len\", type=int, default=5, help=\"segment length (L_seg)\")\n",
    "parser.add_argument(\n",
    "    \"--win_size\", type=int, default=2, help=\"window size for segment merge\"\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--factor\",\n",
    "    type=int,\n",
    "    default=10,\n",
    "    help=\"num of routers in Cross-Dimension Stage of TSA (c)\",\n",
    ")\n",
    "\n",
    "parser.add_argument(\n",
    "    \"--d_model\", type=int, default=256, help=\"dimension of hidden states (d_model)\"\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--d_ff\", type=int, default=512, help=\"dimension of MLP in transformer\"\n",
    ")\n",
    "parser.add_argument(\"--n_heads\", type=int, default=4, help=\"num of heads\")\n",
    "parser.add_argument(\"--e_layers\", type=int, default=3, help=\"num of encoder layers (N)\")\n",
    "parser.add_argument(\"--dropout\", type=float, default=0.2, help=\"dropout\")\n",
    "\n",
    "parser.add_argument(\n",
    "    \"--baseline\",\n",
    "    action=\"store_true\",\n",
    "    help=\"whether to use mean of past series as baseline for prediction\",\n",
    "    default=False,\n",
    ")\n",
    "\n",
    "parser.add_argument(\n",
    "    \"--num_workers\", type=int, default=0, help=\"data loader num workers\"\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--batch_size\", type=int, default=32, help=\"batch size of train input data\"\n",
    ")\n",
    "parser.add_argument(\"--train_epochs\", type=int, default=20, help=\"train epochs\")\n",
    "parser.add_argument(\"--patience\", type=int, default=3, help=\"early stopping patience\")\n",
    "parser.add_argument(\n",
    "    \"--learning_rate\", type=float, default=1e-4, help=\"optimizer initial learning rate\"\n",
    ")\n",
    "parser.add_argument(\"--lradj\", type=str, default=\"type1\", help=\"adjust learning rate\")\n",
    "parser.add_argument(\"--itr\", type=int, default=itr, help=\"experiments times\")\n",
    "\n",
    "parser.add_argument(\n",
    "    \"--save_pred\",\n",
    "    action=\"store_true\",\n",
    "    help=\"whether to save the predicted future MTS\",\n",
    "    default=False,\n",
    ")\n",
    "\n",
    "parser.add_argument(\"--use_gpu\", type=bool, default=True, help=\"use gpu\")\n",
    "parser.add_argument(\"--resume\", type=bool, default=True, help=\"resume\")\n",
    "parser.add_argument(\"--query\", type=str, default=None, help=\"resume\")\n",
    "# parser.add_argument(\"--use_gpu\", type=bool, default=False, help=\"use gpu\")\n",
    "parser.add_argument(\"--gpu\", type=int, default=0, help=\"gpu\")\n",
    "parser.add_argument(\n",
    "    \"--use_multi_gpu\", action=\"store_true\", help=\"use multiple gpus\", default=False\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--devices\", type=str, default=\"0,1,2,3\", help=\"device ids of multile gpus\"\n",
    ")\n",
    "\n",
    "args = parser.parse_args(args=[])\n",
    "\n",
    "args.use_gpu = True if torch.cuda.is_available() and args.use_gpu else False\n",
    "\n",
    "if args.use_gpu and args.use_multi_gpu:\n",
    "    args.devices = args.devices.replace(\" \", \"\")\n",
    "    device_ids = args.devices.split(\",\")\n",
    "    args.device_ids = [int(id_) for id_ in device_ids]\n",
    "    args.gpu = args.device_ids[0]\n",
    "    print(args.gpu)\n",
    "\n",
    "\n",
    "def update_args(itr):\n",
    "    if args.data in data_parser.keys():\n",
    "        data_info = data_parser[args.data]\n",
    "        for k,v in data_info.items():\n",
    "            args.__setattr__(k,v)\n",
    "    if isinstance(args.data_split, str) :\n",
    "        args.data_split = string_split(args.data_split)\n",
    "\n",
    "    print(\"Args in experiment:\")\n",
    "    print(args)\n",
    "    setting = \"Crossformer_itr{}_il{}_ol{}_sl{}_win{}_fa{}_dm{}_nh{}_el{}_wt{}\".format(\n",
    "        itr,\n",
    "        args.in_len,\n",
    "        args.out_len,\n",
    "        args.seg_len,\n",
    "        args.win_size,\n",
    "        args.factor,\n",
    "        args.d_model,\n",
    "        args.n_heads,\n",
    "        args.e_layers,\n",
    "        args.weight\n",
    "    )\n",
    "    return setting\n",
    "import seaborn as sns, numpy as np,math\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def regplot(dep_var, metrics, cols, itr=None, figsize=4):\n",
    "    cnt = len(dep_var) - dep_var.count(\"_\")\n",
    "    figs = min(cnt, cols)\n",
    "    _, axes = plt.subplots(math.ceil(cnt / figs), figs, figsize=(figsize*figs,figsize*max(1,(cnt-1)//figs+1)))\n",
    "    j = 0\n",
    "\n",
    "    for i, name in enumerate(dep_var):\n",
    "        if name != \"_\":\n",
    "            if itr:\n",
    "                name=f'{itr}_{name}'\n",
    "            axs = axes.flat[j] if figs > 1 else axes\n",
    "            j = j + 1\n",
    "            left, right = 999, -999\n",
    "            for ii in range(len(results)):\n",
    "                preds, trues, _ = results[ii]\n",
    "                sns.regplot(\n",
    "                    ax=axs,\n",
    "                    x=trues[:, i],\n",
    "                    y=preds[:, i],\n",
    "                    scatter_kws={\"color\": f\"C{ii}\", \"alpha\": 0.3},\n",
    "                    line_kws={\"color\": f\"C{ii}\", \"alpha\": 0.3},\n",
    "                    label=labels[1][ii],\n",
    "                )\n",
    "                mask = ~np.isnan(trues[:, i])\n",
    "                if not dep_var[i][:3] in [\"dtm\", \"pmc\"]:\n",
    "                    left = min(left, max(np.min(trues[:, i][mask]), -5))\n",
    "                    right = max(right, min(np.max(trues[:, i][mask]), 5))\n",
    "                else:\n",
    "                    left = min(left, np.min(trues[:, i][mask]))\n",
    "                    right = max(right, np.max(trues[:, i][mask]))\n",
    "            axs.set_title(name)\n",
    "            axs.set_xlim(left=left, right=right)\n",
    "            axs.legend()\n",
    "    metric = []\n",
    "    for ii in range(len(results)):\n",
    "        _, _, m = results[ii]\n",
    "        metric.append(m)\n",
    "\n",
    "    metrics = np.append(\n",
    "        metrics, np.array(metric).reshape([1, len(metric), len(m)]), axis=0\n",
    "    )\n",
    "\n",
    "    plt.show()\n",
    "    return metrics\n",
    "    \n",
    "\n",
    "\n",
    "def plot_metric(metrics, labels, *args, **kwargs):\n",
    "    a, b, c = metrics.shape\n",
    "    _, axs = plt.subplots(\n",
    "        nrows=math.ceil(c / 2),\n",
    "        ncols=2, figsize=(16, 16), \n",
    "    )\n",
    "    for i in range(c):\n",
    "        ax = (\n",
    "            axs[i // 2, i % 2] if c > 1 else axs\n",
    "        )  # Handle the case when c=1 to avoid indexing errors\n",
    "        for j in range(a):\n",
    "            ax.plot(\n",
    "                metrics[j, :, i], label=labels[0][j], *args, **kwargs\n",
    "            )  # Plot each series in the i-th plot\n",
    "        ax.set_title(labels[2][i])\n",
    "        ax.legend()  # Show legend in each subplot\n",
    "\n",
    "        # Set custom x-axis labels\n",
    "        ax.set_xticks(range(b))  # Set x-tick positions for all 'b' points\n",
    "        ax.set_xticklabels(labels[1])  # Set x-tick labels\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def plot_hlc():\n",
    "  global results,labels\n",
    "  dep_var=data_names(data_columns(test_set),20)[0]\n",
    "  labels=[[f'm{i}' for i in range(itr)],tables,[\"mae\", \"mse\", \"rmse\", \"mape\", \"mspe\", \"accr\"]]\n",
    "  metrics=np.empty((0,len(tables),metrics_cnt))\n",
    "  n_categories=data_columns(test_set)[\"ycat\"]\n",
    "  for i in range(itr):\n",
    "    setting=update_args(i)\n",
    "    DatasetMTS.clear()\n",
    "    exp = Exp_crossformer(args)\n",
    "    print(f\">>>>>>>testing : {setting}<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\")\n",
    "    results = []\n",
    "    for table in tables:\n",
    "        results.append(exp.test(setting, 'prcs', True, data_path=[table], inverse=True))\n",
    "    metrics=regplot(dep_var,metrics,4,i)\n",
    "        \n",
    "    rows=(len(results)-1)//4+1\n",
    "    _, axes = plt.subplots(rows, 4, figsize=(16, 4*rows))  # 1 row, 2 columns\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    for j, result in enumerate(results):\n",
    "        preds, trues, _ = result\n",
    "        preds = preds[:, -n_categories:]\n",
    "        trues = np.round(trues[:,0]).astype(int)\n",
    "        df = pd.DataFrame(preds, columns=[f\"{i}\" for i in range(1, n_categories + 1)])\n",
    "        df['True_Label'] = trues\n",
    "        # Sum probabilities for each true category\n",
    "        summed_probs = df.groupby('True_Label').mean().T\n",
    "        ax = axes[j]\n",
    "        for col in summed_probs.columns:\n",
    "            ax.plot(summed_probs.index, summed_probs[col], label=f'Col {col}',\n",
    "                    linestyle='--' if col>len(summed_probs.columns)*.67 else '-'\n",
    "                    if col<len(summed_probs.columns)/3. else ':')\n",
    "\n",
    "        # Add labels to each line\n",
    "        for k,col in enumerate( summed_probs.columns):\n",
    "            # icol=round(col)\n",
    "            ax.text(\n",
    "                x=summed_probs.index[k],  # Place at the last x-coordinate\n",
    "                y=summed_probs[col].iloc[k],  # Place at the last y-coordinate\n",
    "                s=col,  # Label\n",
    "                fontsize=8,  # Font size for labels\n",
    "                verticalalignment='center',  # Align text vertically\n",
    "                horizontalalignment='left'  # Align text horizontally\n",
    "            )\n",
    "\n",
    "        # Add rug plots\n",
    "        ax.hist(trues,bins=range(max(trues)),density=True)\n",
    "        # ax.legend(loc='center left', bbox_to_anchor=(1.05, 0.5))\n",
    "        ax.set_title(f'{tables[j]}_{i}')\n",
    "        # axes[j].set_xlim(0, n_categories-1)\n",
    "        axes[j].set_ylim(0.02, 0.1)\n",
    "    axes[-1].legend(loc='center left', bbox_to_anchor=(1.05, 0.5))\n",
    "    plt.show()\n",
    "    \n",
    "  print(metrics)\n",
    "  plot_metric(metrics,labels)\n",
    "\n",
    "np.set_printoptions(precision=4, suppress=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qCfd-gU7JTzW"
   },
   "source": [
    "# train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YeTQzMtGy8Ih"
   },
   "outputs": [],
   "source": [
    "if not run_test:\n",
    "    from cross_exp.exp_crossformer import Exp_crossformer\n",
    "    from data.data_loader import DatasetMTS\n",
    "    data_parser = {\n",
    "        \"vols\": {\n",
    "            \"patience\":epochs[0],\n",
    "            \"train_epochs\":epochs[1],\n",
    "            'learning_rate':0.01,\n",
    "            'data_split':[0.7,0.15,0.15],\n",
    "            'batch_size':batch_size*2//5,\n",
    "            'e_layers':5,\n",
    "            'd_model':512,\n",
    "            'lradj':'type2',\n",
    "            \"checkpoints\":\"./checkpoints/\",\n",
    "        },\n",
    "        }\n",
    "    for _ in range(epochs[2]):\n",
    "        data_parser[\"vols\"][\"learning_rate\"]=.01\n",
    "        for i in range(epochs[2]):\n",
    "            for ii in range(itr):\n",
    "                # setting record of experiments\n",
    "                data_parser[\"vols\"]['weight']=weight[0]\n",
    "                setting = update_args(ii)\n",
    "                DatasetMTS.clear()\n",
    "\n",
    "                exp = Exp_crossformer(args)  # set experiments\n",
    "                print(f\">>>>>>>start training : {setting}>>>>>>>>>>>>>>>>>>>>>>>>>>\")\n",
    "                exp.train(setting, \"vols\")\n",
    "\n",
    "                print(f\">>>>>>>testing : {setting}<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\")\n",
    "                preds, trues,_ = exp.test(setting, 'vols', True, data_path=[tables[-1]], inverse=True)\n",
    "                print(preds.shape, trues.shape)\n",
    "                \n",
    "                data_parser[\"vols\"]['weight']=weight[1]\n",
    "                setting = update_args(ii)\n",
    "                DatasetMTS.clear()\n",
    "                exp = Exp_crossformer(args)  # set experiments           \n",
    "                print(f\">>>>>>>start training : {setting}>>>>>>>>>>>>>>>>>>>>>>>>>>\")\n",
    "                exp.train(setting, \"prcs\")\n",
    "                preds, trues,_ = exp.test(setting, 'prcs', True, data_path=[tables[-1]], inverse=True)\n",
    "                print(preds.shape, trues.shape)\n",
    "            data_parser[\"vols\"][\"learning_rate\"]/=3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "4kj_rRG1J66H"
   },
   "outputs": [],
   "source": [
    "if not run_test:\n",
    "    from google.colab import runtime\n",
    "    runtime.unassign()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "066vGmCNJTzY"
   },
   "source": [
    "# test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "w03KqC8jJTzY"
   },
   "outputs": [],
   "source": [
    "from data.data_loader import DatasetMTS\n",
    "from data.data_def import data_columns, data_names\n",
    "data_parser = {\n",
    "    \"vols\": {\n",
    "        'e_layers':5,\n",
    "        'd_model':512,\n",
    "        'lradj':'type2',\n",
    "        'weight':weight[0],\n",
    "    },\n",
    "    }\n",
    "test_set='vols'\n",
    "dep_var=data_names(data_columns(test_set),20)[0]\n",
    "labels=[[f'm{i}' for i in range(itr)],tables,[\"mae\", \"mse\", \"rmse\", \"mape\", \"mspe\", \"accr\"]]\n",
    "metrics=np.empty((0,len(tables),metrics_cnt))\n",
    "for i in range(itr):\n",
    "  setting=update_args(i)\n",
    "  DatasetMTS.clear()\n",
    "  exp = Exp_crossformer(args)\n",
    "  print(f\">>>>>>>testing : {setting}<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\")\n",
    "  results = []\n",
    "  for table in tables:\n",
    "      results.append(exp.test(setting, 'vols', True, data_path=[table], inverse=True))\n",
    "  metrics=regplot(dep_var,metrics,4,i)\n",
    "\n",
    "print(metrics)\n",
    "plot_metric(metrics,labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wkGkKgp98ua9"
   },
   "source": [
    "## hlc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JKW9afa-cENf"
   },
   "outputs": [],
   "source": [
    "from data.data_loader import DatasetMTS\n",
    "from data.data_def import data_columns, data_names\n",
    "import pandas as pd\n",
    "\n",
    "test_set='prcs'\n",
    "data_parser = {\n",
    "    \"vols\": {\n",
    "        'e_layers':5,\n",
    "        'd_model':512,\n",
    "        'lradj':'type2',\n",
    "        'weight':weight[1],\n",
    "    },\n",
    "    }\n",
    "plot_hlc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L9IXNP9K8ua-"
   },
   "source": [
    "## horizon\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rpzR-1aN8ua-"
   },
   "outputs": [],
   "source": [
    "from data.data_loader import DatasetMTS\n",
    "from cross_exp.exp_crossformer import Exp_crossformer\n",
    "test_set='vols'\n",
    "\n",
    "labels=[[f'm{i}' for i in range(itr)] ,[f'h{h+1}' for h in range(5)],[\"mae\", \"mse\", \"rmse\", \"mape\", \"mspe\", \"accr\"]]\n",
    "dep_var=data_names(data_columns(test_set),20)[0]\n",
    "metrics=np.empty((0,len(labels[1]),len(labels[2])))\n",
    "for i in range(itr):\n",
    "  results = []\n",
    "  for h in range(5):\n",
    "    data_parser = {\n",
    "    \"vols\": {\n",
    "        'e_layers':5,\n",
    "        'd_model':512,\n",
    "        'lradj':'type2',\n",
    "        \"query\": f\"floor(horizon)=={h+1}\",\n",
    "        'weight':weight[0],\n",
    "    },\n",
    "    }\n",
    "    setting=update_args(i)\n",
    "    DatasetMTS.clear()\n",
    "    exp = Exp_crossformer(args)\n",
    "    print(f\">>>>>>>testing : {data_parser['vols']['query']} m{i}h{h+1}<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\")\n",
    "    results.append(exp.test(setting, 'vols', True, inverse=True))\n",
    "  metrics=regplot(dep_var,metrics,4,i)\n",
    "\n",
    "print(metrics)\n",
    "plot_metric(metrics,labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KBfRZp9y8ua-"
   },
   "source": [
    "## cutline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "F6WWmBSmcENg"
   },
   "outputs": [],
   "source": [
    "from cross_exp.exp_crossformer import Exp_crossformer\n",
    "from data.data_loader import DatasetMTS\n",
    "from data.data_def import data_columns, data_names\n",
    "test_set='vols'\n",
    "\n",
    "data_parser = {\n",
    "    \"vols\": {\n",
    "        'e_layers':5,\n",
    "        'd_model':512,\n",
    "        \"query\": f\"date>'#{cutdate}'\",\n",
    "        'root_path':mydrive+testData,\n",
    "        'weight':weight[0],\n",
    "    },\n",
    "    }\n",
    "\n",
    "dep_var=data_names(data_columns(test_set),20)[0]\n",
    "labels=[[f'm{i}' for i in range(itr)],tables,[\"mae\", \"mse\", \"rmse\", \"mape\", \"mspe\", \"accr\"]]\n",
    "metrics=np.empty((0,len(tables),metrics_cnt))\n",
    "for i in range(itr):\n",
    "  setting=update_args(i)\n",
    "  DatasetMTS.clear()\n",
    "  exp = Exp_crossformer(args)\n",
    "  print(f\">>>>>>>testing : {setting}<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\")\n",
    "  results = []\n",
    "  for table in tables:\n",
    "      results.append(exp.test(setting, 'vols', True, data_path=[table], inverse=True))\n",
    "  metrics=regplot(dep_var,metrics,4,i)\n",
    "\n",
    "print(metrics)\n",
    "plot_metric(metrics,labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rWJgEQeu8ua_"
   },
   "source": [
    "## hlc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FFlVJgjocENh"
   },
   "outputs": [],
   "source": [
    "from data.data_loader import DatasetMTS\n",
    "from data.data_def import data_columns, data_names\n",
    "import pandas as pd\n",
    "\n",
    "test_set='prcs'\n",
    "data_parser = {\n",
    "    \"vols\": {\n",
    "        'e_layers':5,\n",
    "        'd_model':512,\n",
    "        'lradj':'type2',\n",
    "        \"query\": f\"date>'#{cutdate}'\",\n",
    "        'root_path':mydrive+testData,\n",
    "        'weight':weight[1],\n",
    "        },\n",
    "    }\n",
    "plot_hlc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ff1dksSt8ubA"
   },
   "source": [
    "## horizon\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VPL62tkj8ubA"
   },
   "outputs": [],
   "source": [
    "from data.data_loader import DatasetMTS\n",
    "from cross_exp.exp_crossformer import Exp_crossformer\n",
    "from data.data_def import data_columns, data_names\n",
    "test_set='vols'\n",
    "labels=[[f'm{i}' for i in range(itr)] ,[f'h{h+1}' for h in range(5)],[\"mae\", \"mse\", \"rmse\", \"mape\", \"mspe\", \"accr\"]]\n",
    "dep_var=data_names(data_columns(test_set),20)[0]\n",
    "metrics=np.empty((0,len(labels[1]),len(labels[2])))\n",
    "for i in range(itr):\n",
    "  results = []\n",
    "  for h in range(5):\n",
    "    data_parser = {\n",
    "    \"vols\": {\n",
    "        'e_layers':5,\n",
    "        'd_model':512,\n",
    "        'lradj':'type2',\n",
    "        'root_path':mydrive+testData,\n",
    "        \"query\": f\"date>'#{cutdate}' and floor(horizon)=={h+1}\",\n",
    "        'weight':weight[0],\n",
    "    },\n",
    "    }\n",
    "    setting=update_args(i)\n",
    "    DatasetMTS.clear()\n",
    "    exp = Exp_crossformer(args)\n",
    "    print(f\">>>>>>>testing : {data_parser['vols']['query']} m{i}h{h+1}<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\")\n",
    "    results.append(exp.test(setting, 'vols', True, inverse=True))\n",
    "  metrics=regplot(dep_var,metrics,4,i)\n",
    "\n",
    "print(metrics)\n",
    "plot_metric(metrics,labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jI4GPCiA8ubA"
   },
   "source": [
    "# end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "45zLIW5xJTza"
   },
   "outputs": [],
   "source": [
    "plt.show()\n",
    "from google.colab import runtime\n",
    "runtime.unassign()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "V100",
   "machine_shape": "hm",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "e1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
